#!/usr/bin/env python3
"""
scorer_trial_worker.py (v3.1 - Patched for Full Scoring)
==================================================
Runs ONE pre-defined scorer trial on a remote worker with intelligent early stopping.
...
v3.1 Patch:
- Modified 'run_trial' to return the full list of scores.
- Modified 'save_local_result' to accept and save this score list.
- This enables the Step 3.5 aggregation script.
"""
# =============================================================================
# PULL ARCHITECTURE MODIFICATION (2025-11-17)
# =============================================================================
# 
# WHAT WAS CHANGED:
#   Lines 321-331 in main() were commented out to disable Optuna connection.
#   This prevents workers from trying to access Optuna database on remote nodes.
#
# WHY:
#   In PULL architecture, Optuna DB only exists on zeus (head node).
#   Remote workers (192.168.3.120, 192.168.3.154) cannot access it.
#   Workers now just run trials and write JSON results for coordinator to pull.
#
# TO RE-ENABLE OPTUNA PRUNING:
#   1. Uncomment lines 321-331 in main() function
#   2. Look for: "# --- DISABLED FOR PURE PULL ARCHITECTURE ---"
#   3. Remove the "# " prefix from each line in that block
#   4. This will re-enable: optuna.load_study() and trial pruning
#
# REQUIREMENTS FOR RE-ENABLING:
#   - Optuna DB must be accessible from all worker nodes
#   - Either: Use shared NFS storage for sqlite DB
#   - Or: Use network Optuna backend (PostgreSQL/MySQL)
#   - Or: Implement checkpoint-based pruning (coordinator-side)
#
# CURRENT STATE: PULL mode (no pruning, all trials run to completion)
# =============================================================================
# --- ADDED: ROCm environment setup - MUST BE FIRST ---
import os
import socket
HOST = socket.gethostname()

# Apply ROCm overrides for AMD systems
if HOST in ["rig-6600", "rig-6600b"]:
    os.environ.setdefault("HSA_OVERRIDE_GFX_VERSION", "10.3.0")
    os.environ.setdefault("HSA_ENABLE_SDMA", "0")

# ROCm paths
os.environ.setdefault("ROCM_PATH", "/opt/rocm")
os.environ.setdefault("HIP_PATH", "/opt/rocm")
# --- END ADDED SECTION ---


import sys
import json
import logging
import time
# os and socket are already imported above
from pathlib import Path
from typing import Optional, Dict, Any, List # <-- ADDED List
import optuna

# Adjust path to find local modules
sys.path.insert(0, str(Path(__file__).parent))

from reinforcement_engine import ReinforcementEngine, ReinforcementConfig
from survivor_scorer import SurvivorScorer

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Global data (loaded once per worker)
survivors = None
train_history = None
holdout_history = None
seeds_to_score = None


def load_data(survivors_file, train_history_file, holdout_history_file):
    """Load all necessary data from local paths."""
    global survivors, train_history, holdout_history, seeds_to_score

    if survivors is None:
        logger.info("Loading data (one time)...")
        try:
            # Expand ~ to user's home directory
            survivors_file = os.path.expanduser(survivors_file)
            train_history_file = os.path.expanduser(train_history_file)
            holdout_history_file = os.path.expanduser(holdout_history_file)

            with open(survivors_file) as f:
                survivors = json.load(f)

            with open(train_history_file) as f:
                train_data = json.load(f)
                if isinstance(train_data, list) and len(train_data) > 0 and isinstance(train_data[0], dict):
                    train_history = [d['draw'] for d in train_data]
                else:
                    train_history = train_data

            with open(holdout_history_file) as f:
                holdout_data = json.load(f)
                if isinstance(holdout_data, list) and len(holdout_data) > 0 and isinstance(holdout_data[0], dict):
                    holdout_history = [d['draw'] for d in holdout_data]
                else:
                    holdout_history = holdout_data

            # Pre-calculate seeds list
            # Handle both survivors.json (list of dicts) and chunk files (list of seeds)
            if isinstance(survivors, list) and len(survivors) > 0:
                if isinstance(survivors[0], dict):
                    seeds_to_score = [s.get('seed', s) for s in survivors]
                else:
                    # This handles the chunk files from Step 3.5
                    seeds_to_score = survivors
            else:
                 seeds_to_score = []


            logger.info(f"Loaded {len(seeds_to_score)} survivors/seeds from {survivors_file}.")
            logger.info(f"Loaded {len(train_history)} training draws from {train_history_file}.")
            logger.info(f"Loaded {len(holdout_history)} holdout draws from {holdout_history_file}.")

        except Exception as e:
            logger.error(f"Failed to load data: {e}", exc_info=True)
            raise

    # ✅ FIX: Return the loaded data!
    return seeds_to_score, train_history, holdout_history


def run_trial(seeds_to_score, train_history, holdout_history, params, trial=None):
    """
    Runs the full test and returns the accuracy score AND the full score list.
    NOW WITH OPTUNA PRUNING SUPPORT!

    Args:
        seeds_to_score: List of seed values
        train_history: Training lottery draws
        holdout_history: Holdout lottery draws
        params: Trial parameters dict
        trial: Optional Optuna trial object for pruning
        
    Returns:
        Tuple[float, List[float]]: (accuracy, holdout_scores)
    """
    try:
        # 1. Create config with trial parameters (using dataclass fields)
        from dataclasses import replace

        # Start with default config
        config = ReinforcementConfig()

        # Update with trial parameters
        config.training.update({
            'epochs': 25,
            'batch_size': params.get('batch_size', 128),
            'learning_rate': params.get('learning_rate', 0.001),
            'early_stopping_patience': 5
        })

        config.model.update({
            'hidden_layers': [int(x) for x in params.get('hidden_layers', '128_64').split('_')],
            'dropout': params.get('dropout', 0.3)
        })

        if hasattr(config, 'survivor_pool'):
            config.survivor_pool.update({
                'prune_threshold': 0.3,
                'cache_scores': True
            })

        logger.info("Initializing Mini-Run Engine...")
        engine = ReinforcementEngine(config, lottery_history=train_history)

        # 2. Override scorer with trial parameters
        trial_scorer_params = {
            'residue_mod_1': params.get('residue_mod_1', 10),
            'residue_mod_2': params.get('residue_mod_2', 100),
            'residue_mod_3': params.get('residue_mod_3', 1000),
            'max_offset': params.get('max_offset', 10),
            'temporal_window_size': params.get('temporal_window_size', 100),
            'temporal_num_windows': params.get('temporal_num_windows', 5),
            'min_confidence_threshold': params.get('min_confidence_threshold', 0.1)
        }

        engine.scorer = SurvivorScorer(
            prng_type='java_lcg',
            mod=1000,
            config_dict=trial_scorer_params
        )
        logger.info("  Survivor scorer: Using custom trial parameters!")

        # 3. Pre-calculate scores
        logger.info(f"Pre-calculating scores for {len(seeds_to_score)} seeds...")
        y_train = engine.scorer.batch_score(
            seeds=seeds_to_score,
            lottery_history=train_history,
            use_dual_gpu=False
        )
        # Extract just the score values from dict results
        y_train = [item["score"] if isinstance(item, dict) else item for item in y_train]

        # 4. Train WITH PRUNING CALLBACK
        logger.info("Starting mini-run training with pruning support...")
        start_train = time.time()

        # Define pruning callback for Optuna
        def pruning_callback(epoch: int, val_loss: float) -> bool:
            """
            Called after each epoch with validation loss.
            Returns True to continue, False to stop (prune).
            """
            # Only check every 2 epochs to reduce overhead
            if trial is not None and epoch % 2 == 0 and epoch >= 6:
                # Report negative MSE (higher is better for Optuna)
                trial.report(-val_loss, epoch)

                # Check if should prune
                if trial.should_prune():
                    logger.info(f"⚡ Trial pruned at epoch {epoch+1} (val_loss={val_loss:.6f})")
                    return False  # Stop training

            return True  # Continue training

        # Train with callback
        try:
            engine.train(
                survivors=seeds_to_score,
                actual_results=y_train,
                lottery_history=train_history,
                epoch_callback=pruning_callback if trial else None
            )
            train_time = time.time() - start_train
            logger.info(f"Training completed in {train_time:.1f}s")

        except Exception as e:
            # If callback raises exception, it might be a pruning signal
            if "pruned" in str(e).lower():
                raise optuna.exceptions.TrialPruned()
            else:
                raise

        # 5. Evaluate on holdout
        logger.info("Evaluating on holdout...")
        y_holdout = engine.scorer.batch_score(
            seeds=seeds_to_score,
            lottery_history=holdout_history,
            use_dual_gpu=False
        )
        # Extract just the score values from dict results
        y_holdout = [item["score"] if isinstance(item, dict) else item for item in y_holdout]

        y_pred_holdout = engine.predict_quality_batch(
            survivors=seeds_to_score,
            lottery_history=holdout_history
        )

        import torch
        holdout_mse = float(torch.nn.functional.mse_loss(
            torch.tensor(y_pred_holdout),
            torch.tensor(y_holdout)
        ))

        accuracy = -holdout_mse  # Negative MSE (higher is better)

        logger.info(f"Holdout MSE: {holdout_mse:.6f}, Accuracy (NegMSE): {accuracy:.6f}")
        
        # --- PATCH v3.1 ---
        # Return both accuracy and the full list of scores
        return accuracy, y_pred_holdout if isinstance(y_pred_holdout, list) else y_pred_holdout.tolist()

    except optuna.exceptions.TrialPruned:
        # Re-raise pruned exception (not an error)
        raise
    except Exception as e:
        logger.error(f"Trial execution failed: {e}", exc_info=True)
        raise


def save_local_result(trial_id: int, params: dict, accuracy: float, state: str, error: Optional[str], scores: Optional[list] = None):
    """Save trial result to local filesystem for coordinator to pull later."""
    # Create local results dir
    local_results_dir = Path.home() / "distributed_prng_analysis" / "scorer_trial_results"
    local_results_dir.mkdir(parents=True, exist_ok=True)

    output_file = local_results_dir / f"trial_{trial_id:04d}.json"

    result = {
        "trial_id": trial_id,
        "params": params,
        "accuracy": accuracy,
        "status": state,
        "error": error,
        "hostname": socket.gethostname(),
        "timestamp": time.time()
    }
    
    # --- PATCH v3.1 ---
    # Add the full scores list if it was provided
    if scores is not None:
        result['scores'] = scores

    with open(output_file, 'w') as f:
        json.dump(result, f, indent=2)

    logger.info(f"✅ Result saved locally to {output_file}")


def main():
    if len(sys.argv) < 6:
        print(__doc__)
        sys.exit(1)

    survivors_file = sys.argv[1]
    train_history_file = sys.argv[2]
    holdout_history_file = sys.argv[3]
    trial_id = int(sys.argv[4])
    params_json = sys.argv[5]

    # Optional Optuna connection for pruning
    study_name = None
    study_db = None
    if len(sys.argv) > 6 and sys.argv[6] == '--optuna-study-name':
        study_name = sys.argv[7]
        study_db = sys.argv[9] if len(sys.argv) > 9 and sys.argv[8] == '--optuna-study-db' else None

    hostname = socket.gethostname()
    logger.info(f"--- Scorer Trial Worker {trial_id} Starting on {hostname} ---")

    params = None # Define params here to be available in exception block
    scores = None # --- PATCH v3.1 ---

    try:
        params = json.loads(params_json)
        logger.info(f"Parameters: {params}")

        # Load data
        seeds, train_hist, holdout_hist = load_data(survivors_file, train_history_file, holdout_history_file)

        # Connect to Optuna study if provided (for pruning)
        trial = None
        #if study_name and study_db:
        #    try:
        #        study = optuna.load_study(study_name=study_name, storage=study_db)
        #        # Get the trial corresponding to this worker
        #        optuna_trial_num = params.get('optuna_trial_number')
        #        if optuna_trial_num is not None:
        #            # Create a trial handle for pruning
        #            trial = optuna.trial.Trial(study, optuna_trial_num) # Use Trial constructor
        #            logger.info(f"Connected to Optuna trial #{optuna_trial_num} for pruning")
        #    except Exception as e:
        #        logger.warning(f"Could not connect to Optuna for pruning: {e}")

        # Run trial with optional pruning
        # --- PATCH v3.1 ---
        accuracy, scores = run_trial(seeds, train_hist, holdout_hist, params, trial=trial)

        # Save result
        # --- PATCH v3.1 ---
        save_local_result(trial_id, params, accuracy, "success", None, scores=scores)

        print(json.dumps({"status": "success", "trial_id": trial_id, "accuracy": accuracy}))
        sys.exit(0)

    except optuna.exceptions.TrialPruned:
        logger.info(f"⚡ Trial {trial_id} was pruned (early stopped)")
        # --- PATCH v3.1 ---
        save_local_result(trial_id, params, float('-inf'), "pruned", "Trial pruned by Optuna", scores=None)
        print(json.dumps({"status": "pruned", "trial_id": trial_id}))
        sys.exit(0)

    except Exception as e:
        error_msg = str(e)
        logger.error(f"❌ Trial {trial_id} failed: {error_msg}", exc_info=True)
        if params is None: # Handle case where params failed to load
            params = {"error": "Failed to parse params_json"}
        # --- PATCH v3.1 ---
        save_local_result(trial_id, params, float('-inf'), "error", error_msg, scores=None)
        print(json.dumps({"status": "error", "trial_id": trial_id, "error": error_msg}))
        sys.exit(1)


if __name__ == "__main__":
    main()
