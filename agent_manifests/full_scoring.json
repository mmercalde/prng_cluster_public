{
  "agent_name": "full_scoring_agent",
  "description": "Step 3: Applies optimized scoring parameters from Step 2.5 to ALL survivors. Produces fully-scored survivor dataset for ML training.",
  "pipeline_step": 3,
  "version": "1.3.0",
  "feature_registry": "config_manifests/feature_registry.json",
  "inputs": [
    "bidirectional_survivors_binary.npz",
    "optimal_scorer_config.json",
    "lottery_file"
  ],
  "outputs": [
    "survivors_with_scores.json",
    "scoring_statistics.json"
  ],
  "actions": [
    {
      "type": "run_script",
      "script": "generate_full_scoring_jobs.py",
      "args_map": {
        "survivors": "survivors",
        "config": "config",
        "train-history": "train_history",
        "holdout-history": "holdout_history"
      },
      "distributed": false,
      "timeout_minutes": 10
    },
    {
      "type": "run_distributed",
      "script": "full_scoring_worker.py",
      "args_map": {
        "job-file": "job_file",
        "gpu-id": "gpu_id",
        "lottery-file": "lottery_file"
      },
      "distributed": true,
      "timeout_minutes": 180
    },
    {
      "type": "aggregate",
      "script": "aggregate_scoring_results.py",
      "args_map": {
        "input-dir": "scoring_output_dir",
        "output-file": "survivors_with_scores_file"
      },
      "distributed": false,
      "timeout_minutes": 30
    }
  ],
  "follow_up_agents": [
    "ml_meta_agent"
  ],
  "success_condition": [
    "survivors_with_scores.json"
  ],
  "retry": 2,
  "parameter_bounds": {
    "chunk_size": {
      "type": "int",
      "min": 500,
      "max": 20000,
      "default": 5000,
      "description": "Number of survivors per scoring job. Larger than Step 2.5 since using pre-optimized parameters.",
      "optimized_by": "Manual tuning",
      "effect": "Larger chunks improve throughput since parameters are fixed. Typical 2000-10000 for production."
    },
    "batch_size": {
      "type": "int",
      "min": 64,
      "max": 1024,
      "default": 256,
      "description": "GPU batch size for vectorized scoring operations.",
      "optimized_by": "Manual tuning",
      "effect": "Larger = faster but more VRAM. RX 6600 (8GB): use 256. RTX 3080 Ti (12GB): use 512."
    },
    "feature_extraction_depth": {
      "type": "int",
      "min": 46,
      "max": 128,
      "default": 64,
      "description": "Number of ML features to extract per survivor (46 base + skip mode features).",
      "optimized_by": "Manual tuning",
      "effect": "More features = richer ML input but slower extraction. 64 includes all skip mode features."
    },
    "score_precision": {
      "type": "int",
      "min": 4,
      "max": 8,
      "default": 6,
      "description": "Decimal precision for score storage.",
      "optimized_by": "Fixed",
      "effect": "6 decimals provides sufficient precision for ML ranking."
    },
    "parallel_workers": {
      "type": "int",
      "min": 1,
      "max": 26,
      "default": 26,
      "description": "Number of parallel GPU workers across cluster.",
      "optimized_by": "Hardware",
      "effect": "Use full cluster (26 GPUs) for maximum throughput."
    }
  },
  "success_metrics": {
    "min_scored_survivors": 100,
    "expected_scoring_rate": 0.99,
    "max_scoring_failures": 10
  },
  "default_params": {
    "survivors": "bidirectional_survivors_binary.npz",
    "config": "optimal_scorer_config.json",
    "train_history": "train_history.json",
    "holdout_history": "holdout_history.json",
    "chunk_size": 1000,
    "jobs_file": "scoring_jobs.json",
    "prng_type": "java_lcg",
    "mod": 1000,
    "batch_size": 100,
    "output_file": "survivors_with_scores.json"
  },
  "evaluation_params": {
    "confidence_formula": "bit_length",
    "confidence_base": 0.7,
    "confidence_divisor": 64.0,
    "confidence_cap": 0.95,
    "zero_scored_confidence": 0.5,
    "min_scored_survivors": 100
  },
  "evaluation_type": "file_exists",
  "disable_llm_parsing": true,
  "disable_heuristic_parsing": true,
  "retry_policy": "none",
  "_note_default_params": "Some default_params (prng_type, mod, batch_size, jobs_file, output_file) are included for documentation/future use but are not currently consumed by run_step3_full_scoring.sh. The shell script's tolerance mechanism logs 'Note: Ignoring unknown option' for these - this is expected behavior, not an error."
}