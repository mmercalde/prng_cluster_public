{
  "agent_name": "ml_meta_agent",
  "description": "Step 4: Capacity & Architecture Planning. Derives optimal training parameters (survivor pool size, network depth, epochs) from window optimizer behavior and lottery pattern complexity. INTENTIONALLY does NOT consume survivor-level data - that happens in Step 5.",
  "pipeline_step": 4,
  "version": "2.0.0",
  "design_note": "Step 4 is a CAPACITY PLANNER, not a data-aware optimizer. Model selection (neural_net/xgboost/lightgbm/catboost) happens in Step 5.",
  
  "inputs": [
    "optimal_window_config.json",
    "train_history.json"
  ],
  
  "outputs": [
    "reinforcement_engine_config.json",
    "optimization_results/meta_optimization_results.json"
  ],
  
  "actions": [
    {
      "type": "run_script",
      "script": "adaptive_meta_optimizer.py",
      "args_map": {
        "--mode": "full",
        "--window-results": "optimal_window_config.json",
        "--lottery-data": "train_history.json",
        "--apply": true
      },
      "distributed": false,
      "timeout_minutes": 10
    }
  ],
  
  "follow_up_agents": [
    "reinforcement_agent"
  ],
  
  "success_condition": "reinforcement_engine_config.json exists AND contains survivor_pool.max_pool_size",
  
  "retry": 1,
  
  "parameter_bounds": {
    "window_optimizer_weight": {
      "type": "float",
      "min": 0.4,
      "max": 0.8,
      "default": 0.6,
      "description": "Weight given to window optimizer results (PRIMARY source).",
      "effect": "Higher = more trust in sieve behavior analysis."
    },
    "historical_pattern_weight": {
      "type": "float",
      "min": 0.2,
      "max": 0.5,
      "default": 0.35,
      "description": "Weight given to lottery history pattern analysis (SECONDARY source).",
      "effect": "Higher = more trust in entropy/stability analysis."
    },
    "reinforcement_feedback_weight": {
      "type": "float",
      "min": 0.05,
      "max": 0.25,
      "default": 0.05,
      "description": "Weight given to reinforcement feedback (CONTINUOUS source, grows over time).",
      "effect": "Grows from 5% to 25% based on confidence in historical performance."
    },
    "survivor_count_min_multiplier": {
      "type": "float",
      "min": 0.3,
      "max": 0.7,
      "default": 0.5,
      "description": "Minimum survivor count as multiplier of optimal.",
      "effect": "Lower = allow smaller pools."
    },
    "survivor_count_max_multiplier": {
      "type": "float",
      "min": 1.5,
      "max": 3.0,
      "default": 2.0,
      "description": "Maximum survivor count as multiplier of optimal.",
      "effect": "Higher = allow larger pools."
    },
    "min_epochs": {
      "type": "int",
      "min": 20,
      "max": 100,
      "default": 50,
      "description": "Minimum training epochs.",
      "effect": "Lower bound for epoch estimation."
    },
    "max_epochs": {
      "type": "int",
      "min": 200,
      "max": 1000,
      "default": 500,
      "description": "Maximum training epochs.",
      "effect": "Upper bound for epoch estimation."
    }
  },
  
  "success_metrics": {
    "config_written": true,
    "survivor_count_reasonable": "survivor_count >= 100 AND survivor_count <= 10000",
    "epochs_reasonable": "training_epochs >= 50 AND training_epochs <= 500"
  },
  
  "default_params": {
    "window_results": "optimal_window_config.json",
    "lottery_data": "train_history.json",
    "mode": "full",
    "apply": true
  },
  
  "evaluation_params": {
    "confidence_source": "weighted_combination",
    "confidence_base": 0.7,
    "confidence_cap": 0.95
  },
  
  "what_step_4_does_NOT_do": [
    "Load survivors_with_scores.json (that's Step 5)",
    "Inspect holdout_hits (that's Step 5)",
    "Select model type (that's Step 5)",
    "Run Optuna trials on survivor data (that's Step 5)",
    "Perform any evaluation (that's Step 5)"
  ]
}
