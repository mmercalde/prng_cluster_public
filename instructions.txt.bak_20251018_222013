# Distributed PRNG Analysis System - Production Instructions

## System Overview
**Status: FULLY OPERATIONAL - 26 GPU Cluster (285.69 TFLOPS)**

A distributed pseudorandom number generator (PRNG) analysis system that uses GPU acceleration across multiple nodes to analyze lottery data patterns. The system automatically detects and optimizes for both NVIDIA (CUDA) and AMD (ROCm) hardware.

**NEW: Bidirectional Sieve Architecture** - Forward + Reverse PRNG analysis with ML fusion for adaptive pattern discovery.
## Data File Format Requirements

### Standard Input Format (daily3.json, test files)

All analysis requires JSON files with lottery draw data. The format varies slightly depending on analysis type:

#### Fixed Skip Sieve Format (Minimal)
```json
[
  {
    "draw": 134,
    "session": "midday",
    "timestamp": 5000000
  },
  {
    "draw": 840,
    "session": "midday", 
    "timestamp": 5000001
  }
]
```

**Required fields:**
- `draw` (integer 0-999): The lottery draw result
- `session` (string): "midday" or "evening" (can be any identifier)
- `timestamp` or `date` (integer/string): Temporal ordering

#### Hybrid Variable Skip Format (Same as Fixed)
```json
[
  {
    "draw": 994,
    "session": "midday",
    "timestamp": 5000000
  }
]
```

**Note:** Hybrid mode uses the SAME format as fixed skip. The only difference is you add `--hybrid` flag.

#### Multi-Modulo Validation Format (Advanced)
```json
[
  {
    "draw": 134,
    "full_state": 3234134,
    "session": "midday",
    "timestamp": 5000000
  }
]
```

**Additional field:**
- `full_state` (integer): Complete PRNG state value (not just mod 1000)

**When to use full_state:**
- For maximum confidence (triple modulo validation)
- When you have access to complete PRNG state
- Testing with synthetic data where full state is known

**When NOT needed:**
- Standard lottery data (only has draw values 0-999)
- Hybrid mode (works with draw values only)
- Most real-world scenarios

#### Quick Reference: What Format Do I Need?

| Analysis Type | Required Fields | Optional Fields |
|--------------|-----------------|-----------------|
| Fixed Skip Sieve | draw, session, timestamp | full_state |
| Hybrid Variable Skip | draw, session, timestamp | full_state |
| Reverse Sieve | draw, session, timestamp | full_state |
| Timestamp Search | draw, session, timestamp | - |

### Example: Creating Test Data

#### For Fixed Skip Testing
```bash
cat > test_simple.json << 'EOF'
[
  {"draw": 450, "session": "midday", "timestamp": 1000000},
  {"draw": 303, "session": "midday", "timestamp": 1000001},
  {"draw": 618, "session": "midday", "timestamp": 1000002}
]
EOF
```

#### For Hybrid Testing (Variable Skip)
```bash
# Use the create_xorshift32_hybrid_test.py script shown in Hybrid section
# It generates proper format automatically
python3 create_xorshift32_hybrid_test.py
```

### Common Format Mistakes

❌ **Wrong: Missing required fields**
```json
[
  {"draw": 134}  // Missing session and timestamp
]
```

❌ **Wrong: Incorrect data types**
```json
[
  {"draw": "134", "session": "midday", "timestamp": 5000000}  // draw should be int, not string
]
```

❌ **Wrong: Using date when timestamp expected**
```json
// Some modes expect timestamp (integer), check docs
[
  {"draw": 134, "session": "midday", "date": "2025-10-16"}  // Should use timestamp for most modes
]
```

✅ **Correct: All required fields, proper types**
```json
[
  {"draw": 134, "session": "midday", "timestamp": 5000000}
]
```
## Hardware Architecture
- **Zeus (Coordinator)**: 2x RTX 3080 Ti (CUDA)
- **rig-6600 (192.168.3.120)**: 12x RX 6600 (ROCm)
- **rig-6600b (192.168.3.154)**: 12x RX 6600 (ROCm)
- **Total**: 26 GPUs, ~285.69 TFLOPS computational power

## Core System Files

### Main Components
- `unified_system_working.py` - Primary interface with modular analysis options
- `coordinator.py` - Distributed job coordinator with SSH connection management
- `distributed_worker.py` - GPU worker script (runs on all nodes)
- `sieve_filter.py` - **NEW: GPU-accelerated forward/reverse sieve engine**
- `prng_registry.py` - **NEW: Multi-PRNG kernel library with forward + reverse implementations**
- `enhanced_gpu_model_id.py` - GPU-accelerated PRNG analysis engine
- `distributed_config.json` - Node configuration and connection settings
- `daily3.json` - Input lottery data

### Module System (modules/ directory)
- `direct_analysis.py` - Cluster analysis with parameter optimization
- `result_viewer.py` - Interactive result viewing and visualization
- `system_monitor.py` - Hardware monitoring and diagnostics
- `database_manager.py` - Database operations and job management
- `file_manager.py` - File operations and maintenance

## NEW: Multi-PRNG Bidirectional Sieve System

### Overview
**Status: PRODUCTION READY - Forward Sieve Verified on All 26 GPUs**

A universal PRNG analysis framework that simultaneously tests multiple PRNG families using bidirectional validation:
- **Forward Sieve**: Generate sequences from candidate seeds
- **Reverse Sieve**: Work backward from recent draws to find candidate seeds
- **Bidirectional Intersection**: High-confidence survivors that pass both directions
- **ML Fusion**: Adaptive weighting and PRNG family identification

### Supported PRNG Families

#### Fully Implemented (Forward + Reverse)
1. **xorshift32** - Fast XorShift variant (✅ VERIFIED: seed 42 found with 100% match)
2. **xorshift64** - 64-bit XorShift
3. **xorshift128** - 128-bit XorShift
4. **lcg32** - Linear Congruential Generator (MSVC variant)
5. **pcg32** - Permuted Congruential Generator
6. **mt19937** - Mersenne Twister (32-bit)
7. **splitmix64** - SplitMix64 algorithm

#### Key Features
- **Multi-modulo validation**: Tests state % 1000, % 8, % 125 for high confidence
- **Full 32-bit state support**: Handles complete PRNG state values
- **Configurable skip/offset**: Handles draw spacing and temporal alignment
- **GPU kernel compilation cache**: Automatic optimization per hardware

### Performance Benchmarks

#### Forward Sieve (Verified)
- **RTX 3080 Ti**: ~730 seeds/sec per GPU (with full state validation)
- **RX 6600**: ~730 seeds/sec per GPU (ROCm optimized)
- **Full cluster**: 26/26 jobs successful, 100K seeds in 47.2 seconds
- **Match accuracy**: 100% (seed 42 found with perfect 30/30 match)

#### Reverse Sieve (In Development)
- Expected performance: Similar to forward sieve
- Backward state propagation from most recent draws
- Exponential candidate elimination per step

### CLI Usage Examples

#### Basic Forward Sieve
```bash
# Test single PRNG family
python3 coordinator.py \
  test_seed42_first30.json \
  --method residue_sieve \
  --prng-type xorshift32 \
  --seeds 100000 \
  --offset 0

# Search larger seed space
python3 coordinator.py \
  daily3.json \
  --method residue_sieve \
  --prng-type mt19937 \
  --seeds 1000000 \
  --offset 15 \
  --skip-range 0 20
```

#### Multi-PRNG Ensemble Analysis (Coming Soon)
```bash
# Test all PRNG families simultaneously
python3 coordinator.py \
  daily3.json \
  --method ensemble_sieve \
  --prng-families xorshift32,mt19937,lcg32,pcg32 \
  --seeds 500000 \
  --bidirectional

# ML-guided PRNG identification
python3 coordinator.py \
  daily3.json \
  --method ml_fusion \
  --auto-detect-prng \
  --confidence-threshold 0.95
```

#### Bidirectional Validation (Coming Soon)
```bash
# Forward + Reverse intersection
python3 coordinator.py \
  daily3.json \
  --method bidirectional \
  --prng-type xorshift32 \
  --seeds 1000000 \
  --forward-window 30 \
  --reverse-window 30

# Adaptive drift detection
python3 coordinator.py \
  daily3.json \
  --method adaptive \
  --detect-reseeding \
  --temporal-validation
```

### Sieve Parameters Reference

#### Core Parameters
- `--method {residue_sieve,ensemble_sieve,bidirectional,ml_fusion}`: Analysis mode
- `--prng-type {xorshift32,mt19937,lcg32,pcg32,xorshift64,splitmix64}`: PRNG family
- `--prng-families LIST`: Multiple PRNGs for ensemble (comma-separated)
- `--seeds INT`: Total seed candidates to test across cluster
- `--offset INT`: Number of PRNG steps to skip before sequence (temporal alignment)
- `--skip-range MIN MAX`: Test multiple skip values (e.g., 0 20)

#### Validation Parameters
- `--window-size INT`: Number of draws to validate against (default: 30)
- `--min-match-threshold FLOAT`: Match rate threshold (0.0-1.0, default: 0.5)
- `--bidirectional`: Enable forward + reverse validation
- `--forward-window INT`: Forward sieve window size
- `--reverse-window INT`: Reverse sieve window size

#### ML Parameters (Coming Soon)
- `--auto-detect-prng`: Let ML identify PRNG family
- `--confidence-threshold FLOAT`: Minimum confidence for predictions
- `--learning-rate FLOAT`: RL adaptation rate
- `--ensemble-weights`: Custom PRNG weighting

### Understanding Multi-Modulo Validation

The sieve uses **three simultaneous modulo checks** for high confidence:

```python
# A seed survives only if ALL three match:
match = (state % 1000 == draw % 1000) AND  # The actual draw value
        (state % 8 == draw % 8) AND        # Low bits check
        (state % 125 == draw % 125)        # Mid bits check
```

**Why this matters:**
- Single mod 1000 match = ~0.1% false positive rate
- Triple validation = ~0.00001% false positive rate
- Effectively requires full 32-bit state match

**Data Requirements:**
- Dataset must include `full_state` field (not just `draw`)
- For testing: Use `create_synthetic_full_state.py` to generate test data
- For production: Capture full PRNG state values, not just mod 1000 outputs

### Creating Test Datasets

#### Synthetic Test Data (Known Seeds)
```bash
# Generate test data with known seed 42
cat > create_test_data.py << 'EOF'
import json

def xorshift32_step(state):
    x = state & 0xFFFFFFFF
    x ^= (x << 13) & 0xFFFFFFFF
    x ^= (x >> 17) & 0xFFFFFFFF
    x ^= (x << 5) & 0xFFFFFFFF
    return x & 0xFFFFFFFF

state = 42
draws = []
for i in range(100):
    state = xorshift32_step(state)
    draws.append({
        "date": f"2020-01-{i+1:02d}",
        "session": "midday",
        "draw": state % 1000,
        "full_state": int(state)  # Critical for multi-modulo validation
    })

with open('test_seed42_known.json', 'w') as f:
    json.dump(draws, f, indent=2)
EOF

python3 create_test_data.py

# Verify the sieve finds it
python3 coordinator.py \
  test_seed42_known.json \
  --method residue_sieve \
  --prng-type xorshift32 \
  --seeds 100000 \
  --offset 0

# Expected: Seed 42 found with 100% match rate
```

#### Multi-Session Test Data
```bash
# Generate data with separate midday/evening seeds
python3 create_synthetic_dataset.py \
  --seed-midday 42 \
  --seed-evening 1337 \
  --prng xorshift32 \
  --count 10000 \
  --skip 5 \
  --output synthetic_dual_session.json
```

### Result Interpretation

#### Survivor Output Format
```json
{
  "seed": 42,
  "family": "xorshift32",
  "match_rate": 1.0,
  "matches": 30,
  "total": 30,
  "best_skip": 0
}
```

**Key Metrics:**
- **match_rate**: Percentage of draws that matched (0.0-1.0)
- **matches/total**: Raw match count (e.g., 30/30 = perfect)
- **best_skip**: Optimal skip value found (temporal alignment)
- **seed**: The PRNG seed candidate

#### Confidence Levels
- **match_rate >= 0.95**: Extremely high confidence (likely correct seed)
- **match_rate 0.80-0.94**: High confidence (strong candidate)
- **match_rate 0.60-0.79**: Moderate confidence (needs validation)
- **match_rate < 0.60**: Low confidence (likely false positive)

#### Example Analysis Results
```bash
# Check results for seed 42
cat results/multi_gpu_analysis_*.json | python3 -c "
import sys, json
d = json.load(sys.stdin)
survivors = []
for r in d.get('results', []):
    survivors.extend(r.get('survivors', []))

seed_42 = [s for s in survivors if s.get('seed') == 42]
if seed_42:
    print('✅ SEED 42 FOUND!')
    print(f'Match rate: {seed_42[0][\"match_rate\"]}')
    print(f'Matches: {seed_42[0][\"matches\"]}/{seed_42[0][\"total\"]}')
"
```

## Legacy: Fast Congruence Residue Sieve

### Overview
**Status: SUPERSEDED by Multi-PRNG Sieve (above)**

Original fast residue filter for mod 1000 only. Still functional but replaced by more comprehensive multi-modulo validation system.

### Performance Benchmarks (Legacy)
- **RTX 3080 Ti**: 60,000-90,000 seeds/sec per GPU
- **RX 6600**: 10,000-20,000 seeds/sec per GPU
- **Full cluster**: 40/40 jobs successful, 100K seeds in 2.9 seconds

### Legacy CLI Usage
```bash
# Original residue sieve (mod 1000 only)
python3 coordinator.py --method residue_sieve --prng-type lcg32 --window-size 512 --k-sigma 6.0 --seeds 1000000 daily3.json -o results/sieve_test.json
```

**Note**: New code should use `--method residue_sieve` with multi-modulo validation instead.

## CRITICAL: ROCm Environment Setup - What NOT to Do

### ❌ DO NOT Use Shell Wrappers for AMD Nodes
**Wrong Approach**: Creating wrapper scripts like `run_worker_rocm.sh` and modifying `distributed_config.json` to use them.

**Why Wrong**: The coordinator already has built-in environment activation via `python_env` paths. Adding wrappers creates unnecessary complexity and can interfere with the proven job distribution system.

### ❌ DO NOT Modify Remote Command Execution
**Wrong Approach**: Changing the coordinator's SSH command construction or adding manual environment activation to commands.

**Why Wrong**: The coordinator automatically constructs proper activation commands based on `python_env` paths in `distributed_config.json`. The existing mechanism works reliably.

### ❌ DO NOT Set Environment Variables in Config File
**Wrong Approach**: Adding environment variables to `distributed_config.json` or trying to pass them through SSH commands.

**Why Wrong**: Environment variables must be set BEFORE any Python imports, which means they belong in the Python files themselves, not in configuration or command-line parameters.

### ✅ The Correct Approach (Proven Working Method)
1. **Use existing python_env mechanism**: Point AMD nodes to `/home/michael/rocm_env/bin/python` in config
2. **Set environment variables in Python files**: Add ROCm variables at the top of `distributed_worker.py`, `sieve_filter.py`, and `enhanced_gpu_model_id.py`
3. **Leverage proven infrastructure**: Use the established job data structure and routing logic
4. **Follow existing patterns**: Add new functionality using the same patterns as existing analysis modes

### Example of Correct ROCm Setup Pattern
```python
#!/usr/bin/env python3
# ROCm environment setup - MUST BE FIRST
import os, socket
HOST = socket.gethostname()

# Apply ROCm overrides for AMD systems
if HOST in ["rig-6600", "rig-6600b"]:
    os.environ.setdefault("HSA_OVERRIDE_GFX_VERSION", "10.3.0")
    os.environ.setdefault("HSA_ENABLE_SDMA", "0")

# ROCm paths
os.environ.setdefault("ROCM_PATH", "/opt/rocm")
os.environ.setdefault("HIP_PATH", "/opt/rocm")

# AFTER environment setup, import GPU libraries
import cupy as cp
```

**Critical Files Requiring ROCm Prelude:**
- `distributed_worker.py` ✅
- `sieve_filter.py` ✅ 
- `enhanced_gpu_model_id.py` ✅

## Common Integration Mistakes and Solutions

### Issue: "Python integer out of bounds for uint16"
**Cause**: Old kernel code using `unsigned short* residues` (16-bit) instead of `unsigned int*` (32-bit)
**Solution**: All kernels in `prng_registry.py` now use `unsigned int* residues` for full state support

### Issue: "Connection reset by peer (104)" on AMD Nodes
**Cause**: New functionality not following established job data patterns
**Solution**: Use existing job_data structure, don't create custom communication protocols

### Issue: Seed Not Found Despite Perfect Manual Match
**Cause**: Missing offset parameter or incorrect data format
**Solution**: 
- Verify dataset includes `full_state` field (not just `draw`)
- Calculate correct offset (e.g., last 30 of 100 draws needs offset=70)
- Check sieve uses `entry.get('full_state', entry['draw'])` in data loading

### Issue: Zero Match Rate for Known Seeds
**Cause**: Data type mismatch between Python and GPU kernel
**Solution**: Verify `residues_gpu = cp.array(residues, dtype=cp.uint32)` not uint16

### Key Lesson
The system now supports full 32-bit PRNG state analysis with multi-modulo validation. Always ensure:
1. Dataset contains `full_state` values
2. Kernels use `unsigned int*` for residues
3. Correct offset calculation for temporal alignment
4. ROCm environment variables set before any GPU imports

## Quick Start Guide

### Starting the System
```bash
# Activate your GPU environment (tf or torch)
source ~/venvs/tf/bin/activate  # or torch

# Launch unified interface
python3 unified_system_working.py

# Test all 26 GPUs
# Select: Direct Analysis → System Connectivity Test
# Expected: All nodes show "GPUs available"
```

### Basic Analysis Workflow
```bash
# 1. Test sieve with known seed (verification)
python3 coordinator.py \
  test_seed42_first30.json \
  --method residue_sieve \
  --prng-type xorshift32 \
  --seeds 100000 \
  --offset 0

# Expected: Seed 42 found with 100% match rate in ~47 seconds

# 2. Multi-PRNG ensemble search (production)
python3 coordinator.py \
  daily3.json \
  --method residue_sieve \
  --prng-type mt19937 \
  --seeds 1000000 \
  --offset 15

# 3. Standard correlation analysis (legacy)
python3 unified_system_working.py
# Select: Direct Analysis → Standard Analysis → General correlation analysis → y
# Expected: 25/25 jobs successful across all 26 GPUs
```

## Critical GPU Setup Requirements

### NVIDIA Nodes (Zeus - localhost)
**Environment**: Any Python environment with CUDA-compatible CuPy
```bash
# Verify CUDA CuPy installation
python3 -c "import cupy; print('CUDA CuPy:', cupy.__version__)"
# Expected output: CUDA CuPy: 13.5.1 (or similar)

# Test local GPU workers
echo '{"job_id":"test","seeds":[1],"prng_type":"xorshift","samples":1000}' > test.json
python3 distributed_worker.py test.json --gpu-id 0
# Expected: "Job test completed successfully"

# NEW: Test sieve functionality
python3 sieve_filter.py --job-file test_job.json --gpu-id 0
# Expected: JSON output with survivor results
```

### AMD Nodes (Both rig-6600 systems)
**Critical Requirement**: ROCm environment variables must be set BEFORE any GPU imports.

**File Requirements**: All GPU-intensive files must contain ROCm prelude:

```python
#!/usr/bin/env python3

# ROCm environment setup - MUST BE FIRST
import os, socket
HOST = socket.gethostname()

# Apply ROCm overrides for AMD systems
if HOST in ["rig-6600", "rig-6600b"]:
    os.environ.setdefault("HSA_OVERRIDE_GFX_VERSION", "10.3.0")
    os.environ.setdefault("HSA_ENABLE_SDMA", "0")

# ROCm paths
os.environ.setdefault("ROCM_PATH", "/opt/rocm")
os.environ.setdefault("HIP_PATH", "/opt/rocm")

# AFTER environment setup, import GPU libraries
import cupy as cp
# ... rest of imports
```

**Files Requiring ROCm Prelude:**
- ✅ `distributed_worker.py`
- ✅ `sieve_filter.py`
- ✅ `enhanced_gpu_model_id.py`

**Test AMD nodes**:
```bash
# Test rig-6600
ssh 192.168.3.120 'source ~/rocm_env/bin/activate && cd distributed_prng_analysis && python3 -c "import cupy; print(cupy.cuda.runtime.getDeviceCount())"'
# Expected: 12

# Test rig-6600b
ssh 192.168.3.154 'source ~/rocm_env/bin/activate && cd distributed_prng_analysis && python3 -c "import cupy; print(cupy.cuda.runtime.getDeviceCount())"'
# Expected: 12

# NEW: Test sieve on AMD nodes
ssh 192.168.3.120 'source ~/rocm_env/bin/activate && cd distributed_prng_analysis && python3 sieve_filter.py --job-file test_job.json --gpu-id 0'
# Expected: JSON output with results
```

## Configuration File Setup

### distributed_config.json
```json
{
  "nodes": [
    {
      "hostname": "localhost",
      "username": "michael",
      "gpu_count": 2,
      "gpu_type": "RTX 3080 Ti",
      "script_path": "/home/michael/distributed_prng_analysis",
      "python_env": "/home/michael/venvs/tf/bin/python"
    },
    {
      "hostname": "192.168.3.120",
      "username": "michael",
      "gpu_count": 12,
      "gpu_type": "RX 6600",
      "script_path": "/home/michael/distributed_prng_analysis",
      "python_env": "/home/michael/rocm_env/bin/python",
      "password": "your_password"
    },
    {
      "hostname": "192.168.3.154",
      "username": "michael",
      "gpu_count": 12,
      "gpu_type": "RX 6600",
      "script_path": "/home/michael/distributed_prng_analysis",
      "python_env": "/home/michael/rocm_env/bin/python",
      "password": "your_password"
    }
  ]
}
```

**Key Points**:
- `python_env` must point to Python executable in the correct virtual environment
- `script_path` must contain all system files on each node including `sieve_filter.py` and `prng_registry.py`
- Passwords stored in plain text - consider SSH keys for security
- All nodes must have identical versions of `sieve_filter.py` and `prng_registry.py`

## Analysis Types and Parameters

### Quick Test (Connectivity Verification)
- **Purpose**: Verify all 26 GPUs respond correctly
- **Parameters**: 1,000 seeds, 1,000 samples, light correlation
- **Runtime**: 30-60 seconds
- **Command**: Direct Analysis → Quick Test Analysis

### NEW: Sieve Analysis (Production Mode)
- **Quick sieve test**: 100K seeds, 30 window (47 seconds) - Verification
- **Standard sieve**: 1M seeds, 30 window (7 minutes) - Production
- **Deep sieve**: 10M seeds, 30 window (70 minutes) - Comprehensive search
- **Multi-PRNG ensemble**: Test all families simultaneously
- **Purpose**: Find PRNG seeds with high-confidence bidirectional validation

### Standard Analysis (Legacy)
- **General correlation**: 50K seeds, 10K samples, correlation lag 32
- **Pattern matching**: 25K seeds, 20K samples, optimized for recent patterns
- **Randomness testing**: 100K seeds, 5K samples, comprehensive statistical tests
- **Runtime**: 5-15 minutes across full cluster

### Comprehensive Analysis
- **Deep correlation**: 200K seeds, 50K samples, correlation lag 128
- **Multi-target search**: Automated lottery number targeting
- **Historical reconstruction**: 300K seeds, extensive temporal analysis
- **Runtime**: 30-120 minutes utilizing full 285.69 TFLOPS

### Draw Matching (Number Search)
- **Quick search**: 10K seeds (30 seconds)
- **Standard search**: 100K seeds (2-5 minutes)
- **Deep search**: 500K seeds (10-20 minutes)
- **Purpose**: Find PRNG seeds that generate specific lottery numbers

## Command Line Usage

### NEW: Multi-PRNG Sieve Operations
```bash
# Test known seed (verification)
python3 coordinator.py \
  test_seed42_first30.json \
  --method residue_sieve \
  --prng-type xorshift32 \
  --seeds 100000 \
  --offset 0

# Production analysis on real data
python3 coordinator.py \
  daily3.json \
  --method residue_sieve \
  --prng-type mt19937 \
  --seeds 1000000 \
  --offset 15 \
  --skip-range 0 20 \
  --min-match-threshold 0.8

# Multi-PRNG ensemble (coming soon)
python3 coordinator.py \
  daily3.json \
  --method ensemble_sieve \
  --prng-families xorshift32,mt19937,lcg32,pcg32 \
  --seeds 500000 \
  --bidirectional
```

### Basic Cluster Analysis (Legacy)
```bash
# Test connectivity across all nodes
python3 coordinator.py daily3.json -c distributed_config.json --test-only

# Multi-PRNG analysis (legacy correlation mode)
python3 coordinator.py daily3.json -c distributed_config.json -s 50000 -n 10000
```

### Advanced Parameters

#### Sieve-Specific
- `--method {residue_sieve,ensemble_sieve,bidirectional}`: Sieve operation mode
- `--prng-type {xorshift32,mt19937,lcg32,pcg32,xorshift64,splitmix64}`: PRNG family
- `--prng-families LIST`: Multiple PRNGs for ensemble testing
- `--seeds INT`: Total seed candidates across cluster
- `--offset INT`: Temporal alignment (PRNG steps to skip)
- `--skip-range MIN MAX`: Test multiple skip values
- `--min-match-threshold FLOAT`: Survivor threshold (0.0-1.0)
- `--window-size INT`: Number of draws to validate (default: 30)
- `--bidirectional`: Enable forward + reverse validation

#### Legacy Correlation
- `-s, --seeds`: Total seeds across all nodes (higher = more statistical confidence)
- `-n, --samples`: Samples per seed (higher = better accuracy per seed)
- `--lmax`: Maximum correlation lag (32-128 typical)
- `--grid-size`: Grid for 2D analysis (8-16 typical)
- `--draw-match N`: Search for seeds producing number N (0-999)

## Troubleshooting Guide

### GPU Detection Issues

#### NVIDIA Problems
```bash
# Check CUDA installation
nvidia-smi
python3 -c "import cupy; print(cupy.cuda.runtime.getDeviceCount())"

# Common fix: Update CuPy
pip install --upgrade cupy-cuda12x
```

#### AMD ROCm Problems
```bash
# Check ROCm installation
rocm-smi --showid
# Should show 12 GPUs on each AMD node

# Verify environment variables in ALL worker files
grep -n "HSA_OVERRIDE_GFX_VERSION" distributed_worker.py sieve_filter.py enhanced_gpu_model_id.py
# Should find the environment setup code in ALL three files

# Test ROCm CuPy
ssh 192.168.3.120 'source ~/rocm_env/bin/activate && python3 -c "import cupy; print(\"Working\")"'
```

#### Common GPU Errors and Solutions

**"No module named 'cupy'"**
```bash
# Check virtual environment activation
# Coordinator uses python_env path from config file
# Verify config points to environment with CuPy installed
```

**"Python integer X out of bounds for uint16"**
```bash
# FIXED: All kernels now use unsigned int* (32-bit)
# If error persists, verify prng_registry.py has been updated:
grep "unsigned int\* residues" prng_registry.py
# Should show multiple matches, NOT "unsigned short* residues"
```

**"radix_sort: failed on 2nd step"**
```bash
# Clear CuPy cache (often resolves kernel compilation issues)
rm -rf ~/.cache/cupy
ssh 192.168.3.120 "rm -rf ~/.cache/cupy"
ssh 192.168.3.154 "rm -rf ~/.cache/cupy"
```

**"Module not initialized" (AMD only)**
```bash
# Verify HSA_OVERRIDE_GFX_VERSION=10.3.0 is set BEFORE cupy import
# Check ALL three files: distributed_worker.py, sieve_filter.py, enhanced_gpu_model_id.py
# Environment variables must be at the very top of files
```

**"name 'offset' is not defined"**
```bash
# Ensure sieve_filter.py run_sieve() function signature includes offset parameter
# Should be: def run_sieve(..., chunk_size: int = 1_000_000, offset: int = 0)
```

**"get_kernel_info() takes 1 positional argument but 2 were given"**
```bash
# FIXED: Updated sieve_filter.py to call get_kernel_info(prng_family) without custom_params
# If error persists, check line ~93 in sieve_filter.py
```

**"Connection reset by peer (104)" (AMD only)**
```bash
# Usually indicates new functionality not following established patterns
# Check job_data structure matches existing job types
# Verify ROCm environment prelude is present in ALL GPU-intensive files
```

**"Local execution failed (rc=1)"**
```bash
# Test worker directly to see full error
echo '{"job_id":"debug","seeds":[1]}' > debug.json
python3 distributed_worker.py debug.json --gpu-id 0
# Look for syntax errors, missing imports, or environment issues

# NEW: Test sieve directly
python3 sieve_filter.py --job-file debug_sieve.json --gpu-id 0
```

### Sieve-Specific Issues

**"Seed found manually but not by sieve"**
```bash
# Common causes:
# 1. Incorrect offset calculation
#    - Last 30 of 100 draws needs offset=70, not offset=0
# 2. Missing full_state in dataset
#    - Dataset must have "full_state" field for multi-modulo validation
# 3. Wrong skip parameter
#    - Try --skip-range 0 20 to test multiple skip values
```

**"Zero survivors despite patterns"**
```bash
# Check dataset format
python3 -c "
import json
with open('your_data.json') as f:
    d = json.load(f)
    print('Has full_state:', 'full_state' in d[0] if d else False)
"

# Verify data loading
grep "get.*full_state" sieve_filter.py
# Should show: entry.get('full_state', entry['draw'])
```

**"Match rate always 0.0"**
```bash
# Verify kernel parameter passing
# Check sieve_filter.py lines ~150-160 for:
# - kernel_args.append(cp.uint32(shift_a))
# - kernel_args.append(cp.uint32(shift_b))
# - kernel_args.append(cp.uint32(shift_c))
# - kernel_args.append(cp.int32(offset))  # Must be LAST
```

### Network and SSH Issues

#### Connection Problems
```bash
# Test SSH connectivity
ssh user@192.168.3.120 "echo 'Connection working'"
ssh user@192.168.3.154 "echo 'Connection working'"

# Check SSH key setup (recommended over passwords)
ssh-keygen -t rsa
ssh-copy-id user@192.168.3.120
ssh-copy-id user@192.168.3.154
```

#### File Synchronization
```bash
# Ensure all nodes have identical files (CRITICAL for sieve functionality)
scp sieve_filter.py prng_registry.py distributed_worker.py 192.168.3.120:/home/michael/distributed_prng_analysis/
scp sieve_filter.py prng_registry.py distributed_worker.py 192.168.3.154:/home/michael/distributed_prng_analysis/

# Verify file integrity
sha256sum sieve_filter.py prng_registry.py
ssh 192.168.3.120 "cd distributed_prng_analysis && sha256sum sieve_filter.py prng_registry.py"
ssh 192.168.3.154 "cd distributed_prng_analysis && sha256sum sieve_filter.py prng_registry.py"
# Checksums should match across all nodes

## NEW: Timestamp-Based PRNG Seed Search

### Overview
**Status: PRODUCTION READY - Fully Verified on All 26 GPUs**

Searches for Unix timestamp seeds by testing millions of candidate timestamps to see if any generate matching lottery draw sequences.

### Key Features
- Tests 800M+ timestamps in ~50 seconds
- Skip/gap detection (0-100 gaps)
- Multiple PRNG families: MT19937, xorshift32, pcg32, lcg32, xorshift64
- Verified: 100% match on synthetic test (seed 1706817600, skip 5)
- Full MT19937 with 624-word state

### Basic Usage

Search for timestamp seeds:
  python3 timestamp_search.py daily3.json --mode second --window 512 --threshold 0.15 --prngs mt19937 --skip-max 100

Create test data:
  python3 create_test_mt19937.py

Verify system works:
  python3 timestamp_search.py test_mt19937_512.json --mode second --window 512 --threshold 0.8 --prngs mt19937 --skip-max 10

### Timestamp Modes
- second: 800M timestamps, 1-second resolution (RECOMMENDED)
- millisecond: 800B timestamps, 0.001-second resolution (slower)
- minute: Per-minute timestamps (faster, lower precision)

### System Verification
- Seed 1706817600 found with 100% match (512/512 draws)
- Skip value 5 detected correctly
- All 26 GPUs working

### Performance
- Throughput: 1.56 billion seeds/second
- Runtime: ~50 seconds for 800M timestamps
- Memory: 2.5 KB per MT19937 state

### Deploy to Remote Nodes
  scp prng_registry.py timestamp_search.py coordinator.py sieve_filter.py michael@192.168.3.120:~/distributed_prng_analysis/
  scp prng_registry.py timestamp_search.py coordinator.py sieve_filter.py michael@192.168.3.154:~/distributed_prng_analysis/

## NEW: Hybrid Variable Skip Detection (October 16, 2025)

### Overview
**Status: PRODUCTION READY - Verified on All 26 GPUs**

Advanced PRNG analysis that detects **variable skip patterns** (non-constant gaps between draws) using multi-strategy hybrid kernels. Unlike fixed-skip sieves that assume constant gaps, hybrid mode can discover complex, changing skip patterns.

### Supported Hybrid PRNGs
1. **mt19937_hybrid** - Two-phase MT19937 (fixed skip → variable skip refinement)
2. **xorshift32_hybrid** - Single-phase Xorshift32 with multi-strategy detection ✅ NEW
3. **pcg32_hybrid** - Coming soon
4. **lcg32_hybrid** - Coming soon
5. **xorshift64_hybrid** - Coming soon

### Key Features
- **Multi-strategy detection**: Tests 5 different skip pattern strategies simultaneously
- **Variable skip patterns**: Handles patterns like [5,5,3,7,5,5,8,4,5,5] (changing gaps)
- **Single-phase & two-phase modes**: Optimized per PRNG family
- **100% match accuracy**: Verified with seed 54321, 670 draws, variable pattern
- **Forward + Reverse validation**: Bidirectional confidence (reverse implementation in progress)

### How It Works

**Traditional Fixed Skip (Existing Sieves)**:
```
Draws:  [D1] --5--> [D2] --5--> [D3] --5--> [D4]
        Constant gap of 5 between every draw
```

**Hybrid Variable Skip (NEW)**:
```
Draws:  [D1] --5--> [D2] --3--> [D3] --7--> [D4] --5--> [D5]
        Variable gaps: 5, then 3, then 7, then 5...
```

**Detection Strategy**:
- Uses 5 strategies with different tolerance levels
- Each strategy has:
  - `max_consecutive_misses`: How many gaps can be wrong
  - `skip_tolerance`: ±N range for skip detection
  - `match_threshold`: Minimum % of draws that must match

### CLI Usage Examples

#### Test Xorshift32 Hybrid (Verification)
```bash
# Create test data with variable skip pattern
cat > create_xorshift32_hybrid_test.py << 'PYEOF'
import json
from prng_registry import xorshift32_cpu

seed = 54321
base_pattern = [5,5,3,7,5,5,8,4,5,5]
skip_pattern = base_pattern * 67  # 670 draws

total_needed = sum(skip_pattern) + len(skip_pattern)
all_outputs = xorshift32_cpu(seed, total_needed, skip=0)

draws = []
idx = 0
for skip in skip_pattern:
    idx += skip
    draws.append(all_outputs[idx] % 1000)
    idx += 1

test_data = [{'draw': d, 'session': 'midday', 'timestamp': 5000000 + i} 
             for i, d in enumerate(draws)]

with open('test_xorshift32_hybrid.json', 'w') as f:
    json.dump(test_data, f)
    
print(f"Created test_xorshift32_hybrid.json: {len(draws)} draws")
print(f"Expected seed: {seed}")
print(f"Variable pattern: {base_pattern}")
PYEOF

python3 create_xorshift32_hybrid_test.py

# Run hybrid sieve
python3 coordinator.py \
  test_xorshift32_hybrid.json \
  --method residue_sieve \
  --prng-type xorshift32_hybrid \
  --seeds 100000 \
  --window-size 512 \
  --threshold 0.50 \
  --hybrid

# Expected output:
# ✅ Seed 54321 found
# Match rate: 100.0%
# Pattern detected: [5, 5, 3, 7, 5, 5, 8, 4, 5, 5]
```

#### Test MT19937 Hybrid (Two-Phase)
```bash
# MT19937 uses two-phase approach:
# Phase 1: Fixed-skip wide search (threshold 0.01)
# Phase 2: Variable-skip refinement on survivors (threshold 0.50)

python3 coordinator.py \
  test_known.json \
  --method residue_sieve \
  --prng-type mt19937 \
  --seeds 100000 \
  --window-size 10 \
  --threshold 0.01 \
  --hybrid \
  --phase1-threshold 0.01 \
  --phase2-threshold 0.50

# Phase 1 finds candidates with fixed skip
# Phase 2 validates variable skip patterns
```

#### Production Analysis with Hybrid
```bash
# Search real lottery data for variable skip patterns
python3 coordinator.py \
  daily3.json \
  --method residue_sieve \
  --prng-type xorshift32_hybrid \
  --seeds 1000000 \
  --window-size 100 \
  --threshold 0.50 \
  --hybrid \
  --offset 0

# Will test 1M seeds across 26 GPUs
# Detects variable skip patterns automatically
```

### Parameter Reference (Hybrid-Specific)

#### Core Hybrid Parameters
- `--hybrid`: Enable hybrid variable skip detection mode (REQUIRED for *_hybrid PRNGs)
- `--phase1-threshold FLOAT`: Phase 1 threshold for two-phase PRNGs (default: 0.01)
- `--phase2-threshold FLOAT`: Phase 2 threshold for all hybrid modes (default: 0.50)
- `--threshold FLOAT`: Overall match threshold (0.5-0.8 typical for hybrid)

#### Standard Parameters (Apply to Hybrid Too)
- `--prng-type {xorshift32_hybrid,mt19937_hybrid}`: PRNG family
- `--seeds INT`: Total seed candidates to test across cluster
- `--window-size INT`: Number of draws to validate against
- `--offset INT`: Temporal alignment (PRNG steps to skip before sequence)
- `--skip-min INT`: Minimum skip value in pattern (default: 0)
- `--skip-max INT`: Maximum skip value in pattern (default: 16)

#### Strategy Parameters (Advanced - Built-in)
Hybrid mode uses 5 built-in strategies from `hybrid_strategy.py`:

1. **Strict Continuous**
   - `max_consecutive_misses: 3`
   - `skip_tolerance: 5`
   - Best for: Tight, consistent patterns

2. **Lenient Continuous**
   - `max_consecutive_misses: 10`
   - `skip_tolerance: 20`
   - Best for: Loose, variable patterns

3. **Aggressive Reseed**
   - `max_consecutive_misses: 5`
   - `skip_tolerance: 5`
   - `enable_reseed_search: True`
   - Best for: Patterns with potential reseeding

4. **Balanced Hybrid** (Recommended)
   - `max_consecutive_misses: 7`
   - `skip_tolerance: 10`
   - Best for: General-purpose detection

5. **Extreme Tolerance**
   - `max_consecutive_misses: 20`
   - `skip_tolerance: 50`
   - Best for: Catching everything, high false positives

### Result Interpretation

#### Fixed Skip Output (Existing)
```json
{
  "seed": 12345,
  "family": "xorshift32",
  "match_rate": 1.0,
  "matches": 100,
  "total": 100,
  "best_skip": 5
}
```

#### Hybrid Variable Skip Output (NEW)
```json
{
  "seed": 54321,
  "family": "xorshift32_hybrid",
  "match_rate": 1.0,
  "matches": 670,
  "total": 670,
  "skip_pattern": [5, 5, 3, 7, 5, 5, 8, 4, 5, 5, 5, 5, 3, 7, ...],
  "strategy_used": "Balanced Hybrid",
  "pattern_stats": {
    "mean_skip": 5.4,
    "variance": 2.1,
    "std_dev": 1.45
  }
}
```

**Key Differences**:
- `skip_pattern`: Array of detected skip values (not single `best_skip`)
- `strategy_used`: Which detection strategy found the match
- `pattern_stats`: Statistical analysis of skip pattern

### Performance Benchmarks

#### Xorshift32 Hybrid (Single-Phase)
- **RTX 3080 Ti**: ~1,200 seeds/sec per GPU
- **RX 6600**: ~1,200 seeds/sec per GPU  
- **Full cluster**: 100K seeds in ~3-4 seconds
- **Match accuracy**: 100% on variable patterns
- **Memory**: ~512 KB per GPU (strategy state tracking)

#### MT19937 Hybrid (Two-Phase)
- **Phase 1** (fixed): ~60K seeds/sec per GPU
- **Phase 2** (variable): ~1K seeds/sec per GPU
- **Full cluster**: 100K seeds Phase 1 in ~2s, survivors Phase 2 in ~5s
- **False positive rate**: <0.01% after two-phase validation
- **Memory**: ~2.5 MB per GPU (MT19937 state + strategy tracking)

### Comparison: Fixed vs Hybrid

| Feature | Fixed Skip | Hybrid Variable Skip |
|---------|-----------|---------------------|
| **Speed** | 60K seeds/sec | 1.2K seeds/sec |
| **Pattern Type** | Constant gaps | Variable gaps |
| **Strategies** | 1 (simple match) | 5 (multi-strategy) |
| **Memory** | Minimal | Moderate |
| **Best For** | Simple RNGs | Complex systems |
| **False Positives** | Very low | Very low |

### Troubleshooting Hybrid Mode

#### "0 strategies loaded" Error
```bash
# Check if hybrid_strategy module exists
ls -lh hybrid_strategy.py

# Verify it can be imported
python3 -c "from hybrid_strategy import get_all_strategies; print('OK')"

# Deploy to remote nodes if missing
scp hybrid_strategy.py 192.168.3.120:~/distributed_prng_analysis/
scp hybrid_strategy.py 192.168.3.154:~/distributed_prng_analysis/
```

#### "CUDA_ERROR_INVALID_VALUE: invalid argument"
```bash
# Usually means kernel parameters are mismatched
# Hybrid kernels need additional parameters

# Verify sieve_filter.py passes correct args for hybrid:
grep -A 20 "xorshift32_hybrid" prng_registry.py

# Should show kernel signature with:
# - unsigned int* seeds
# - unsigned int* residues
# - ... other params ...
# - float threshold
# - int shift_a, shift_b, shift_c
# - int offset (MUST BE LAST)
```

#### "Seed found in direct test but not by coordinator"
```bash
# Most common: Test data not deployed to remote nodes
for host in 192.168.3.120 192.168.3.154; do
    ssh $host "ls -lh ~/distributed_prng_analysis/test_*.json"
done

# Copy missing test files
scp test_xorshift32_hybrid.json test_xorshift32_const_skip5.json \
    192.168.3.120:~/distributed_prng_analysis/
scp test_xorshift32_hybrid.json test_xorshift32_const_skip5.json \
    192.168.3.154:~/distributed_prng_analysis/
```

#### "Hybrid mode only supports mt19937_hybrid"
```bash
# OLD ERROR - FIXED in latest code
# This error means you're running old sieve_filter.py

# Check if code checks metadata, not hardcoded PRNG name
grep "variable_skip" sieve_filter.py
# Should show: family_config.get('variable_skip', False)

# NOT: if family_name == 'mt19937':

# Redeploy latest code if needed
scp sieve_filter.py 192.168.3.120:~/distributed_prng_analysis/
scp sieve_filter.py 192.168.3.154:~/distributed_prng_analysis/
```

#### "IndentationError" in sieve_filter.py
```bash
# Can happen after patching hybrid support
# Verify Python syntax
python3 -m py_compile sieve_filter.py

# If error, check lines around 490-510 for proper indentation
# The elif block for two-phase must be properly indented
```

### Deployment Checklist for Hybrid

Before running hybrid analysis across cluster:

#### 1. Deploy Core Files
```bash
# All nodes need these files for hybrid to work
for host in 192.168.3.120 192.168.3.154; do
    scp prng_registry.py sieve_filter.py hybrid_strategy.py coordinator.py \
        reverse_sieve_filter.py $host:~/distributed_prng_analysis/
done
```

#### 2. Deploy Test Data (If Testing)
```bash
for host in 192.168.3.120 192.168.3.154; do
    scp test_*.json $host:~/distributed_prng_analysis/
done
```

#### 3. Verify File Timestamps Match
```bash
# Check local vs remote timestamps
ls -lh sieve_filter.py prng_registry.py hybrid_strategy.py

# Check remote nodes
ssh 192.168.3.120 "ls -lh ~/distributed_prng_analysis/{sieve_filter,prng_registry,hybrid_strategy}.py"
ssh 192.168.3.154 "ls -lh ~/distributed_prng_analysis/{sieve_filter,prng_registry,hybrid_strategy}.py"

# Timestamps should match (or remote should be newer)
```

#### 4. Verify Checksums
```bash
# Generate checksums locally
sha256sum sieve_filter.py prng_registry.py hybrid_strategy.py

# Compare with remote nodes
ssh 192.168.3.120 "cd ~/distributed_prng_analysis && sha256sum sieve_filter.py prng_registry.py hybrid_strategy.py"
ssh 192.168.3.154 "cd ~/distributed_prng_analysis && sha256sum sieve_filter.py prng_registry.py hybrid_strategy.py"

# ALL checksums must match exactly
```

#### 5. Test on Single GPU First
```bash
# Before running full cluster, test one GPU
python3 coordinator.py \
  test_xorshift32_hybrid.json \
  --method residue_sieve \
  --prng-type xorshift32_hybrid \
  --seeds 10000 \
  --threshold 0.50 \
  --hybrid

# Verify seed 54321 found with 100% match
# Only then scale to full cluster
```

### Verified Test Results (October 16, 2025)

**Test 1: MT19937 Constant Skip** ✅
- File: test_known.json (10 draws)
- Seed: 54321, Skip: 1
- Result: Found with 10.0% match rate
- Worker: 192.168.3.154 GPU0 (RX 6600)
- Status: PASSED

**Test 2: Xorshift32 Constant Skip** ✅  
- File: test_xorshift32_const_skip5.json (100 draws)
- Seed: 12345, Skip: 5
- Result: Found with 100.0% match rate
- Worker: 192.168.3.120 GPU1 (RX 6600)
- Status: PASSED

**Test 3: Xorshift32 Variable Skip (Hybrid)** ✅
- File: test_xorshift32_hybrid_dist.json (670 draws)
- Seed: 54321, Pattern: [5,5,3,7,5,5,8,4,5,5]
- Result: Found with 100.0% match rate, pattern detected correctly
- Worker: 192.168.3.154 GPU0 (RX 6600)
- Runtime: 0.98s
- Status: PASSED

All tests passed on distributed cluster (26 GPUs across 3 nodes).

### Backup Procedures (Hybrid Release)

#### In-Place Backups
```bash
# Creates .bak_TIMESTAMP files next to originals
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Local backups
for file in prng_registry.py sieve_filter.py coordinator.py hybrid_strategy.py reverse_sieve_filter.py; do
    [ -f "$file" ] && cp "$file" "${file}.bak_${TIMESTAMP}"
done

# Remote backups
for host in 192.168.3.120 192.168.3.154; do
    ssh $host "cd ~/distributed_prng_analysis && \
        for file in prng_registry.py sieve_filter.py hybrid_strategy.py reverse_sieve_filter.py; do \
            [ -f \"\$file\" ] && cp \"\$file\" \"\${file}.bak_${TIMESTAMP}\"; \
        done"
done

echo "✅ Backups complete: .bak_${TIMESTAMP}"
```

#### Restore from Backup
```bash
# List available backups
ls -lt *.bak_* | head -10

# Restore specific file
TIMESTAMP=20251016_192844
cp sieve_filter.py.bak_${TIMESTAMP} sieve_filter.py

# Restore to remote nodes
for host in 192.168.3.120 192.168.3.154; do
    scp sieve_filter.py.bak_${TIMESTAMP} $host:~/distributed_prng_analysis/sieve_filter.py
done
```

**Last Verified Backup**: `.bak_20251016_192844`

### Architecture Notes: Single-Phase vs Two-Phase

#### Single-Phase Hybrid (xorshift32_hybrid)
- PRNG name already has `_hybrid` suffix
- Directly calls `run_hybrid_sieve()` with multi-strategy detection
- No Phase 1 filtering required
- Best for: PRNGs with fast variable skip kernels

```python
# Automatic detection in sieve_filter.py
if family_name.endswith('_hybrid'):
    # Single-phase: Direct hybrid sieve
    result = sieve.run_hybrid_sieve(
        prng_family=family_name,
        seed_start=seed_start,
        seed_end=seed_end,
        residues=draws,
        strategies=strategies,
        min_match_threshold=phase2_threshold,
        offset=offset
    )
```

#### Two-Phase Hybrid (mt19937)
- Base name `mt19937` without `_hybrid` suffix
- Phase 1: Fixed skip wide search (fast, filters to ~1% survivors)
- Phase 2: Variable skip validation on survivors (thorough)
- Best for: Complex PRNGs where fixed-skip filtering helps

```python
# Automatic detection in sieve_filter.py
elif family_config.get('multi_strategy', False):
    # Two-phase approach
    # Phase 1: Fixed skip
    phase1_result = sieve.run_sieve(
        prng_family='mt19937',
        ...
        min_match_threshold=phase1_threshold  # Low threshold
    )
    
    # Phase 2: Variable skip on survivors
    phase2_result = sieve.run_hybrid_sieve(
        prng_family='mt19937_hybrid',
        ...
        min_match_threshold=phase2_threshold  # High threshold
    )
```

### When to Use Hybrid Mode

#### Use Hybrid If:
- ✅ Skip patterns are **not constant** (varies between draws)
- ✅ Standard fixed-skip sieve finds **no survivors**
- ✅ You suspect **adaptive or dynamic** draw spacing
- ✅ Testing **real-world RNG implementations** (often have variable timing)
- ✅ Need to detect **reseeding events** in sequence

#### Use Fixed Skip If:
- ✅ Skip patterns are **constant** (same gap every time)
- ✅ Need **maximum speed** (60K seeds/sec vs 1.2K seeds/sec)
- ✅ Testing **simple PRNGs** with predictable behavior
- ✅ Working with **synthetic test data** with known constant skip
- ✅ First-pass **wide search** before hybrid refinement

### Future Hybrid PRNGs (Coming Soon)

**pcg32_hybrid** - PCG with variable skip
**lcg32_hybrid** - LCG with variable skip
**xorshift64_hybrid** - 64-bit xorshift with variable skip

All will follow the single-phase architecture pattern (like xorshift32_hybrid).

---

**Hybrid Variable Skip System Version**: 2.0
**Status**: Production Ready
**Last Updated**: October 16, 2025
**Verified On**: 26 GPUs (2x RTX 3080 Ti, 24x RX 6600)
