{
  "sources": {
    "window_optimizer_results": {
      "path": "optimal_window_config.json",
      "weight": 0.6,
      "required": true,
      "description": "PRIMARY SOURCE - Empirical survivor counts from window optimization"
    },
    "lottery_history": {
      "path": "lottery_data.json",
      "weight": 0.35,
      "required": true,
      "description": "SECONDARY SOURCE - Historical pattern characteristics"
    },
    "reinforcement_feedback": {
      "weight": 0.05,
      "max_weight": 0.25,
      "growth_rate": "confidence_based",
      "description": "CONTINUOUS SOURCE - Performance feedback (grows from 5% to 25%)"
    }
  },
  "modes": {
    "initialization": true,
    "continuous": true,
    "regime_response": true
  },
  "optimization": {
    "survivor_count": {
      "derive_from": [
        "window_optimizer",
        "historical_patterns"
      ],
      "min_multiplier": 0.5,
      "max_multiplier": 2.0,
      "step": "logarithmic",
      "description": "Survivor count derived from multiple weighted sources"
    },
    "network_architecture": {
      "search_space": "adaptive",
      "options": [
        [
          32
        ],
        [
          64,
          32
        ],
        [
          128,
          64,
          32
        ],
        [
          256,
          128,
          64
        ]
      ],
      "selection_criteria": [
        "training_stability",
        "prediction_variance"
      ],
      "description": "Network architecture selection based on complexity vs performance"
    },
    "training_epochs": {
      "derive_from": "convergence_analysis",
      "min": 50,
      "max": 500,
      "adaptive": true,
      "description": "Epochs based on convergence speed from window optimizer"
    }
  },
  "continuous_optimization": {
    "enabled": true,
    "adjustment_threshold": 0.05,
    "feedback_window": 100,
    "adjustment_frequency": "per_epoch",
    "min_confidence": 0.7,
    "description": "Micro-adjustments triggered by performance changes >5%"
  },
  "regime_change": {
    "detection_source": "global_state_tracker",
    "trigger_full_recalibration": true,
    "preserve_history": true,
    "fallback_to_last_stable": true,
    "validation_period": 50,
    "description": "Full re-optimization on regime changes detected by GlobalStateTracker"
  },
  "output": {
    "target_file": "reinforcement_engine_config.json",
    "update_strategy": "merge_preserving_user_overrides",
    "backup_previous": true,
    "validation": true,
    "results_dir": "optimization_results",
    "history_file": "meta_optimization_history.json",
    "description": "Output configuration compatible with reinforcement_engine.py"
  }
}