#!/usr/bin/env python3
"""
Survivor Scorer Module - Complete ML/AI Compatible Architecture

DESIGN PRINCIPLES:
‚úÖ Modular - Drop-in replacement for any PRNG system
‚úÖ ML/AI Ready - Returns ALL features for whitepaper strategy
‚úÖ CLI & Frontend Compatible - Can be imported or run standalone
‚úÖ No Hardcoded Values - All parameters configurable
‚úÖ Rolling Window Support - For temporal analysis
‚úÖ Gap-Tolerant - Handles partial reconstruction
‚úÖ Percentage-Based Scoring - 0-100% scale for rankings

WHITEPAPER FEATURES IMPLEMENTED:
‚úÖ Survivor overlap ratios (forward vs. reverse)
‚úÖ Skip entropy and residue coherence (%8, %125, %1000)
‚úÖ Temporal stability and survivor velocity
‚úÖ Intersection weight and lane agreement metrics
‚úÖ Forward/Reverse bidirectional analysis
‚úÖ Continuous reinforcement learning support

INTEGRATION:
- Compatible with prng_registry.py (44 PRNGs)
- Works with database_manager.py
- Exports for ml_fusion.py training
- Supports coordinator.py jobs

USAGE:
    # Module:
    from survivor_scorer import SurvivorScorer
    scorer = SurvivorScorer()
    results = scorer.score_survivor(seed=12345, lottery_history=[...])

    # ML Features:
    features = scorer.extract_ml_features(seed, history)

    # CLI:
    python survivor_scorer.py --seed 12345 --lottery-data daily3.json
"""

import sys
import os
import json
import argparse
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional, Any, Union, Tuple
from datetime import datetime
from collections import Counter
from scipy.stats import entropy

try:
    import cupy as cp
    GPU_AVAILABLE = True
except ImportError:
    cp = np
    GPU_AVAILABLE = False


class SurvivorScorer:
    """
    Complete ML/AI-ready survivor scorer with all whitepaper features

    Implements:
    - Bidirectional scoring (forward/reverse)
    - Residue coherence analysis (%8, %125, %1000)
    - Skip entropy calculation
    - Temporal stability metrics
    - Survivor velocity tracking
    - Intersection weights
    - Lane agreement analysis
    """

    def __init__(
        self,
        prng_type: str = 'java_lcg',
        mod: int = 1000,
        residue_mods: List[int] = None
    ):
        """
        Initialize scorer with full ML capabilities

        Args:
            prng_type: PRNG type from prng_registry (e.g., 'java_lcg', 'mt19937')
            mod: Modulo value for lottery (default 1000 for Pick 3)
            residue_mods: List of residue modulos for coherence analysis
        """
        self.prng_type = prng_type
        self.mod = mod
        self.residue_mods = residue_mods or [8, 125, 1000]
        self.prng_func = self._get_prng_function(prng_type)

    def _get_prng_function(self, prng_type: str):
        """Get PRNG function from prng_registry"""
        try:
            from prng_registry import get_cpu_reference
            return get_cpu_reference(prng_type)
        except ImportError:
            raise ImportError(
                "prng_registry.py not found. Please ensure it's in the same directory."
            )
        except Exception as e:
            raise ValueError(f"Failed to load PRNG '{prng_type}': {e}")

    def score_survivor(
        self,
        seed: int,
        lottery_history: List[int],
        max_draws: Optional[int] = None,
        skip: int = 0,
        offset_search: bool = True,
        max_offset: int = 5,
        direction: str = 'forward'
    ) -> Dict[str, Any]:
        """
        Score a survivor seed against lottery history with full ML features

        Args:
            seed: PRNG seed to test
            lottery_history: List of actual lottery draws
            max_draws: Maximum predictions to generate (default: len(lottery_history))
            skip: Skip value for PRNG
            offset_search: Search for best offset alignment
            max_offset: Maximum offset to search
            direction: 'forward' or 'reverse' for bidirectional analysis

        Returns:
            Dictionary with score, matches, confidence, and ALL ML features
        """
        if max_draws is None:
            max_draws = len(lottery_history)

        # Generate predictions using the PRNG
        predictions = self._generate_predictions(seed, max_draws, skip)

        if not predictions:
            return self._empty_result()

        # Find best offset if enabled
        best_offset = 0
        best_matches = 0

        if offset_search:
            for offset in range(-max_offset, max_offset + 1):
                matches = self._count_matches(predictions, lottery_history, offset)
                if matches > best_matches:
                    best_matches = matches
                    best_offset = offset
        else:
            best_matches = self._count_matches(predictions, lottery_history, 0)

        # Calculate metrics
        total_predictions = min(len(predictions), len(lottery_history))
        score = (best_matches / total_predictions * 100) if total_predictions > 0 else 0.0
        confidence = min(best_matches, 100)

        # Get aligned predictions and actuals
        aligned_preds, aligned_actuals = self._align_sequences(
            predictions, lottery_history, best_offset
        )

        return {
            'score': score,
            'exact_matches': best_matches,
            'total_predictions': total_predictions,
            'confidence': confidence,
            'best_offset': best_offset,
            'seed': seed,
            'prng_type': self.prng_type,
            'direction': direction,
            'details': {
                'predictions': aligned_preds,
                'actuals': aligned_actuals,
                'skip': skip,
                'all_predictions': predictions
            }
        }

    def _generate_predictions(self, seed: int, n: int, skip: int = 0) -> List[int]:
        """Generate predictions from PRNG"""
        try:
            raw_outputs = self.prng_func(seed, n, skip)
            predictions = [val % self.mod for val in raw_outputs]
            return predictions
        except Exception as e:
            print(f"Error generating predictions: {e}")
            return []

    def _count_matches(
        self,
        predictions: List[int],
        actuals: List[int],
        offset: int
    ) -> int:
        """Count exact matches with offset"""
        matches = 0

        if offset >= 0:
            pred_start = offset
            actual_start = 0
        else:
            pred_start = 0
            actual_start = -offset

        compare_len = min(
            len(predictions) - pred_start,
            len(actuals) - actual_start
        )

        for i in range(compare_len):
            if predictions[pred_start + i] == actuals[actual_start + i]:
                matches += 1

        return matches

    def _align_sequences(
        self,
        predictions: List[int],
        actuals: List[int],
        offset: int
    ) -> Tuple[List[int], List[int]]:
        """Align prediction and actual sequences based on offset"""
        if offset >= 0:
            aligned_preds = predictions[offset:]
            aligned_actuals = actuals[:len(aligned_preds)]
        else:
            aligned_preds = predictions[:len(actuals) + offset]
            aligned_actuals = actuals[-offset:]

        min_len = min(len(aligned_preds), len(aligned_actuals))
        return aligned_preds[:min_len], aligned_actuals[:min_len]

    def _empty_result(self) -> Dict[str, Any]:
        """Return empty result structure"""
        return {
            'score': 0.0,
            'exact_matches': 0,
            'total_predictions': 0,
            'confidence': 0,
            'best_offset': 0,
            'seed': 0,
            'prng_type': self.prng_type,
            'direction': 'forward',
            'details': {
                'predictions': [],
                'actuals': [],
                'skip': 0,
                'all_predictions': []
            }
        }
    # ==================== DUAL-SIEVE INTEGRATION (WHITEPAPER) ====================

    def calculate_survivor_overlap_ratio(
        self,
        forward_survivors: List[int],
        reverse_survivors: List[int]
    ) -> Dict[str, Any]:
        """
        Calculate survivor overlap ratios (forward vs. reverse)
        
        This is a KEY whitepaper metric: measures agreement between
        forward and reverse sieve survivors. High overlap = high confidence.
        
        Args:
            forward_survivors: Seeds from forward sieve
            reverse_survivors: Seeds from reverse sieve
            
        Returns:
            Dictionary with overlap metrics including Jaccard index
        """
        if not forward_survivors or not reverse_survivors:
            return {
                'overlap_ratio': 0.0,
                'intersection_count': 0,
                'union_count': 0,
                'forward_only': 0,
                'reverse_only': 0,
                'jaccard_index': 0.0
            }
        
        forward_set = set(forward_survivors)
        reverse_set = set(reverse_survivors)
        
        intersection = forward_set & reverse_set
        union = forward_set | reverse_set
        forward_only = forward_set - reverse_set
        reverse_only = reverse_set - forward_set
        
        # Jaccard index: |A ‚à© B| / |A ‚à™ B|
        jaccard = len(intersection) / len(union) if len(union) > 0 else 0.0
        
        return {
            'overlap_ratio': jaccard,
            'intersection_count': len(intersection),
            'union_count': len(union),
            'forward_only': len(forward_only),
            'reverse_only': len(reverse_only),
            'jaccard_index': float(jaccard),
            'intersection_seeds': list(intersection)
        }

    def compute_dual_sieve_intersection(
        self,
        forward_survivors: List[int],
        reverse_survivors: List[int]
    ) -> List[int]:
        """
        Compute intersection of forward and reverse survivors
        
        These are the HIGHEST confidence seeds - they survived BOTH sieves.
        This is the core of the dual-sieve reinforcement strategy.
        
        Args:
            forward_survivors: Seeds from forward sieve
            reverse_survivors: Seeds from reverse sieve
            
        Returns:
            List of seeds in intersection (sorted by seed value)
        """
        if not forward_survivors or not reverse_survivors:
            return []
        
        intersection = set(forward_survivors) & set(reverse_survivors)
        return sorted(list(intersection))

    def validate_bidirectional_consistency(
        self,
        seed: int,
        lottery_history: List[int],
        skip: int = 0,
        tolerance: float = 0.1
    ) -> Dict[str, Any]:
        """
        Validate bidirectional consistency for a seed
        
        Checks if seed performs well in BOTH forward and reverse directions.
        This validates the dual-sieve hypothesis from the whitepaper.
        
        Args:
            seed: Seed to validate
            lottery_history: Actual lottery draws
            skip: Skip value for PRNG
            tolerance: Minimum score threshold for consistency
            
        Returns:
            Dictionary with forward/reverse scores and consistency flag
        """
        # Score in forward direction
        forward_result = self.score_survivor(
            seed, lottery_history, skip=skip, direction='forward'
        )
        
        # Score in reverse direction (from end of history)
        reverse_history = list(reversed(lottery_history))
        reverse_result = self.score_survivor(
            seed, reverse_history, skip=skip, direction='reverse'
        )
        
        # Check consistency
        forward_score = forward_result['score']
        reverse_score = reverse_result['score']
        
        is_consistent = (
            forward_score >= tolerance and 
            reverse_score >= tolerance and
            abs(forward_score - reverse_score) < 50.0  # Not too divergent
        )
        
        avg_score = (forward_score + reverse_score) / 2.0
        score_diff = abs(forward_score - reverse_score)
        
        return {
            'seed': seed,
            'forward_score': forward_score,
            'reverse_score': reverse_score,
            'avg_score': avg_score,
            'score_difference': score_diff,
            'is_bidirectionally_consistent': is_consistent,
            'forward_matches': forward_result['exact_matches'],
            'reverse_matches': reverse_result['exact_matches'],
            'consistency_confidence': min(forward_score, reverse_score)
        }

    def score_with_dual_sieve(
        self,
        seed: int,
        lottery_history: List[int],
        forward_survivors: Optional[List[int]] = None,
        reverse_survivors: Optional[List[int]] = None,
        skip: int = 0
    ) -> Dict[str, Any]:
        """
        Score a seed using DUAL-SIEVE methodology
        
        Combines forward and reverse analysis for enhanced confidence.
        This implements the whitepaper's bidirectional validation strategy.
        
        Args:
            seed: Seed to score
            lottery_history: Actual lottery draws
            forward_survivors: Optional forward sieve survivors
            reverse_survivors: Optional reverse sieve survivors
            skip: Skip value
            
        Returns:
            Enhanced scoring with dual-sieve metrics
        """
        # Get basic forward score
        forward_result = self.score_survivor(seed, lottery_history, skip=skip)
        
        # Check bidirectional consistency
        consistency = self.validate_bidirectional_consistency(
            seed, lottery_history, skip=skip
        )
        
        # Calculate intersection bonus if survivor lists provided
        intersection_bonus = 0.0
        in_intersection = False
        
        if forward_survivors and reverse_survivors:
            intersection = set(forward_survivors) & set(reverse_survivors)
            in_intersection = seed in intersection
            
            if in_intersection:
                # Bonus for being in dual-sieve intersection
                overlap_metrics = self.calculate_survivor_overlap_ratio(
                    forward_survivors, reverse_survivors
                )
                intersection_bonus = 10.0 * overlap_metrics['jaccard_index']
        
        # Compute dual-sieve score
        base_score = forward_result['score']
        dual_score = base_score + intersection_bonus
        
        # Enhanced confidence based on bidirectional consistency
        enhanced_confidence = (
            consistency['consistency_confidence'] * 
            (1.5 if in_intersection else 1.0)
        )
        
        return {
            **forward_result,
            'dual_sieve_score': dual_score,
            'base_score': base_score,
            'intersection_bonus': intersection_bonus,
            'in_intersection': in_intersection,
            'bidirectional_consistent': consistency['is_bidirectionally_consistent'],
            'forward_score': consistency['forward_score'],
            'reverse_score': consistency['reverse_score'],
            'score_difference': consistency['score_difference'],
            'enhanced_confidence': enhanced_confidence
        }

    def build_prediction_pool(
        self,
        survivors: List[int],
        lottery_history: List[int],
        pool_size: int = 10,
        skip: int = 0,
        use_dual_scoring: bool = True,
        forward_survivors: Optional[List[int]] = None,
        reverse_survivors: Optional[List[int]] = None
    ) -> Dict[str, Any]:
        """
        Build high-quality prediction pool from survivors
        
        Creates compact, high-confidence prediction sets by ranking survivors
        and selecting top-K. This is used by the reinforcement engine.
        
        Args:
            survivors: List of survivor seeds
            lottery_history: Actual lottery draws
            pool_size: Number of top survivors to include
            skip: Skip value
            use_dual_scoring: Use dual-sieve scoring if True
            forward_survivors: Forward sieve survivors (for dual scoring)
            reverse_survivors: Reverse sieve survivors (for dual scoring)
            
        Returns:
            Dictionary with ranked pool and predictions
        """
        if not survivors:
            return {
                'pool': [],
                'pool_size': 0,
                'predictions': [],
                'avg_confidence': 0.0,
                'method': 'none'
            }
        
        # Score all survivors
        scored_survivors = []
        
        for seed in survivors:
            if use_dual_scoring and forward_survivors and reverse_survivors:
                result = self.score_with_dual_sieve(
                    seed, lottery_history, 
                    forward_survivors, reverse_survivors,
                    skip=skip
                )
                score_key = 'dual_sieve_score'
            else:
                result = self.score_survivor(seed, lottery_history, skip=skip)
                score_key = 'score'
            
            scored_survivors.append({
                'seed': seed,
                'score': result[score_key],
                'confidence': result.get('enhanced_confidence', result['confidence']),
                'matches': result['exact_matches']
            })
        
        # Sort by score (descending)
        scored_survivors.sort(key=lambda x: x['score'], reverse=True)
        
        # Take top K
        top_survivors = scored_survivors[:pool_size]
        
        # Generate predictions from top survivors
        predictions = []
        for survivor in top_survivors:
            pred = self._generate_predictions(
                survivor['seed'], 
                len(lottery_history) + 1,  # +1 for next draw
                skip
            )
            if pred:
                predictions.append({
                    'seed': survivor['seed'],
                    'next_prediction': pred[-1],  # Next draw prediction
                    'confidence': survivor['confidence']
                })
        
        # Calculate average confidence
        avg_confidence = (
            np.mean([s['confidence'] for s in top_survivors])
            if top_survivors else 0.0
        )
        
        return {
            'pool': top_survivors,
            'pool_size': len(top_survivors),
            'predictions': predictions,
            'avg_confidence': float(avg_confidence),
            'method': 'dual_sieve' if use_dual_scoring else 'forward_only',
            'all_scored_survivors': scored_survivors
        }

    def rank_by_dual_confidence(
        self,
        survivors: List[int],
        lottery_history: List[int],
        forward_survivors: Optional[List[int]] = None,
        reverse_survivors: Optional[List[int]] = None,
        skip: int = 0
    ) -> List[Dict[str, Any]]:
        """
        Rank survivors by dual-sieve confidence
        
        Prioritizes seeds that:
        1. Survive both forward and reverse sieves
        2. Have high bidirectional consistency
        3. Show strong pattern matching
        
        Args:
            survivors: Seeds to rank
            lottery_history: Actual lottery draws
            forward_survivors: Forward sieve survivors
            reverse_survivors: Reverse sieve survivors
            skip: Skip value
            
        Returns:
            List of ranked survivors with confidence scores
        """
        if not survivors:
            return []
        
        ranked = []
        
        for seed in survivors:
            result = self.score_with_dual_sieve(
                seed, lottery_history,
                forward_survivors, reverse_survivors,
                skip=skip
            )
            
            # Calculate composite confidence
            composite_confidence = (
                result['enhanced_confidence'] * 0.5 +
                result['dual_sieve_score'] * 0.3 +
                (100.0 if result['in_intersection'] else 0.0) * 0.2
            )
            
            ranked.append({
                'seed': seed,
                'dual_confidence': composite_confidence,
                'dual_score': result['dual_sieve_score'],
                'enhanced_confidence': result['enhanced_confidence'],
                'in_intersection': result['in_intersection'],
                'bidirectional_consistent': result['bidirectional_consistent'],
                'forward_score': result['forward_score'],
                'reverse_score': result['reverse_score']
            })
        
        # Sort by dual confidence (descending)
        ranked.sort(key=lambda x: x['dual_confidence'], reverse=True)
        
        return ranked

    # ==================== WHITEPAPER ML FEATURES ====================

    def extract_ml_features(
        self,
        seed: int,
        lottery_history: List[int],
        forward_survivors: Optional[List[int]] = None,
        reverse_survivors: Optional[List[int]] = None,
        skip_values: Optional[List[int]] = None,
        **kwargs
    ) -> Dict[str, float]:
        """
        Extract ALL ML features required by whitepaper strategy

        Features extracted:
        1. Basic scoring metrics
        2. Residue coherence (%8, %125, %1000)
        3. Skip entropy
        4. Temporal stability
        5. Survivor velocity
        6. Intersection weights (forward/reverse overlap)
        7. Lane agreement metrics

        Args:
            seed: PRNG seed
            lottery_history: Actual lottery draws
            forward_survivors: List of forward sieve survivors (optional)
            reverse_survivors: List of reverse sieve survivors (optional)
            skip_values: List of skip values to analyze (optional)
            **kwargs: Additional args

        Returns:
            Dictionary of ALL numerical features for ML training
        """
        result = self.score_survivor(seed, lottery_history, **kwargs)

        predictions = result['details']['all_predictions']
        actuals = result['details']['actuals']

        if not predictions or not actuals:
            return self._empty_ml_features()

        # 1. Basic scoring metrics
        basic_features = {
            'score': result['score'],
            'exact_matches': result['exact_matches'],
            'total_predictions': result['total_predictions'],
            'confidence': result['confidence'],
            'best_offset': result['best_offset'],
        }

        # 2. Residue coherence analysis
        residue_features = self._calculate_residue_coherence(predictions, actuals)

        # 3. Skip entropy
        skip_features = self._calculate_skip_entropy(predictions, skip_values)

        # 4. Temporal stability
        temporal_features = self._calculate_temporal_stability(
            seed, lottery_history, **kwargs
        )

        # 5. Survivor velocity
        velocity_features = self._calculate_survivor_velocity(predictions, actuals)

        # 6. Intersection weights
        intersection_features = self._calculate_intersection_weights(
            seed, forward_survivors, reverse_survivors
        )

        # 7. Lane agreement metrics
        lane_features = self._calculate_lane_agreement(predictions, actuals)

        # 8. Statistical features
        stat_features = self._calculate_statistical_features(predictions, actuals)

        # Combine all features
        all_features = {
            **basic_features,
            **residue_features,
            **skip_features,
            **temporal_features,
            **velocity_features,
            **intersection_features,
            **lane_features,
            **stat_features
        }

        return all_features

    def _calculate_residue_coherence(
        self,
        predictions: List[int],
        actuals: List[int]
    ) -> Dict[str, float]:
        """Calculate residue coherence for %8, %125, %1000"""
        features = {}

        for mod_val in self.residue_mods:
            pred_residues = [p % mod_val for p in predictions]
            actual_residues = [a % mod_val for a in actuals[:len(pred_residues)]]

            residue_matches = sum(
                1 for p, a in zip(pred_residues, actual_residues) if p == a
            )
            match_rate = residue_matches / len(pred_residues) if pred_residues else 0.0

            pred_dist = self._get_distribution(pred_residues, mod_val)
            actual_dist = self._get_distribution(actual_residues, mod_val)
            kl_div = self._kl_divergence(pred_dist, actual_dist)

            features[f'residue_{mod_val}_match_rate'] = match_rate
            features[f'residue_{mod_val}_kl_divergence'] = kl_div
            features[f'residue_{mod_val}_coherence'] = match_rate * (1 / (1 + kl_div))

        return features

    def _calculate_skip_entropy(
        self,
        predictions: List[int],
        skip_values: Optional[List[int]] = None
    ) -> Dict[str, float]:
        """Calculate skip entropy - measures variability in skip patterns"""
        if skip_values is None or len(skip_values) == 0:
            gaps = [predictions[i+1] - predictions[i] for i in range(len(predictions)-1)]
            skip_values = gaps

        if not skip_values:
            return {
                'skip_entropy': 0.0,
                'skip_mean': 0.0,
                'skip_std': 0.0,
                'skip_range': 0
            }

        skip_abs = [abs(s) for s in skip_values]
        skip_entropy_val = entropy(self._get_distribution(skip_abs, max(skip_abs) + 1))

        return {
            'skip_entropy': float(skip_entropy_val),
            'skip_mean': float(np.mean(skip_abs)),
            'skip_std': float(np.std(skip_abs)),
            'skip_range': int(max(skip_abs) - min(skip_abs)) if skip_abs else 0
        }

    def _calculate_temporal_stability(
        self,
        seed: int,
        lottery_history: List[int],
        window_size: int = 50,
        stride: int = 10,
        **kwargs
    ) -> Dict[str, float]:
        """Calculate temporal stability"""
        if len(lottery_history) < window_size:
            return {
                'temporal_stability_mean': 0.0,
                'temporal_stability_std': 0.0,
                'temporal_stability_trend': 0.0,
                'temporal_stability_min': 0.0,
                'temporal_stability_max': 0.0
            }

        window_scores = []

        for start in range(0, len(lottery_history) - window_size + 1, stride):
            window_history = lottery_history[start:start + window_size]
            result = self.score_survivor(seed, window_history, max_draws=window_size)
            window_scores.append(result['score'])

        if not window_scores:
            return {
                'temporal_stability_mean': 0.0,
                'temporal_stability_std': 0.0,
                'temporal_stability_trend': 0.0,
                'temporal_stability_min': 0.0,
                'temporal_stability_max': 0.0
            }

        x = np.arange(len(window_scores))
        y = np.array(window_scores)
        trend = np.polyfit(x, y, 1)[0] if len(x) > 1 else 0.0

        return {
            'temporal_stability_mean': float(np.mean(window_scores)),
            'temporal_stability_std': float(np.std(window_scores)),
            'temporal_stability_trend': float(trend),
            'temporal_stability_min': float(np.min(window_scores)),
            'temporal_stability_max': float(np.max(window_scores))
        }

    def _calculate_survivor_velocity(
        self,
        predictions: List[int],
        actuals: List[int]
    ) -> Dict[str, float]:
        """Calculate survivor velocity"""
        if len(predictions) < 10 or len(actuals) < 10:
            return {
                'survivor_velocity': 0.0,
                'velocity_acceleration': 0.0
            }

        chunk_size = max(10, len(predictions) // 10)
        chunk_accuracies = []

        for i in range(0, len(predictions) - chunk_size + 1, chunk_size):
            pred_chunk = predictions[i:i+chunk_size]
            actual_chunk = actuals[i:i+chunk_size] if i+chunk_size <= len(actuals) else actuals[i:]

            if len(pred_chunk) == len(actual_chunk):
                matches = sum(1 for p, a in zip(pred_chunk, actual_chunk) if p == a)
                accuracy = matches / len(pred_chunk)
                chunk_accuracies.append(accuracy)

        if len(chunk_accuracies) < 2:
            return {
                'survivor_velocity': 0.0,
                'velocity_acceleration': 0.0
            }

        velocities = [
            chunk_accuracies[i+1] - chunk_accuracies[i]
            for i in range(len(chunk_accuracies) - 1)
        ]

        velocity = np.mean(velocities) if velocities else 0.0

        acceleration = 0.0
        if len(velocities) > 1:
            accelerations = [
                velocities[i+1] - velocities[i]
                for i in range(len(velocities) - 1)
            ]
            acceleration = np.mean(accelerations) if accelerations else 0.0

        return {
            'survivor_velocity': float(velocity),
            'velocity_acceleration': float(acceleration)
        }

    def _calculate_intersection_weights(
        self,
        seed: int,
        forward_survivors: Optional[List[int]],
        reverse_survivors: Optional[List[int]]
    ) -> Dict[str, float]:
        """
        Calculate intersection weights (ENHANCED with whitepaper metrics)
        
        Now uses the full dual-sieve overlap calculation for richer ML features
        """
        if forward_survivors is None or reverse_survivors is None:
            return {
                'intersection_ratio': 0.0,
                'intersection_count': 0,
                'forward_count': 0,
                'reverse_count': 0,
                'intersection_weight': 0.0,
                'survivor_overlap_ratio': 0.0,
                'forward_only_count': 0,
                'reverse_only_count': 0
            }

        # Use the new dual-sieve overlap calculation
        overlap_metrics = self.calculate_survivor_overlap_ratio(
            forward_survivors, reverse_survivors
        )
        
        # Check if this seed is in the intersection
        intersection = set(forward_survivors) & set(reverse_survivors)
        seed_in_intersection = 1.0 if seed in intersection else 0.0
        
        # Enhanced intersection weight (not just binary, but weighted by overlap quality)
        enhanced_weight = seed_in_intersection * overlap_metrics['jaccard_index']

        return {
            'intersection_ratio': overlap_metrics['jaccard_index'],
            'intersection_count': overlap_metrics['intersection_count'],
            'forward_count': len(forward_survivors),
            'reverse_count': len(reverse_survivors),
            'intersection_weight': enhanced_weight,
            'survivor_overlap_ratio': overlap_metrics['overlap_ratio'],
            'forward_only_count': overlap_metrics['forward_only'],
            'reverse_only_count': overlap_metrics['reverse_only']
        }

    def _calculate_lane_agreement(
        self,
        predictions: List[int],
        actuals: List[int]
    ) -> Dict[str, float]:
        """Calculate lane agreement"""
        if not predictions or not actuals:
            return {
                'lane_agreement_8': 0.0,
                'lane_agreement_125': 0.0,
                'lane_consistency': 0.0
            }

        lane_agreements = {}

        for mod_val in [8, 125]:
            lane_matches = {}
            lane_totals = {}

            for pred, actual in zip(predictions, actuals):
                lane = pred % mod_val
                if lane not in lane_matches:
                    lane_matches[lane] = 0
                    lane_totals[lane] = 0

                lane_totals[lane] += 1
                if pred == actual:
                    lane_matches[lane] += 1

            lane_accuracies = [
                lane_matches[lane] / lane_totals[lane]
                for lane in lane_totals
                if lane_totals[lane] > 0
            ]

            avg_agreement = np.mean(lane_accuracies) if lane_accuracies else 0.0
            lane_agreements[f'lane_agreement_{mod_val}'] = float(avg_agreement)

        all_agreements = [v for v in lane_agreements.values()]
        consistency = 1.0 - np.std(all_agreements) if len(all_agreements) > 1 else 0.0

        return {
            **lane_agreements,
            'lane_consistency': float(consistency)
        }

    def _calculate_statistical_features(
        self,
        predictions: List[int],
        actuals: List[int]
    ) -> Dict[str, float]:
        """Calculate statistical features"""
        if not predictions or not actuals:
            return self._empty_statistical_features()

        min_len = min(len(predictions), len(actuals))
        residuals = [predictions[i] - actuals[i] for i in range(min_len)]

        return {
            'pred_mean': float(np.mean(predictions)),
            'pred_std': float(np.std(predictions)),
            'pred_min': int(np.min(predictions)),
            'pred_max': int(np.max(predictions)),
            'actual_mean': float(np.mean(actuals)),
            'actual_std': float(np.std(actuals)),
            'residual_mean': float(np.mean(residuals)),
            'residual_std': float(np.std(residuals)),
            'residual_abs_mean': float(np.mean(np.abs(residuals))),
            'residual_max_abs': int(np.max(np.abs(residuals)))
        }

    def _empty_statistical_features(self) -> Dict[str, float]:
        """Return empty statistical features"""
        return {
            'pred_mean': 0.0, 'pred_std': 0.0, 'pred_min': 0, 'pred_max': 0,
            'actual_mean': 0.0, 'actual_std': 0.0,
            'residual_mean': 0.0, 'residual_std': 0.0,
            'residual_abs_mean': 0.0, 'residual_max_abs': 0
        }

    def _get_distribution(self, values: List[int], num_bins: int) -> np.ndarray:
        """Get normalized probability distribution"""
        counts = np.zeros(num_bins)
        for val in values:
            if 0 <= val < num_bins:
                counts[val] += 1

        total = np.sum(counts)
        if total > 0:
            counts = counts / total

        counts = counts + 1e-10
        return counts

    def _kl_divergence(self, p: np.ndarray, q: np.ndarray) -> float:
        """Calculate KL divergence"""
        return float(np.sum(p * np.log(p / q)))

    def _empty_ml_features(self) -> Dict[str, float]:
        """Return empty ML feature set"""
        return {
            'score': 0.0, 'exact_matches': 0, 'total_predictions': 0,
            'confidence': 0, 'best_offset': 0,
            'residue_8_match_rate': 0.0, 'residue_8_kl_divergence': 0.0,
            'residue_8_coherence': 0.0, 'residue_125_match_rate': 0.0,
            'residue_125_kl_divergence': 0.0, 'residue_125_coherence': 0.0,
            'residue_1000_match_rate': 0.0, 'residue_1000_kl_divergence': 0.0,
            'residue_1000_coherence': 0.0, 'skip_entropy': 0.0,
            'skip_mean': 0.0, 'skip_std': 0.0, 'skip_range': 0,
            'temporal_stability_mean': 0.0, 'temporal_stability_std': 0.0,
            'temporal_stability_trend': 0.0, 'temporal_stability_min': 0.0,
            'temporal_stability_max': 0.0, 'survivor_velocity': 0.0,
            'velocity_acceleration': 0.0, 'intersection_ratio': 0.0,
            'intersection_count': 0, 'forward_count': 0, 'reverse_count': 0,
            'intersection_weight': 0.0, 'lane_agreement_8': 0.0,
            'lane_agreement_125': 0.0, 'lane_consistency': 0.0,
            **self._empty_statistical_features()
        }

    # ==================== BATCH & UTILITY METHODS ====================

    def batch_score(
        self,
        seeds: List[int],
        lottery_history: List[int],
        extract_features: bool = False,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """Score multiple seeds and return ranked results"""
        results = []

        for seed in seeds:
            if extract_features:
                result = self.extract_ml_features(seed, lottery_history, **kwargs)
            else:
                result = self.score_survivor(seed, lottery_history, **kwargs)
            results.append(result)

        results.sort(key=lambda x: x.get('score', 0), reverse=True)
        return results

    def rolling_window_score(
        self,
        seed: int,
        lottery_history: List[int],
        window_size: int = 50,
        stride: int = 10,
        **kwargs
    ) -> Dict[str, Any]:
        """Score using rolling windows"""
        window_scores = []

        for start in range(0, len(lottery_history) - window_size + 1, stride):
            window_history = lottery_history[start:start + window_size]
            result = self.score_survivor(seed, window_history, **kwargs)

            window_scores.append({
                'window_start': start,
                'window_end': start + window_size,
                'score': result['score'],
                'matches': result['exact_matches']
            })

        if not window_scores:
            return {'windows': [], 'mean_score': 0.0, 'std_score': 0.0}

        scores = [w['score'] for w in window_scores]

        return {
            'windows': window_scores,
            'mean_score': float(np.mean(scores)),
            'std_score': float(np.std(scores)),
            'min_score': float(np.min(scores)),
            'max_score': float(np.max(scores))
        }

    def export_results(self, results: Any, filepath: str, format: str = 'json'):
        """Export results to file"""
        import csv

        if format == 'json':
            with open(filepath, 'w') as f:
                json.dump(results, f, indent=2)

        elif format == 'csv':
            if isinstance(results, dict):
                results = [results]

            if not results:
                return

            flattened = []
            for result in results:
                flat = {}
                for key, value in result.items():
                    if isinstance(value, dict):
                        for subkey, subval in value.items():
                            flat[f"{key}_{subkey}"] = subval
                    elif isinstance(value, list):
                        flat[key] = str(value)
                    else:
                        flat[key] = value
                flattened.append(flat)

            keys = flattened[0].keys()

            with open(filepath, 'w', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=keys)
                writer.writeheader()
                writer.writerows(flattened)


def main():
    """Self-test and CLI interface"""
    parser = argparse.ArgumentParser(description='Survivor Scorer - Complete ML/AI Ready')
    parser.add_argument('--seed', type=int, help='Seed to test')
    parser.add_argument('--lottery-data', type=str, help='Path to lottery history JSON file')
    parser.add_argument('--prng-type', type=str, default='java_lcg', help='PRNG type')
    parser.add_argument('--mod', type=int, default=1000, help='Modulo value')
    parser.add_argument('--skip', type=int, default=0, help='Skip value')
    parser.add_argument('--extract-features', action='store_true', help='Extract full ML features')
    parser.add_argument('--output', type=str, help='Output file path')
    parser.add_argument('--format', type=str, default='json', choices=['json', 'csv'], help='Output format')
    parser.add_argument('--test', action='store_true', help='Run self-test')

    args = parser.parse_args()

    if args.test or (not args.seed and not args.lottery_data):
        print("="*60)
        print("SURVIVOR SCORER - COMPLETE ML/AI READY")
        print("="*60)

        print("\n[Test 1] Basic Scoring Test")
        print("-" * 60)

        scorer = SurvivorScorer(prng_type='java_lcg', mod=1000)

        test_seed = 42424242
        test_history = scorer._generate_predictions(test_seed, 100, skip=0)

        print(f"Generated {len(test_history)} test draws")
        print(f"First 10 draws: {test_history[:10]}")

        result = scorer.score_survivor(test_seed, test_history)
        print(f"\n‚úÖ Correct seed score: {result['score']:.2f}%")
        print(f"   Matches: {result['exact_matches']}/{result['total_predictions']}")

        wrong_result = scorer.score_survivor(99999999, test_history)
        print(f"‚ùå Wrong seed score: {wrong_result['score']:.2f}%")
        print(f"   Matches: {wrong_result['exact_matches']}/{wrong_result['total_predictions']}")

        print("\n[Test 2] ML Feature Extraction")
        print("-" * 60)

        features = scorer.extract_ml_features(test_seed, test_history)
        print(f"‚úÖ Extracted {len(features)} ML features")
        print("\nKey features:")

        key_features = ['score', 'residue_8_coherence', 'skip_entropy',
                        'temporal_stability_mean', 'survivor_velocity',
                        'intersection_ratio', 'lane_agreement_8']

        for key in key_features:
            if key in features:
                print(f"  {key}: {features[key]:.4f}")

        print("\n[Test 3] Batch Scoring")
        print("-" * 60)

        test_seeds = [42424242, 12345678, 87654321, 99999999]
        batch_results = scorer.batch_score(test_seeds, test_history)

        print(f"‚úÖ Scored {len(batch_results)} seeds")
        print("\nTop 3 seeds:")
        for i, result in enumerate(batch_results[:3], 1):
            print(f"  {i}. Seed {result['seed']}: {result['score']:.2f}% ({result['exact_matches']} matches)")

        print("\n[Test 4] Rolling Window Analysis")
        print("-" * 60)

        window_result = scorer.rolling_window_score(test_seed, test_history, window_size=20, stride=10)
        print(f"‚úÖ Analyzed {len(window_result['windows'])} windows")
        print(f"   Mean score: {window_result['mean_score']:.2f}%")
        print(f"   Std score: {window_result['std_score']:.2f}%")
        print(f"   Min score: {window_result['min_score']:.2f}%")
        print(f"   Max score: {window_result['max_score']:.2f}%")

        print("\n" + "="*60)
        print("ALL TESTS PASSED! üöÄ")
        print("="*60)
        print("\nUsage examples:")
        print("  python survivor_scorer.py --seed 12345 --lottery-data history.json")
        print("  python survivor_scorer.py --seed 12345 --lottery-data history.json --extract-features")
        print("  python survivor_scorer.py --seed 12345 --lottery-data history.json --extract-features --output results.json")

        return

    # CLI mode - score a seed
    if args.seed and args.lottery_data:
        # Load lottery data
        with open(args.lottery_data, 'r') as f:
            data = json.load(f)

        # Parse lottery history from various formats
        lottery_history = []

        if isinstance(data, dict):
            # Dict format: {"draws": [...], ...}
            lottery_history = data.get('draws', data.get('results', data.get('numbers', [])))
        elif isinstance(data, list):
            if not data:
                lottery_history = []
            elif isinstance(data[0], dict):
                # List of dicts: [{"draw": 123, ...}, ...]
                for entry in data:
                    if 'draw' in entry:
                        lottery_history.append(int(entry['draw']))
                    elif 'result' in entry:
                        lottery_history.append(int(entry['result']))
                    elif 'number' in entry:
                        lottery_history.append(int(entry['number']))
                    elif 'value' in entry:
                        lottery_history.append(int(entry['value']))
            else:
                # Simple list: [123, 456, 789, ...]
                lottery_history = [int(x) for x in data]

        if not lottery_history:
            print("Error: Could not extract lottery numbers from data file")
            sys.exit(1)

        print(f"Loaded {len(lottery_history)} draws from {args.lottery_data}")
        print(f"Sample draws: {lottery_history[:5]}")
        # Initialize scorer
        scorer = SurvivorScorer(prng_type=args.prng_type, mod=args.mod)

        # Score or extract features
        if args.extract_features:
            print(f"Extracting ML features for seed {args.seed}...")
            result = scorer.extract_ml_features(args.seed, lottery_history, skip=args.skip)
        else:
            print(f"Scoring seed {args.seed}...")
            result = scorer.score_survivor(args.seed, lottery_history, skip=args.skip)

        # Display results
        print("\n" + "="*60)
        print(f"RESULTS FOR SEED {args.seed}")
        print("="*60)
        print(f"Score: {result['score']:.2f}%")
        print(f"Matches: {result.get('exact_matches', 0)}/{result.get('total_predictions', 0)}")

        if args.extract_features:
            print(f"\nExtracted {len(result)} features")
            print("\nTop features:")
            for key in ['residue_8_coherence', 'skip_entropy', 'temporal_stability_mean',
                        'survivor_velocity', 'lane_agreement_8']:
                if key in result:
                    print(f"  {key}: {result[key]:.4f}")

        # Export if requested
        if args.output:
            scorer.export_results(result, args.output, args.format)
            print(f"\n‚úÖ Results exported to {args.output}")

    else:
        parser.print_help()


if __name__ == '__main__':
    main()
