# Chapter 13 Implementation Progress

**Last Updated:** 2026-01-29  
**Document Version:** 1.5.0  
**Status:** Phases 1-6 Complete â†’ Phase 7 Testing â†’ Phase 8 Selfplay Integration  
**Team Beta Endorsement:** âœ… Approved (including Selfplay Architecture v1.1)

---

## Overall Progress

| Phase | Status | Owner | Target |
|-------|--------|-------|--------|
| 1. Draw Ingestion | âœ… Complete | Claude | Week 1 |
| 2. Diagnostics Engine | âœ… Complete | Claude | Week 1-2 |
| 3. Retrain Triggers | âœ… Complete | Claude | Week 2 |
| 4. LLM Integration | âœ… Complete | Claude | Week 3 |
| 5. Acceptance Engine | âœ… Complete | Claude | Week 3 |
| 6. WATCHER Orchestration | âœ… Complete | Claude | Week 4 |
| 7. Testing & Validation | ğŸŸ¡ In Progress | TBD | Week 4 |
| **8. Selfplay Integration** | ğŸŸ¡ **In Progress** | Team Beta | Week 5 |

**Legend:** ğŸ”² Not Started | ğŸŸ¡ In Progress | âœ… Complete | âŒ Blocked

---

## âš ï¸ CRITICAL: Coordination Requirements

**GPU work MUST use existing coordinators to prevent ROCm/SSH storms.**

| Work Type | Direct SSH OK? | Use Coordinator? | Stagger Required? |
|-----------|----------------|------------------|-------------------|
| GPU Sieving (Outer Episode) | âŒ **NO** | âœ… **YES (mandatory)** | âœ… YES (0.3s) |
| CPU ML Training (Inner Episode) | âœ… YES | Optional | âŒ NO |

See: `SELFPLAY_ARCHITECTURE_PROPOSAL_v1_0.md` for full details.

---

## Phase 8: Selfplay Integration ğŸŸ¡ IN PROGRESS

**New in v1.5.0** â€” Integrates selfplay architecture approved by Team Beta on 2026-01-29.

### 8.1 Selfplay Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SELFPLAY ORCHESTRATOR                           â”‚
â”‚                                                                     â”‚
â”‚  CRITICAL: Does NOT directly SSH to rigs for GPU work!             â”‚
â”‚  Uses existing proven coordinators to prevent ROCm/SSH storms.     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTER EPISODE (Sieving)                          â”‚
â”‚                                                                     â”‚
â”‚  COORDINATION: Uses coordinator.py / scripts_coordinator.py        â”‚
â”‚  Framework: PyTorch (GPU vectorized operations)                    â”‚
â”‚                                                                     â”‚
â”‚  Zeus:      2Ã— RTX 3080 Ti (CUDA)     â†’ Sieving workers            â”‚
â”‚  rig-6600:  12Ã— RX 6600 (ROCm)        â†’ Sieving workers            â”‚
â”‚  rig-6600b: 12Ã— RX 6600 (ROCm)        â†’ Sieving workers            â”‚
â”‚                                                                     â”‚
â”‚  Total: 26 GPU workers (coordinated, not direct SSH)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INNER EPISODE (ML Training)                      â”‚
â”‚                                                                     â”‚
â”‚  Models: LightGBM, XGBoost, CatBoost ONLY (NO neural_net)         â”‚
â”‚  Device: CPU only (GPU is 8-11x slower for tree models)           â”‚
â”‚                                                                     â”‚
â”‚  Zeus i9-9920X:    3Ã— CPU workers (8 threads each) = ~30 models/s â”‚
â”‚  rig-6600 i5-9400: 2Ã— CPU workers (3 threads each) = ~10 models/s â”‚
â”‚  rig-6600b i5-8400: 2Ã— CPU workers (3 threads each) = ~11 models/sâ”‚
â”‚                                                                     â”‚
â”‚  Total: 7 parallel CPU workers = ~50 models/sec                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 Selfplay Tasks

| Task | Status | Notes |
|------|--------|-------|
| Phase 1 verification complete | âœ… | Coordinators exist, packages verified |
| CPU throughput benchmarked | âœ… | Zeus: 10.6 models/sec |
| Learning Telemetry module | ğŸ”² | `modules/learning_telemetry.py` |
| Selfplay Orchestrator | ğŸ”² | `selfplay_orchestrator.py` |
| Inner Episode Trainer | ğŸ”² | `inner_episode_trainer.py` |
| Worker Pool Manager | ğŸ”² | `worker_pool_manager.py` |
| Configuration files | ğŸ”² | `configs/selfplay_config.json` |
| Chapter 13 telemetry hooks | ğŸ”² | Integration with diagnostics |
| End-to-end selfplay test | ğŸ”² | Full cycle validation |

### 8.3 Learning Telemetry (Observability Only)

**Purpose:** Provides visibility into learning progress WITHOUT controlling decisions.

```json
{
  "learning_health": {
    "timestamp": "2026-01-29T12:00:00Z",
    "inner_episode_throughput": 68.2,
    "policy_entropy": 0.41,
    "recent_reward_trend": "+3.2%",
    "last_promotion_days_ago": 4,
    "models_trained_total": 1247,
    "current_best_policy": "policy_v3_2_1",
    "survivor_count_avg": 2340,
    "training_time_avg_ms": 142
  }
}
```

| Metric | Healthy Range | Warning Threshold |
|--------|---------------|-------------------|
| `inner_episode_throughput` | 50-80 models/sec | < 30 |
| `policy_entropy` | 0.2-0.6 | < 0.1 (premature convergence) |
| `recent_reward_trend` | > -5% | < -10% (regression) |
| `last_promotion_days_ago` | < 14 days | > 21 (stalled) |

**Critical Constraint:** Telemetry is **READ-ONLY**. No system may use it for automated decisions.

### 8.4 Model Selection (Inner Episode)

| Model | Device | Use Case | Status |
|-------|--------|----------|--------|
| LightGBM | CPU | Default (fastest) | âœ… Approved |
| XGBoost | CPU | Alternative | âœ… Approved |
| CatBoost | CPU | Best accuracy | âœ… Approved |
| ~~Neural Net~~ | ~~GPU~~ | ~~FORBIDDEN~~ | âŒ **500,000x worse MSE** |

**Benchmark Results (January 29, 2026):**

| Rig | CPU (12 models) | GPU (12 models) | CPU Advantage |
|-----|-----------------|-----------------|---------------|
| rig-6600 | **1.12s** | 8.79s | **7.9x faster** |
| rig-6600b | **1.08s** | 11.92s | **11x faster** |
| Zeus | **1.14s** | â€” | **10.6 models/sec** |

### 8.5 Selfplay Files to Create

| File | Purpose | Status |
|------|---------|--------|
| `selfplay_orchestrator.py` | Main orchestration | ğŸ”² |
| `inner_episode_trainer.py` | CPU model trainer | ğŸ”² |
| `worker_pool_manager.py` | Worker management | ğŸ”² |
| `modules/learning_telemetry.py` | Telemetry module | ğŸ”² |
| `configs/selfplay_config.json` | Configuration | ğŸ”² |

### 8.6 Selfplay â†” Chapter 13 Integration

| Chapter 13 Component | Selfplay Integration |
|---------------------|----------------------|
| `chapter_13_orchestrator.py` | Triggers selfplay outer episodes |
| `chapter_13_diagnostics.py` | Consumes learning telemetry (read-only) |
| `chapter_13_triggers.py` | May trigger selfplay retraining |
| `chapter_13_acceptance.py` | Validates selfplay policy promotions |

**Authority Model (Unchanged):**
- Learning happens **statistically** (tree models + bandit policy)
- Verification happens **deterministically** (Chapter 13)
- Telemetry happens **observationally** (no control path)
- LLM role remains **advisory only**

---

## Phase 1: Draw Ingestion âœ… COMPLETE

| Task | Status | Notes |
|------|--------|-------|
| Create `draw_ingestion_daemon.py` | âœ… | v1.0.0 - Directory watch + flag watch modes |
| Create `synthetic_draw_injector.py` | âœ… | v1.0.0 - Reads PRNG from config, uses registry |
| Create `watcher_policies.json` | âœ… | v1.0.0 - Full threshold config |
| Append-only history update logic | âœ… | Implemented in daemon |
| Fingerprint change detection | âœ… | SHA256-based detection |
| Test: Manual injection | âœ… | `--inject-one` mode ready |
| Test: Daemon injection | âœ… | `--daemon` mode ready |

**Blockers:** None  
**Completion Date:** 2026-01-12

### Phase 1 Deliverables

| File | Version | Lines | Description |
|------|---------|-------|-------------|
| `synthetic_draw_injector.py` | 1.0.0 | ~450 | Synthetic draw generation using config-based PRNG |
| `draw_ingestion_daemon.py` | 1.0.0 | ~450 | Draw monitoring and history management |
| `watcher_policies.json` | 1.0.0 | ~120 | Test mode settings and Chapter 13 thresholds |

---

## Phase 2: Diagnostics Engine âœ… COMPLETE

| Task | Status | Notes |
|------|--------|-------|
| Create `chapter_13_diagnostics.py` | âœ… | v1.0.0 - Core diagnostic generator |
| Prediction vs reality comparison | âœ… | Hit rate, rank, near-hits, coverage |
| Confidence calibration metrics | âœ… | Predicted vs actual correlation |
| Survivor performance tracking | âœ… | Hit/decay/reinforce candidates |
| Feature drift detection | âœ… | Entropy, turnover, schema hash |
| Generate `post_draw_diagnostics.json` | âœ… | Output artifact |
| Create `diagnostics_history/` archival | âœ… | Historical storage |
| Test: Diagnostic accuracy | âœ… | Validated with mock data |

**Blockers:** None  
**Completion Date:** 2026-01-12

---

## Phase 3: Retrain Trigger Logic âœ… COMPLETE

| Task | Status | Notes |
|------|--------|-------|
| Define thresholds in `watcher_policies.json` | âœ… | Done in Phase 1 |
| Create `chapter_13_triggers.py` | âœ… | v1.0.0 - Team Beta approved separation |
| Implement `should_retrain()` | âœ… | Quick boolean check |
| Implement `evaluate_triggers()` | âœ… | Full evaluation with metrics |
| Implement `execute_learning_loop()` | âœ… | Runs Steps 3â†’5â†’6 |
| Implement partial rerun logic | âœ… | Configurable step list |
| Implement cooldown enforcement | âœ… | CooldownState tracking |
| Human approval gate | âœ… | v1 requirement enforced |
| Test: Trigger conditions | âœ… | All 6 triggers implemented |

**Blockers:** None  
**Completion Date:** 2026-01-12

### Trigger Conditions Implemented

| Trigger | Threshold | Action |
|---------|-----------|--------|
| `consecutive_misses` | â‰¥5 | Learning Loop (3â†’5â†’6) |
| `confidence_drift` | correlation < 0.2 | Learning Loop |
| `hit_rate_collapse` | < 0.01 | Learning Loop |
| `n_draws_accumulated` | â‰¥10 | Learning Loop |
| `regime_shift` | decay > 0.5 AND churn > 0.4 | Full Pipeline (1â†’6) |
| `RETRAIN_RECOMMENDED` flag | From diagnostics | Learning Loop |

---

## Phase 4: LLM Integration âœ… COMPLETE

| Task | Status | Notes |
|------|--------|-------|
| Create `chapter_13_llm_advisor.py` | âœ… | v1.0.0 - LLM analysis module |
| Create `llm_proposal_schema.py` | âœ… | v1.0.0 - Dataclass models |
| Create `chapter_13.gbnf` | âœ… | v1.1 - Grammar constraint |
| System prompt template | âœ… | Strategist role with hard constraints |
| User prompt template | âœ… | Diagnostic analysis format |
| Integration with existing LLM infra | âœ… | LLMRouter + grammar |
| Test: DeepSeek grammar-constrained | âœ… | Verified working |
| Test: Claude backup fallback | âœ… | Verified working |
| Test: Heuristic fallback | âœ… | Verified working |

**Blockers:** None  
**Completion Date:** 2026-01-12

### LLM Role Enforced (Advisory Only)

| Allowed | Forbidden |
|---------|-----------|
| âœ… Interpret diagnostics | âŒ Modify files |
| âœ… Propose parameter adjustments | âŒ Execute code |
| âœ… Flag regime shifts | âŒ Apply parameters directly |
| âœ… Explain performance changes | âŒ Override WATCHER |

---

## Phase 5: Acceptance/Rejection Engine âœ… COMPLETE

| Task | Status | Notes |
|------|--------|-------|
| Create `chapter_13_acceptance.py` | âœ… | v1.0.0 - Validation engine |
| Implement `validate_proposal()` | âœ… | Full validation pipeline |
| Enforce 30% max delta | âœ… | `max_parameter_delta` check |
| Enforce 3 param max | âœ… | `max_parameters_per_proposal` |
| Enforce cooldown periods | âœ… | `ParameterHistory` tracking |
| Enforce frozen parameters | âœ… | Steps 1, 2, 4 params protected |
| Reversal detection | âœ… | `would_reverse()` check |
| Escalation logic | âœ… | Risk level, flags, failures |
| Create `acceptance_decisions.jsonl` | âœ… | Audit trail |

**Blockers:** None  
**Completion Date:** 2026-01-12

---

## Phase 6: WATCHER Orchestration âœ… COMPLETE

| Task | Status | Notes |
|------|--------|-------|
| Create `chapter_13_orchestrator.py` | âœ… | v1.0.0 - Main daemon |
| New draw detection (flag monitoring) | âœ… | Monitors `new_draw.flag` |
| Run diagnostics on trigger | âœ… | Calls `chapter_13_diagnostics` |
| Evaluate retrain triggers | âœ… | Uses `Chapter13TriggerManager` |
| Query LLM (optional) | âœ… | Uses `Chapter13LLMAdvisor` |
| Validate proposals | âœ… | Uses `Chapter13AcceptanceEngine` |
| Human approval gate | âœ… | v1 requirement enforced |

**Blockers:** None  
**Completion Date:** 2026-01-12

---

## Phase 7: Testing & Validation ğŸŸ¡ IN PROGRESS

| Task | Status | Notes |
|------|--------|-------|
| Module import validation | âœ… | All modules import cleanly |
| Synthetic draw convergence test | ğŸ”² | True seed rises in rankings |
| Forced retrain validation | ğŸ”² | Steps 3â†’5â†’6 execute |
| Proposal rejection test | ğŸ”² | Bounds enforced |
| Divergence detection test | ğŸ”² | Halt on instability |
| Cooldown enforcement test | ğŸ”² | Thrashing prevented |
| Full autonomy test (100 draws) | ğŸ”² | Extended run |

**Blockers:** None

---

## Convergence Metrics

### Chapter 13 Metrics (Test Mode)

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Hit Rate (Top-20) | > 5% | - | ğŸ”² |
| Confidence Calibration | Correlation > 0.3 | - | ğŸ”² |
| Confidence trend | Increasing | - | ğŸ”² |

### Selfplay Metrics (Learning Telemetry)

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Inner episode throughput | â‰¥50 models/sec | - | ğŸ”² |
| Policy entropy | 0.2-0.6 | - | ğŸ”² |
| Reward trend | > -5% | - | ğŸ”² |
| Promotion frequency | < 14 days | - | ğŸ”² |

---

## Files Created/Modified

### Chapter 13 Core Files

| File | Status | Purpose |
|------|--------|---------|
| `draw_ingestion_daemon.py` | âœ… v1.0.0 | Draw monitoring |
| `synthetic_draw_injector.py` | âœ… v1.0.0 | Test mode |
| `watcher_policies.json` | âœ… v1.0.0 | Config |
| `chapter_13_diagnostics.py` | âœ… v1.0.0 | Diagnostic engine |
| `chapter_13_triggers.py` | âœ… v1.0.0 | Retrain triggers |
| `chapter_13_llm_advisor.py` | âœ… v1.0.0 | LLM integration |
| `llm_proposal_schema.py` | âœ… v1.0.0 | Schema models |
| `chapter_13.gbnf` | âœ… v1.1.0 | Grammar constraint |
| `chapter_13_acceptance.py` | âœ… v1.0.0 | Acceptance engine |
| `chapter_13_orchestrator.py` | âœ… v1.0.0 | Main orchestration daemon |

### Selfplay Files (Phase 8)

| File | Status | Purpose |
|------|--------|---------|
| `selfplay_orchestrator.py` | ğŸ”² | Main selfplay orchestration |
| `inner_episode_trainer.py` | ğŸ”² | CPU tree model trainer |
| `worker_pool_manager.py` | ğŸ”² | Worker management |
| `modules/learning_telemetry.py` | ğŸ”² | Telemetry module |
| `configs/selfplay_config.json` | ğŸ”² | Selfplay configuration |

### Documentation

| File | Status | Purpose |
|------|--------|---------|
| `SELFPLAY_ARCHITECTURE_PROPOSAL_v1_0.md` | âœ… | Approved architecture |
| `SELFPLAY_INTEGRATION_PROGRESS_v1_0.md` | âœ… | Implementation tracker |
| `CHAPTER_13_IMPLEMENTATION_PROGRESS_v1_5.md` | âœ… | This document |

---

## Critical Design Invariants

### Chapter 13 Invariant
**Chapter 13 v1 does not alter model weights directly. All learning occurs through controlled re-execution of Step 5 with expanded labels.**

### Selfplay Invariant
**GPU sieving work MUST use coordinator.py / scripts_coordinator.py. Direct SSH to rigs for GPU work is FORBIDDEN.**

### Learning Authority Invariant
**Learning is statistical (tree models + bandit). Verification is deterministic (Chapter 13). LLM is advisory only. Telemetry is observational only.**

---

## Session History

| Date | Event |
|------|-------|
| 2026-01-11 | Chapter 13 spec finalized (v1.1) |
| 2026-01-12 | Phases 1-6 implementation complete |
| 2026-01-13 | watcher_policies.json finalized |
| 2026-01-14 to 2026-01-17 | ROCm stability investigation (4.5Ã— perf improvement) |
| 2026-01-18 | Resumed Chapter 13 testing, functional mimicry paradigm documented (v1.2) |
| 2026-01-28-29 | LightGBM GPU benchmarking, CPU wins confirmed (8-11x faster) |
| **2026-01-29** | **Selfplay Architecture Proposal v1.1 approved by Team Beta** |
| **2026-01-29** | **Phase 8 (Selfplay Integration) added, Phase 1 verification complete** |

---

## Deferred Extensions (Future Work)

| Extension | Description | Status |
|-----------|-------------|--------|
| #1 | Step-6 Backtesting Hooks | ğŸ”² Deferred |
| #2 | Confidence Calibration Curves | ğŸ”² Deferred |
| #3 | Autonomous Trigger Execution (no approval) | ğŸ”² Deferred |
| #4 | Convergence Dashboards | ğŸ”² Deferred |

---

## Next Actions

1. [x] ~~Phases 1-6 complete~~
2. [x] ~~Selfplay architecture proposal approved~~
3. [x] ~~Phase 1 selfplay verification (coordinators, packages, throughput)~~
4. [ ] Create `modules/learning_telemetry.py`
5. [ ] Create `inner_episode_trainer.py`
6. [ ] Create `selfplay_orchestrator.py`
7. [ ] Create `configs/selfplay_config.json`
8. [ ] Integrate telemetry with Chapter 13 diagnostics
9. [ ] End-to-end selfplay test
10. [ ] Phase 7: Full pipeline convergence test

---

*Update this document as implementation progresses.*
