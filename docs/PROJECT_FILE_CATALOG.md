# DISTRIBUTED PRNG ANALYSIS SYSTEM — COMPLETE FILE CATALOG
## Project: ~/distributed_prng_analysis (Zeus)
### Compiled: February 4, 2026 | Phase 7 WATCHER Integration COMPLETE | Soak B CERTIFIED

---

## PROJECT SIZE SUMMARY

| Category | File Count | Est. Size |
|----------|-----------|-----------|
| Core Pipeline Scripts | ~15 | ~120 KB |
| Chapter 13 (Live Feedback Loop) | 10 | ~226 KB |
| Phase 7 WATCHER + Dispatch | 3 | ~70 KB |
| Phase 9B Selfplay System | 4 | ~104 KB |
| Bundle Factory + LLM Services | 5 | ~50 KB |
| Multi-Model Architecture | 8 | ~40 KB |
| Agent Manifests (JSON) | 6 | ~12 KB |
| Agent Grammars (GBNF) | 4+ | ~10 KB |
| Shell Scripts (Orchestrators) | 4 | ~15 KB |
| Schemas / Config JSON | 6+ | ~20 KB |
| Integration / Core Modules | 4 | ~25 KB |
| Utilities / Converters | 3 | ~10 KB |
| Documentation (Chapters 1-14) | 14+ | ~200 KB |
| Documentation (Proposals/Guides) | 10+ | ~150 KB |
| **TOTAL (code + docs)** | **~110+ files** | **~1.05 MB** |

**Runtime Data (generated, not in repo):**

| Data File | Typical Size | Generated By |
|-----------|-------------|--------------|
| bidirectional_survivors.json | 258 MB | Step 1 |
| bidirectional_survivors_binary.npz | 0.6 MB | convert_survivors_to_binary.py |
| survivors_with_scores.json | 500+ MB | Step 3 |
| Optuna study DBs | 10–50 MB each | Steps 1, 2.5, 5 |
| Model checkpoints (.pth/.cbm/.json/.txt) | 1–50 MB | Step 5 |

---

## 1. CORE PIPELINE SCRIPTS (Steps 1–6)

### Step 1: Window Optimization

| File | Purpose | Produces |
|------|---------|----------|
| `window_optimizer.py` | Bayesian window parameter search (Optuna TPE) | `optimal_window_config.json`, `bidirectional_survivors.json`, `forward_survivors.json`, `reverse_survivors.json`, `train_history.json`, `holdout_history.json`, `window_optimization_results.json` |
| `window_optimizer_integration_final.py` | Bidirectional sieve integration layer | Called by window_optimizer.py — no standalone output |
| `window_optimizer_bayesian.py` | Bayesian optimization engine | Called by window_optimizer.py — no standalone output |

### Step 2 (Sieve): Bidirectional Filtering

| File | Purpose | Produces |
|------|---------|----------|
| `sieve_filter.py` (v2.3.1) | GPU-accelerated residue sieve (CuPy kernels) | Survivor arrays returned to caller, also writes to `results/summaries/*.txt`, `results/csv/*.csv`, `results/json/*.json` |

### Step 2.5: Scorer Meta-Optimization

| File | Purpose | Produces |
|------|---------|----------|
| `run_scorer_meta_optimizer.sh` | Orchestrator shell script (PULL architecture) | Coordinates jobs, collects results |
| `generate_scorer_jobs.py` | Creates trial job specs for distributed execution | `scorer_jobs.json` |
| `scorer_trial_worker.py` | Executes single scorer trial on one GPU | `scorer_trial_results/trial_{id}.json` |
| `scripts_coordinator.py` | Dispatches script jobs to 26 GPUs (staggered, file-based success) | Per-worker result files, aggregated summary |

**Combined Step 2.5 Output:** `optimal_scorer_config.json`

### Step 3: Full Distributed Scoring

| File | Purpose | Produces |
|------|---------|----------|
| `run_step3_full_scoring.sh` (v2.0.0) | Shell orchestrator — ramdisk deploy, job gen, coordinator dispatch | Coordinates full scoring run |
| `generate_step3_scoring_jobs.py` | Creates scoring chunk jobs for all survivors | Job spec JSON |
| `full_scoring_worker.py` | Scores a chunk of survivors (50 per-seed + 14 global features) | `scored_chunks/chunk_{id}.json` |

**Combined Step 3 Output:** `survivors_with_scores.json` (all survivors with 64 ML features each)

### Step 4: Adaptive Meta-Optimizer

| File | Purpose | Produces |
|------|---------|----------|
| `adaptive_meta_optimizer.py` | Capacity & architecture planning (NOT data-aware) | `reinforcement_engine_config.json` |

**Note:** Step 4 does NOT consume survivor-level data. It plans network depth, epochs, pool sizes.

### Step 5: Anti-Overfit Training

| File | Purpose | Produces |
|------|---------|----------|
| `meta_prediction_optimizer_anti_overfit.py` | Orchestrator with K-fold CV, overfit detection | `models/reinforcement/best_model.meta.json` (sidecar), model checkpoint |
| `subprocess_trial_coordinator.py` | Subprocess isolation for multi-model comparison | Coordinates isolated training subprocesses |
| `train_single_trial.py` | Single trial worker (runs in subprocess) | Trial result JSON |

**Combined Step 5 Output:**
- `models/reinforcement/best_model.meta.json` — metadata sidecar (model type, feature schema hash, metrics)
- `models/reinforcement/best_model.{pth\|json\|cbm\|txt}` — model checkpoint (format depends on winner)

### Step 6: Prediction Generation

| File | Purpose | Produces |
|------|---------|----------|
| `prediction_generator.py` | Loads trained model, ranks survivors, generates pools | `predictions/ranked_predictions.json`, `predictions/prediction_pools.json`, `predictions/next_draw_prediction.json` |

### End-to-End Workflow Script

| File | Purpose | Produces |
|------|---------|----------|
| `complete_whitepaper_workflow_with_meta_optimizer_v3.py` | Runs Steps 1→6 sequentially with prerequisite checks | All outputs from Steps 1–6 |

---

## 2. COORDINATOR & DISTRIBUTED WORKERS

| File | Version | Purpose | Produces |
|------|---------|---------|----------|
| `coordinator.py` | v1.8.2 | 26-GPU job distribution, SSH pooling, fault tolerance, SCP result collection | Job dispatch logs, collected results |
| `scripts_coordinator.py` | — | ML script job distribution (Steps 2.5, 3) with staggered launch, file-based success detection | Aggregated results from workers |
| `distributed_worker.py` | v1.8.0 | GPU-bound execution agent on each node | Local result files per job |
| `distributed_config.json` | — | Cluster topology: node IPs, GPU counts, SSH paths, search bounds | Configuration (consumed, not produced) |
| `ml_coordinator_config.json` | — | ML-specific coordinator settings | Configuration (consumed) |

---

## 3. SCORING & PRNG ENGINES

| File | Version | Purpose | Produces |
|------|---------|---------|----------|
| `prng_registry.py` | v2.4 | 46 PRNG algorithm implementations (CuPy GPU kernels + PyTorch GPU functions) | No files — provides API: `get_kernel_info()`, `get_pytorch_gpu_reference()`, `list_available_prngs()` |
| `survivor_scorer.py` | — | 50-feature per-seed ML scoring engine | Feature dicts per survivor (returned to caller) |
| `global_state_tracker.py` | — | 14 global lottery features (entropy, marker tracking, regime detection) | Global feature dict (returned to caller) |
| `reinforcement_engine.py` | v1.4.0 | Neural network model (SurvivorQualityNet: 62→128→64→32→1) | Trained model `.pth` file |

---

## 4. MULTI-MODEL ARCHITECTURE (models/)

| File | Purpose | Produces |
|------|---------|----------|
| `models/__init__.py` | Package init, exports ModelFactory | — |
| `models/model_factory.py` | Unified factory: `create_model()`, `load_model_from_sidecar()` | Model instances |
| `models/model_selector.py` | `train_and_compare()` — trains all 4 types, picks winner | Comparison results JSON |
| `models/feature_schema.py` | Dynamic schema derivation + SHA256 hash validation | Schema dict with hash |
| `models/gpu_memory.py` | GPU memory reporting mixin | Memory stats dict |
| `models/wrappers/__init__.py` | Wrapper package init | — |
| `models/wrappers/base.py` | `ModelInterface` protocol (train, predict, save, load) | — |
| `models/wrappers/neural_net_wrapper.py` | Wraps PyTorch SurvivorQualityNet | `.pth` checkpoint |
| `models/wrappers/xgboost_wrapper.py` | XGBoost with GPU (CUDA) | `.json` checkpoint |
| `models/wrappers/lightgbm_wrapper.py` | LightGBM with GPU (OpenCL) | `.txt` checkpoint |
| `models/wrappers/catboost_wrapper.py` | CatBoost with GPU (CUDA, multi-GPU) | `.cbm` checkpoint |

---

## 5. CHAPTER 13: LIVE FEEDBACK LOOP (~226 KB, 10 files)

| File | Est. Size | Purpose | Produces |
|------|-----------|---------|----------|
| `chapter_13_diagnostics.py` | 39 KB | Computes drift, anomaly, regime metrics | Diagnostics JSON |
| `chapter_13_llm_advisor.py` | 23 KB | LLM-powered strategy advisor with GBNF constraints | `strategy_recommendation.json` |
| `chapter_13_triggers.py` | 36 KB | Event-driven trigger evaluation (drift, anomaly, schedule) | Trigger event records |
| `chapter_13_acceptance.py` | 41 KB | Ground-truth validation, policy promotion/rejection | `learned_policy_active.json` (on promotion) |
| `chapter_13_orchestrator.py` | 23 KB | Top-level orchestrator tying all Ch13 modules | Orchestration logs |
| `llm_proposal_schema.py` | 14 KB | Pydantic models mirroring GBNF grammar | — (schema definitions) |
| `chapter_13.gbnf` | 2.9 KB | GBNF grammar for LLM output constraints | — (grammar definition) |
| `draw_ingestion_daemon.py` | 22 KB | Monitors for new draw data, triggers pipeline | Ingested draw records |
| `synthetic_draw_injector.py` | 20 KB | Injects synthetic draws for testing/soak tests | Synthetic draw JSON |
| `watcher_policies.json` | 4.7 KB | Policy configuration for WATCHER-Ch13 interaction | — (configuration) |

**Ch13 Runtime State Files:**
- `learned_policy_active.json` — currently promoted policy
- `learned_policy_candidate.json` — candidate awaiting validation
- `chapter13/summaries/*.json` — curated outcome summaries
- `watcher_requests/*.json` — retrain requests for WATCHER

---

## 6. WATCHER AGENT & DISPATCH (Phase 7)

| File | Est. Size | Purpose | Produces |
|------|-----------|---------|----------|
| `agents/watcher_agent.py` | v1.4.0 ~30 KB | Main autonomous pipeline orchestrator | `watcher_history.json`, `watcher_decisions.jsonl`, `watcher_halt.flag` |
| `agents/watcher_dispatch.py` | ~30 KB | Selfplay + learning loop dispatch functions | Dispatch logs, request files |
| `agents/contexts/bundle_factory.py` | ~32 KB | Unified LLM context assembly (token-budgeted, provenance-tracked) | `StepAwarenessBundle` objects (in-memory) |

**WATCHER Runtime State:**
- `watcher_history.json` — run history summary
- `watcher_decisions.jsonl` — detailed decision audit trail
- `watcher_halt.flag` — kill switch file
- `watcher_requests/` — retrain request directory
- `state/watcher_failures.jsonl` — incident log

---

## 7. SELFPLAY SYSTEM (Phase 9B)

| File | Est. Size | Purpose | Produces |
|------|-----------|---------|----------|
| `selfplay_orchestrator.py` | 43 KB (v1.1.0) | Outer+inner episode loop with policy conditioning | `selfplay_history.jsonl`, episode results |
| `policy_transform.py` | 36 KB (v1.0.0) | Pure-functional policy transforms (filter, mask, rescore) | Transformed survivor arrays (in-memory) |
| `policy_conditioned_episode.py` | 25 KB (v1.0.0) | Integration layer: loads active policy, conditions survivors | `learned_policy_candidate.json`, `policy_history/{id}.json` |
| `inner_episode_trainer.py` | — | Trains models during selfplay inner episodes | Episode result dicts |
| `modules/learning_telemetry.py` | — | Telemetry tracking for selfplay learning | Telemetry JSON |
| `configs/selfplay_config.json` | — | Selfplay configuration | — (consumed) |

---

## 8. AGENT FRAMEWORK

### Agent Core

| File | Purpose | Produces |
|------|---------|----------|
| `agents/agent_core.py` | BaseAgent class | — (base class) |
| `agents/doctrine.py` (v3.2.0) | Agent behavioral doctrine | — (constants) |
| `agents/prompt_builder.py` (v3.2.0) | Prompt construction for LLM calls | Prompt strings |
| `agents/__init__.py` | Package init | — |

### Agent Manifests (agent_manifests/)

Each manifest defines: `required_inputs`, `primary_output`, `default_params`, `evaluation_criteria`, `actions`.

| File | Pipeline Step | required_inputs | primary_output |
|------|--------------|-----------------|----------------|
| `window_optimizer.json` | Step 1 | `synthetic_lottery.json` | `optimal_window_config.json` |
| `scorer_meta.json` | Step 2.5 | `.npz`, `train_history.json`, `holdout_history.json` | `optimal_scorer_config.json` |
| `full_scoring.json` | Step 3 | `.npz`, config, train, holdout | `survivors_with_scores.json` |
| `ml_meta.json` | Step 4 | `optimal_window_config.json`, train | `reinforcement_engine_config.json` |
| `reinforcement.json` | Step 5 | scores, train, config | `best_model.meta.json` |
| `prediction.json` | Step 6 | model, scores, forward, config | `next_draw_prediction.json` |

### Agent Step Contexts (agents/contexts/)

| File | Purpose |
|------|---------|
| `step1_context.py` | Window optimizer context builder |
| `step2_context.py` | Scorer meta context builder |
| `step3_context.py` | Full scoring context builder |
| `step4_context.py` | ML meta context builder |
| `step5_context.py` | Anti-overfit context builder |
| `step6_context.py` | Prediction context builder |
| `ch13_context.py` | Chapter 13 context builder |

### Agent Grammars (agent_grammars/)

| File | Purpose |
|------|---------|
| `chapter_13.gbnf` | Ch13 LLM output constraints |
| `watcher_decision.gbnf` | WATCHER decision output format |
| `agent_decision.gbnf` | Generic agent decision format |
| `selfplay_decision.gbnf` | Selfplay dispatch decisions |

---

## 9. LLM SERVICES

| File | Version | Purpose | Produces |
|------|---------|---------|----------|
| `llm_services/llm_router.py` | v2.0.0 | Routes requests to DeepSeek-R1-14B (primary) or Claude (backup) | LLM responses |
| `llm_services/grammar_loader.py` | v1.0.0 | Loads GBNF grammars for constrained decoding | Grammar objects |
| `llm_services/llm_server_config.json` | — | LLM server endpoints, model names, ports | — (configuration) |
| `llm_services/start_llm_servers.sh` | v2.1.0 | Starts local LLM servers | Running server processes |
| `llm_services/llm_lifecycle.py` | ~8 KB | Stop/restart LLM servers around GPU-heavy phases | Server state management |

---

## 10. INTEGRATION & CORE UTILITIES

| File | Purpose | Produces |
|------|---------|----------|
| `core/results_manager.py` | Results generation engine (summaries, CSV, JSON) | `results/summaries/*.txt`, `results/csv/*.csv`, `results/json/*.json` |
| `integration/metadata_writer.py` | Writes agent_metadata into result files | Modified result JSONs |
| `integration/sieve_integration.py` | Adapter connecting sieve outputs to results system | Formatted results |
| `convert_survivors_to_binary.py` (v3.0) | Converts JSON survivors to NPZ binary format (88× faster) | `bidirectional_survivors_binary.npz`, `bidirectional_survivors_binary.meta.json` |
| `survivor_loader.py` (v2.0) | Loads survivors from NPZ or JSON (auto-detect) | Survivor arrays |
| `progress_monitor.py` | Rich terminal progress display (tmux-based) | Live terminal output |

---

## 11. SCHEMAS & CONFIGURATION

| File | Purpose |
|------|---------|
| `schemas/results_schema_v1.json` | Data schema definitions |
| `schemas/output_templates.json` | Display format templates |
| `config_manifests/feature_registry.json` | Feature documentation (62 features) |
| `optimal_window_config.json` | Step 1 output (consumed by Steps 2–6) |
| `optimal_scorer_config.json` | Step 2.5 output (consumed by Step 3) |
| `reinforcement_engine_config.json` | Step 4 output (consumed by Step 5) |

---

## 12. MODULES DIRECTORY (modules/)

| File | Purpose | Produces |
|------|---------|----------|
| `modules/direct_analysis.py` | Cluster analysis with parameter optimization | Analysis results |
| `modules/result_viewer.py` | Interactive result viewing and visualization | Terminal display |
| `modules/system_monitor.py` | Hardware monitoring and diagnostics | System stats |
| `modules/database_manager.py` | Database operations and job management | DB records |
| `modules/file_manager.py` | File operations and maintenance | File management |
| `modules/performance_analytics.py` | Performance tracking and analytics | Analytics JSON |
| `modules/visualization_manager.py` | Visualization generation | Charts/plots |
| `modules/mt_engine_exact.py` | Mersenne Twister exact engine | MT19937 sequences |
| `modules/learning_telemetry.py` | Selfplay learning metrics | Telemetry data |

---

## 13. RESULTS & OUTPUT DIRECTORIES (Runtime, Not in Repo)

```
results/
├── summaries/              # Human-readable text summaries
├── csv/                    # Excel-compatible data
├── json/                   # Machine-readable structured data
├── detailed/               # Complete raw data
├── configs/                # Run configurations
└── *.json                  # Legacy format (backward compatible)

models/reinforcement/       # Step 5 output
├── best_model.meta.json    # Sidecar (model type, features, metrics)
├── best_model.pth          # If neural_net won
├── best_model.json         # If xgboost won
├── best_model.txt          # If lightgbm won
└── best_model.cbm          # If catboost won (only ONE exists per run)

predictions/                # Step 6 output
├── ranked_predictions.json # All survivors ranked (~50 MB)
├── prediction_pools.json   # Tight/Balanced/Wide pools (~5 MB)
└── next_draw_prediction.json # Aggregated prediction (~10 KB)

scorer_trial_results/       # Step 2.5 per-trial outputs
└── trial_{0000..N}.json    # One per trial

scored_chunks/              # Step 3 intermediate chunks
└── chunk_{0000..N}.json    # One per scoring chunk

optuna_studies/             # Persistent Optuna databases
├── optuna_window_opt.db
├── optuna_scorer_meta.db
└── optuna_anti_overfit.db

policy_history/             # Selfplay policy archive
└── {policy_id}.json

diagnostics_outputs/        # Chapter 14 (deferred, not yet implemented)
├── training_diagnostics.json
├── tier_comparison.json
└── history/

state/                      # WATCHER state
├── watcher_failures.jsonl
└── strategy_recommendation.json

watcher_requests/           # Ch13 → WATCHER retrain requests
└── retrain_request_{id}.json

logs/
└── watcher_agent.log

/dev/shm/prng/step3/        # Ramdisk (ephemeral, lost on reboot)
├── train_history.json
└── holdout_history.json
```

---

## 14. DOCUMENTATION

### Chapter Documentation (Whitepaper)

| File | Covers |
|------|--------|
| `CHAPTER_1_WINDOW_OPTIMIZER.md` | Step 1: Bayesian window optimization |
| `CHAPTER_2_BIDIRECTIONAL_SIEVE.md` | Step 2: Forward/reverse sieve theory |
| `CHAPTER_3_SCORER_META_OPTIMIZER.md` | Step 2.5: Scorer hyperparameter tuning |
| `CHAPTER_4_FULL_SCORING.md` | Step 3: 64-feature distributed scoring |
| `CHAPTER_5_ML_ARCHITECTURE_OPTIMIZER_v2.md` | Step 4: Adaptive capacity planning |
| `CHAPTER_6_ANTI_OVERFIT_TRAINING.md` | Step 5: K-fold cross-validation, multi-model |
| `CHAPTER_7_PREDICTION_GENERATOR.md` | Step 6: Pool generation and ranking |
| `CHAPTER_8_PRNG_REGISTRY.md` | 46 PRNG algorithm implementations |
| `CHAPTER_9_GPU_CLUSTER_INFRASTRUCTURE.md` | Hardware, ROCm, ramdisk, deployment |
| `CHAPTER_10_AUTONOMOUS_AGENT_FRAMEWORK_v3.md` | Agent architecture and manifests |
| `CHAPTER_11_FEATURE_IMPORTANCE_VISUALIZATION.md` | Feature analysis and visualization |
| `CHAPTER_12_WATCHER_AGENT.md` | WATCHER orchestrator + fingerprint registry |
| `CHAPTER_12_ADDENDUM_v1_3_0.md` | Preflight checks, freshness, cleanup |
| `CHAPTER_12_ADDENDUM_PHASE1_v1_1_2.md` | Hard/soft preflight, manifest IO mapping |
| `CHAPTER_13_LIVE_FEEDBACK_LOOP_v1_1.md` | Live feedback loop design |
| `CHAPTER_13_SECTION_19_UPDATED.md` | Updated Ch13 section |
| `CHAPTER_13_IMPLEMENTATION_PROGRESS_v3_0.md` | Implementation tracker |
| `CHAPTER_14_TRAINING_DIAGNOSTICS.md` | Training diagnostics (v1.1.2, DEFERRED) |

### Proposals & Contracts

| File | Purpose |
|------|---------|
| `PROPOSAL_Multi_Model_Architecture_v3_1_2_FINAL.md` | Multi-model architecture spec |
| `PROPOSAL_Unified_Agent_Context_Framework_v3_2_0.md` | Bundle factory design |
| `PROPOSAL_Addendum_E.md` | Addendum to agent framework |
| `PROPOSAL_LLM_Infrastructure_Optimization_v1_1.md` | DeepSeek-R1-14B upgrade |
| `CONTRACT_SELFPLAY_CHAPTER13_AUTHORITY_v1_0.md` | Authority boundaries |
| `CONTRACT_LLM_STRATEGY_ADVISOR_v1_0.md` | Strategy advisor contract |
| `RESPONSE_Persistent_GPU_Workers_Proposal_DECLINED.md` | Declined proposal |

### Guides & References

| File | Purpose |
|------|---------|
| `COMPLETE_OPERATING_GUIDE_v1_1.md` | Master operating manual |
| `Cluster_operating_manual.txt` | Cluster operations quick reference |
| `instructions.txt` | Development instructions |
| `README.md` | Project overview + quick start |
| `PROJECT_MAP.md` | AI-friendly system navigation |
| `CANONICAL_PIPELINE_AND_CH13_WITH_STARTUP_COMPLETE.md` | Canonical pipeline reference |
| `combined_agent_framework__1_.md` | Agent framework design |

### Session Tracking

| File | Purpose |
|------|---------|
| `SESSION_CHANGELOG_20260130.md` | January 30 changes |
| `SESSION_CHANGELOG_20260130_S4.md` | January 30 Session 4 |
| `SESSION_CHANGELOG_20260201.md` | February 1 changes |
| `IMPLEMENTATION_CHECKLIST_v3_1_2.md` | Multi-model implementation tracker |
| `TODO_PHASE7_WATCHER_INTEGRATION_REVISED_v3.md` | Phase 7 task tracker |
| `PHASE_9B2_INTEGRATION_SPEC.md` | Phase 9B.2 integration spec |

### Specifications & Math

| File | Purpose |
|------|---------|
| `BIDIRECTIONAL_SIEVE_MATHEMATICAL_WHITEPAPER.md` | Sieve mathematics |
| `INSTRUCTIONS_NPZ_ADDITION.md` | NPZ binary format instructions |

### PDFs (Strategy Documents)

| File | Purpose |
|------|---------|
| `High_Probability_Draw_Pools_Plan.pdf` | Pool strategy |
| `Forward_Reverse_Sieve_Strategy_Plan.pdf` | Sieve strategy |
| `Functional_Mimicry_via_Reinforcement.pdf` | Core paradigm |
| `Functional_Mimicry_via_Reinforcement_v1_1.pdf` | Updated paradigm |
| `Reverse_Sieve_Epiphany_Strategy_1.pdf` | Reverse sieve insight |
| `Persistent_GPU_Workers_ROCm_Stability_Proposal.pdf` | GPU worker proposal |

---

## 15. PIPELINE DATA FLOW (Input → Output Chain)

```
synthetic_lottery.json (raw draw data)
        │
        ▼
    ┌─── Step 1: window_optimizer.py ───┐
    │  IN:  synthetic_lottery.json       │
    │  OUT: optimal_window_config.json   │
    │       bidirectional_survivors.json │
    │       forward_survivors.json       │
    │       reverse_survivors.json       │
    │       train_history.json (80%)     │
    │       holdout_history.json (20%)   │
    └───────────────┬───────────────────┘
                    │
    ┌─── convert_survivors_to_binary.py ─┐
    │  IN:  bidirectional_survivors.json  │
    │  OUT: *_binary.npz (88× faster)    │
    └───────────────┬────────────────────┘
                    │
    ┌─── Step 2.5: run_scorer_meta_optimizer.sh ──┐
    │  IN:  .npz, train, holdout                  │
    │  OUT: optimal_scorer_config.json             │
    │       scorer_trial_results/trial_*.json      │
    └───────────────┬─────────────────────────────┘
                    │
    ┌─── Step 3: run_step3_full_scoring.sh ───┐
    │  IN:  .npz, scorer config, train, holdout│
    │  OUT: survivors_with_scores.json         │
    │       (64 features × all survivors)      │
    └───────────────┬──────────────────────────┘
                    │
    ┌─── Step 4: adaptive_meta_optimizer.py ──┐
    │  IN:  optimal_window_config, train       │
    │  OUT: reinforcement_engine_config.json   │
    └───────────────┬──────────────────────────┘
                    │
    ┌─── Step 5: meta_prediction_optimizer_anti_overfit.py ──┐
    │  IN:  survivors_with_scores.json, train, config        │
    │  OUT: best_model.meta.json (sidecar)                   │
    │       best_model.{pth|json|cbm|txt} (checkpoint)       │
    └───────────────┬────────────────────────────────────────┘
                    │
    ┌─── Step 6: prediction_generator.py ─────┐
    │  IN:  model + sidecar, forward survivors │
    │  OUT: ranked_predictions.json            │
    │       prediction_pools.json              │
    │       next_draw_prediction.json          │
    └──────────────────────────────────────────┘
```

---

## 16. WATCHER EXECUTION MAPPING

| Step | STEP_SCRIPTS (Executed) | STEP_MANIFESTS (Config) |
|------|------------------------|-------------------------|
| 1 | `window_optimizer.py` | `window_optimizer.json` |
| 2 | `run_scorer_meta_optimizer.sh` (NOT .py!) | `scorer_meta.json` |
| 3 | `run_step3_full_scoring.sh` | `full_scoring.json` |
| 4 | `adaptive_meta_optimizer.py` | `ml_meta.json` |
| 5 | `meta_prediction_optimizer_anti_overfit.py` | `reinforcement.json` |
| 6 | `prediction_generator.py` | `prediction.json` |

---

## 17. HARDWARE CLUSTER

| Node | IP | GPUs | Backend | CPU | VRAM/card |
|------|----|------|---------|-----|-----------|
| Zeus | localhost | 2× RTX 3080 Ti | CUDA 12.x | — | 12 GB |
| rig-6600 | 192.168.3.120 | 12× RX 6600 | ROCm 6.4.3 | i5-9400 (6c) | 8 GB |
| rig-6600b | 192.168.3.154 | 12× RX 6600 | ROCm 6.4.3 | i5-8400 (6c) | 8 GB |
| rig-6600c | 192.168.3.162 | 8× RX 6600 (planned) | ROCm 6.4.3 | — | 8 GB |

**Combined:** ~34 GPUs, ~285 TFLOPS  
**Note:** rig-6600b GPU[4] slot 5 has chronic loose connection — PCIe set to Gen 1

---

## 18. STATUS SUMMARY

| Component | Status |
|-----------|--------|
| 6-Step Pipeline | ✅ Production ready |
| 46 PRNG Algorithms | ✅ Complete |
| Chapter 13 (Live Feedback) | ✅ Code complete |
| WATCHER Agent | ✅ Phase 7 complete |
| WATCHER Dispatch | ✅ Selfplay + learning loop wired |
| Bundle Factory | ✅ All 7 bundle types pass self-test |
| Selfplay (Phase 9B.2) | ✅ Policy-conditioned episodes |
| Multi-Model Architecture | ✅ 4 model types, subprocess isolation |
| Soak Test A | ⬜ Not started (daemon endurance) |
| Soak Test B | ✅ PASSED + CERTIFIED |
| Soak Test C | ⬜ Not started (full autonomous loop) |
| Chapter 14 (Diagnostics) | ⬜ Design complete, implementation DEFERRED |
| Phase 9B.3 (Auto Policy) | ⬜ Deferred until 9B.2 validated |
| Parameter Advisor | ⬜ Deferred until Steps 4-6 in production |

---

*End of File Catalog — Distributed PRNG Analysis System*
