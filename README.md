# ğŸ² Distributed PRNG Analysis & Functional Mimicry System

**Multi-GPU Cluster â€¢ Autonomous AI Agents â€¢ ML Scoring â€¢ Selfplay Learning â€¢ Optuna Meta-Optimization**

---

## ğŸ“Œ Project Overview

A fully distributed, AI-driven analysis system designed to:

- ğŸ§  Reverse-engineer PRNG behavior through functional mimicry
- âš™ï¸ Brute-force and sieve candidate seeds using GPU-accelerated forward/reverse filtering
- ğŸ“Š Score survivors using statistical and ML-based probability matching
- ğŸ§ª Optimize parameters using Optuna (Bayesian TPE Meta-Optimizer)
- ğŸ§¬ Reinforce high-confidence candidates using pattern feedback learning
- ğŸ¤– Automate pipeline execution via AI Agent Architecture
- ğŸš€ Scale across **26 GPUs** using a pull-based distributed architecture

---

## ğŸ†• Recent Updates (February 2026)

### Sessions 57-59: Phase 7 WATCHER Integration â€” COMPLETE âœ…
- âœ… **FULL AUTONOMY ACHIEVED** â€” End-to-end Chapter 13 â†’ WATCHER â†’ Selfplay loop
- âœ… Dispatch module (`watcher_dispatch.py`) â€” selfplay, learning loop, request processing
- âœ… Bundle factory (`bundle_factory.py`) â€” unified LLM context assembly (7 bundle types)
- âœ… LLM lifecycle management â€” automatic stop/restart around GPU-intensive phases
- âœ… 5 integration bugs found and fixed in D5 end-to-end testing
- âœ… Grammar-constrained LLM evaluation with real DeepSeek-R1 responses

### Session 56: Selfplay Validation + LLM Infrastructure
- âœ… Selfplay system validated â€” 8 episodes, 3 candidates, policy-conditioned mode
- âœ… LLM infrastructure upgraded â€” 8K â†’ 32K context windows
- âœ… LLM lifecycle management deployed

### Sessions 53-55: Chapter 13 + Selfplay Architecture
- âœ… Policy transform module â€” stateless, deterministic, pure functional
- âœ… Policy-conditioned episodes â€” filter, weight, mask transforms
- âœ… Authority contract ratified: Chapter 13 decides, WATCHER executes, selfplay explores

ğŸ“„ See `docs/SESSION_CHANGELOG_*.md` for detailed session history.

---

## ğŸ”— 6-Step Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         COMPLETE PIPELINE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Step 1          Step 2.5        Step 3         Step 4         Step 5       â”‚
â”‚  Window â”€â”€â”€â”€â”€â”€â”€â–º Scorer â”€â”€â”€â”€â”€â”€â”€â–º Full â”€â”€â”€â”€â”€â”€â”€â”€â–º ML Meta â”€â”€â”€â”€â”€â–º Anti-        â”‚
â”‚  Optimizer       Meta-Opt        Scoring        Optimizer      Overfit      â”‚
â”‚                                                                    â”‚        â”‚
â”‚  Bayesian        Distributed     26-GPU         Adaptive          â”‚        â”‚
â”‚  TPE             Optuna          Scoring        Architecture      â”‚        â”‚
â”‚                                                                    â–¼        â”‚
â”‚                                                              Step 6         â”‚
â”‚                                                              Prediction     â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Step | Name | Script | Output |
|------|------|--------|--------|
| 1 | Window Optimizer | `window_optimizer.py` | `bidirectional_survivors.json` |
| 2.5 | Scorer Meta-Optimizer | `generate_scorer_jobs.py` | `optimal_scorer_config.json` |
| 3 | Full Scoring | `generate_full_scoring_jobs.py` | `survivors_with_scores.json` |
| 4 | ML Meta-Optimizer | `adaptive_meta_optimizer.py` | `reinforcement_engine_config.json` |
| 5 | Anti-Overfit Training | `meta_prediction_optimizer_anti_overfit.py` | `best_model.pth` |
| 6 | Prediction | `reinforcement_engine.py` | `prediction_pool.json` |

ğŸ“„ See `PROJECT_MAP.md` for complete system logic and module organization.

---

## ğŸ¤– AI Agent Architecture

The system includes a complete AI agent framework for autonomous pipeline execution:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ZEUS DUAL-LLM LAYER                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   GPU0: PRIMARY LLM     â”‚    â”‚   GPU1: SPECIALIST LLM  â”‚                 â”‚
â”‚  â”‚   DeepSeek-R1-14B        â”‚    â”‚   (Configurable)         â”‚                 â”‚
â”‚  â”‚   Port: 8080            â”‚    â”‚   Port: 8081            â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                             â–¼                                                â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚                  â”‚    LLM Router       â”‚                                     â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI AGENT LAYER                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ WindowOptAgent â”‚  â”‚ ScorerMetaAgentâ”‚  â”‚ PredictionAgentâ”‚  ...            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Components

| Directory | Purpose |
|-----------|---------|
| `agents/` | BaseAgent class, agent implementations |
| `agent_manifests/` | JSON configuration for each pipeline step |
| `llm_services/` | Dual-LLM router and server management |

### 6 Pipeline Agents

| Agent | Step | Manifest |
|-------|------|----------|
| WindowOptimizerAgent | 1 | `window_optimizer.json` |
| ScorerMetaAgent | 2.5 | `scorer_meta.json` |
| FullScoringAgent | 3 | `full_scoring.json` |
| MLMetaAgent | 4 | `ml_meta.json` |
| ReinforcementAgent | 5 | `reinforcement.json` |
| PredictionAgent | 6 | `prediction.json` |

ğŸ“„ See `docs/proposals/` for complete architecture documentation.

---

## ğŸ–¥ Multi-Node Cluster

| Node | GPUs | Type | Purpose |
|------|------|------|---------|
| Zeus (Primary) | 2Ã— RTX 3080 Ti | CUDA | Orchestration, LLM hosting, job generation |
| rig-6600 | 12Ã— RX 6600 | ROCm | Worker Node 1 |
| rig-6600b | 12Ã— RX 6600 | ROCm | Worker Node 2 |
| rig-6600c | (deploying) | ROCm | Worker Node 3 (192.168.3.162) |
| **Total** | **26+ GPUs** | | **~285 TFLOPS** |

### ROCm Activation (AMD rigs)

```bash
export HSA_OVERRIDE_GFX_VERSION=10.3.0
source ~/rocm_env/bin/activate
```

---

## ğŸ§¬ PRNG Support

**46 PRNG Algorithms** across 11+ families with 4 variants each:

| Family | Base | Hybrid | Reverse | Hybrid+Reverse |
|--------|------|--------|---------|----------------|
| java_lcg | âœ… | âœ… | âœ… | âœ… |
| mt19937 | âœ… | âœ… | âœ… | âœ… |
| xorshift32 | âœ… | âœ… | âœ… | âœ… |
| xorshift64 | âœ… | âœ… | âœ… | âœ… |
| xorshift128 | âœ… | âœ… | âœ… | âœ… |
| pcg32 | âœ… | âœ… | âœ… | âœ… |
| lcg32 | âœ… | âœ… | âœ… | âœ… |
| minstd | âœ… | âœ… | âœ… | âœ… |
| xoshiro256pp | âœ… | âœ… | âœ… | âœ… |
| philox4x32 | âœ… | âœ… | âœ… | âœ… |
| sfc64 | âœ… | âœ… | âœ… | âœ… |

All kernels in `prng_registry.py` (~174KB, 4000+ lines).

---

## ğŸ“ Project Structure

```
distributed_prng_analysis/
â”‚
â”œâ”€â”€ agents/                    # AI Agent implementations
â”‚   â”œâ”€â”€ watcher_agent.py       # Main WATCHER orchestrator
â”‚   â”œâ”€â”€ watcher_dispatch.py    # Selfplay/learning dispatch
â”‚   â””â”€â”€ contexts/
â”‚       â””â”€â”€ bundle_factory.py  # LLM context assembly
â”‚
â”œâ”€â”€ agent_grammars/            # GBNF grammar constraints
â”‚   â”œâ”€â”€ chapter_13.gbnf
â”‚   â”œâ”€â”€ watcher_decision.gbnf
â”‚   â””â”€â”€ agent_decision.gbnf
â”‚
â”œâ”€â”€ agent_manifests/           # JSON configs for 6 pipeline agents
â”‚   â”œâ”€â”€ window_optimizer.json
â”‚   â”œâ”€â”€ scorer_meta.json
â”‚   â”œâ”€â”€ full_scoring.json
â”‚   â”œâ”€â”€ ml_meta.json
â”‚   â”œâ”€â”€ reinforcement.json
â”‚   â””â”€â”€ prediction.json
â”‚
â”œâ”€â”€ llm_services/              # Dual-LLM infrastructure
â”‚   â”œâ”€â”€ llm_router.py
â”‚   â”œâ”€â”€ llm_server_config.json
â”‚   â””â”€â”€ start_llm_servers.sh
â”‚
â”œâ”€â”€ core/                      # Results management
â”‚   â””â”€â”€ results_manager.py
â”‚
â”œâ”€â”€ integration/               # Adapters and bridges
â”‚   â”œâ”€â”€ metadata_writer.py
â”‚   â””â”€â”€ sieve_integration.py
â”‚
â”œâ”€â”€ schemas/                   # Data schemas (v1.0.4)
â”‚   â”œâ”€â”€ results_schema_v1.json
â”‚   â””â”€â”€ output_templates.json
â”‚
â”œâ”€â”€ modules/                   # Analytics, visualization, UI
â”œâ”€â”€ docs/                      # Proposals, whitepapers
â”œâ”€â”€ optuna_studies/            # Persistent Optuna DBs
â”œâ”€â”€ results/                   # Output files
â”‚
â”œâ”€â”€ coordinator.py             # 26-GPU distributed controller
â”œâ”€â”€ distributed_worker.py      # GPU worker script
â”œâ”€â”€ prng_registry.py           # 46 PRNG kernels
â”œâ”€â”€ selfplay_orchestrator.py   # Selfplay learning loop
â”œâ”€â”€ policy_transform.py        # Pure-functional policy transforms
â”œâ”€â”€ policy_conditioned_episode.py  # Policy-conditioned episodes
â”œâ”€â”€ reinforcement_engine.py    # ML training engine
â”œâ”€â”€ window_optimizer.py        # Step 1
â”œâ”€â”€ generate_scorer_jobs.py    # Step 2.5
â”‚
â”œâ”€â”€ PROJECT_MAP.md             # System navigation
â””â”€â”€ README.md                  # This file
```

---

## ğŸš€ Quick Start

### Run Complete Pipeline

```bash
python3 complete_whitepaper_workflow_with_meta_optimizer.py \
    --lottery-file synthetic_lottery.json \
    --window-opt-trials 10 \
    --seed-count 10000000 \
    --scorer-trials 20 \
    --anti-overfit-trials 10 \
    --k-folds 5 \
    --prng-type java_lcg \
    --test-both-modes
```

### Run Individual Steps

```bash
# Step 1: Window Optimization
python3 window_optimizer.py --lottery-file data.json --trials 50

# Step 2.5: Scorer Meta-Optimization  
python3 generate_scorer_jobs.py --trials 100 --study scorer_meta

# Run coordinator for distributed execution
python3 coordinator.py --jobs-file scorer_jobs.json
```

### Start LLM Servers (for AI agents)

```bash
cd llm_services
./start_llm_servers.sh
```

---

## ğŸ“Š Progress Display

The system includes a rich terminal progress display via tmux:

```bash
# Auto-launches with workflow script
# Or manually:
tmux new-session -d -s prng
tmux split-window -h "python3 progress_monitor.py"
tmux attach -t prng
```

Shows: Progress bar, ETA, seeds/sec, per-node GPU stats.

---

## ğŸ” Git SSH Auto-Sync

```bash
ssh -T git@github.com
git push   # No credentials required
```

---

## ğŸ“„ Key Documentation

| File | Purpose |
|------|---------|
| `PROJECT_MAP.md` | ğŸŒŸ Logical, AI-friendly navigation map |
| `docs/proposals/README.md` | Agent architecture proposals |
| `complete_workflow_guide_v2.md` | Full pipeline execution guide |
| `instructions.txt` | Development instructions |

---

## ğŸ§­ Roadmap

- [x] 26-GPU distributed architecture
- [x] 46 PRNG algorithms (forward + reverse)
- [x] 6-step pipeline with autonomous execution
- [x] LLM infrastructure (DeepSeek-R1-14B, 32K context)
- [x] Agent manifests (6 pipeline steps)
- [x] WATCHER Agent â€” autonomous pipeline orchestration
- [x] Chapter 13 â€” live feedback loop (10 files, ~226KB)
- [x] Selfplay system â€” policy-conditioned reinforcement learning
- [x] Full WATCHER dispatch â€” Chapter 13 â†’ Selfplay â†’ Learning loop
- [x] Bundle factory â€” unified LLM context assembly
- [x] LLM lifecycle management (stop/restart around GPU phases)
- [ ] Parameter advisor (LLM-advised recommendations for Steps 4-6)
- [ ] Phase 9B.3 (automatic policy proposal heuristics)
- [ ] WebUI for visualization

---

## ğŸ’¡ Design Principles

- **Modular**: All components JSON-configurable
- **Distributed**: 26-GPU pull-based architecture
- **AI-Native**: Designed for agent automation from day one
- **Backward Compatible**: All changes are additive
- **ML-Ready**: Structured outputs for ML training

---

## ğŸ¤ Contributing

Open an issue, fork the repo, or propose improvements.

---

*Distributed PRNG Analysis System â€” Functional mimicry through ML-enhanced pattern detection and autonomous selfplay learning*
