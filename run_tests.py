#!/usr/bin/env python3
"""
CORRECTED STANDALONE TEST SCRIPT FOR survivor_scorer.py
Uses YOUR actual prng_registry.py to generate test data

This ensures 100% accuracy by using the SAME implementation
for both test data generation AND scoring.

Run: python3 run_tests_corrected.py
"""

import json
import sys
import os

print("=" * 70)
print("SURVIVOR_SCORER.PY - CORRECTED TEST SUITE")
print("Using YOUR prng_registry.py for 100% accuracy")
print("=" * 70)

# Step 1: Check dependencies
print("\n[Step 1] Checking dependencies...")

if not os.path.exists('prng_registry.py'):
    print("‚ùå ERROR: prng_registry.py not found!")
    print("   This test needs YOUR actual prng_registry.py")
    sys.exit(1)
else:
    print("‚úÖ Found prng_registry.py")

if not os.path.exists('survivor_scorer.py'):
    print("‚ùå ERROR: survivor_scorer.py not found!")
    sys.exit(1)
else:
    print("‚úÖ Found survivor_scorer.py")

# Step 2: Import modules
print("\n[Step 2] Importing modules...")
try:
    from survivor_scorer import SurvivorScorer
    print("‚úÖ Successfully imported SurvivorScorer")
except ImportError as e:
    print(f"‚ùå ERROR: Could not import survivor_scorer: {e}")
    sys.exit(1)

try:
    from prng_registry import get_cpu_reference
    print("‚úÖ Successfully imported prng_registry")
except ImportError as e:
    print(f"‚ùå ERROR: Could not import prng_registry: {e}")
    sys.exit(1)

# Step 3: Create test data using YOUR prng_registry
print("\n[Step 3] Creating test data using YOUR prng_registry...")
KNOWN_SEED = 42424242
NUM_DRAWS = 500
MOD = 1000

# Use YOUR actual Java LCG implementation
java_lcg = get_cpu_reference('java_lcg')
raw_outputs = java_lcg(KNOWN_SEED, NUM_DRAWS, 0)
draws = [x % MOD for x in raw_outputs]

# Save test data
test_data = [
    {"draw": draw, "session": "test", "timestamp": 1000000 + i}
    for i, draw in enumerate(draws)
]

with open('test_synthetic_corrected.json', 'w') as f:
    json.dump(test_data, f, indent=2)

print(f"‚úÖ Created test_synthetic_corrected.json with {len(draws)} draws")
print(f"   First 10: {draws[:10]}")
print(f"   Known seed: {KNOWN_SEED}")

# Step 4: Test basic scoring with CORRECT seed
print("\n" + "=" * 70)
print("[Test 1] Basic Scoring - CORRECT SEED (Should be 100%)")
print("=" * 70)
scorer = SurvivorScorer(prng_type='java_lcg', mod=MOD)
result = scorer.score_survivor(KNOWN_SEED, draws, skip=0)
print(f"Score: {result['score']:.2f}%")
print(f"Matches: {result['exact_matches']}/{result['total_predictions']}")

if result['score'] >= 99.0:  # Allow for tiny rounding errors
    print("‚úÖ PASS - Perfect score!")
elif result['score'] >= 50.0:
    print(f"‚ö†Ô∏è  PARTIAL - Expected 100%, got {result['score']:.2f}%")
    print("   This might be due to offset or skip differences")
    print("   But the seed is clearly much better than random!")
else:
    print(f"‚ùå FAIL - Expected 100%, got {result['score']:.2f}%")

# Step 5: Test with offset search (in case there's alignment issues)
print("\n" + "=" * 70)
print("[Test 1b] Basic Scoring with Offset Search")
print("=" * 70)
result_offset = scorer.score_survivor(KNOWN_SEED, draws, skip=0, offset_search=True, max_offset=10)
print(f"Score: {result_offset['score']:.2f}%")
print(f"Matches: {result_offset['exact_matches']}/{result_offset['total_predictions']}")
print(f"Best Offset: {result_offset['best_offset']}")

if result_offset['score'] >= 99.0:
    print("‚úÖ PASS - Perfect score with offset search!")
else:
    print(f"‚ö†Ô∏è  Score: {result_offset['score']:.2f}% even with offset search")

# Step 6: Test basic scoring with WRONG seed
print("\n" + "=" * 70)
print("[Test 2] Basic Scoring - WRONG SEED")
print("=" * 70)
wrong_result = scorer.score_survivor(12345678, draws, skip=0)
print(f"Score: {wrong_result['score']:.2f}%")
print(f"Matches: {wrong_result['exact_matches']}/{wrong_result['total_predictions']}")

if wrong_result['score'] < 5.0:
    print("‚úÖ PASS - Correctly identified as wrong seed!")
else:
    print(f"‚ö†Ô∏è  WARNING - Expected <5%, got {wrong_result['score']:.2f}%")

# Step 7: Test ML feature extraction
print("\n" + "=" * 70)
print("[Test 3] ML Feature Extraction")
print("=" * 70)
features = scorer.extract_ml_features(KNOWN_SEED, draws, skip=0)
print(f"Extracted {len(features)} features")
print(f"\nTop features:")
for key in ['score', 'residue_8_coherence', 'skip_entropy', 'temporal_stability_mean']:
    if key in features:
        print(f"  {key}: {features[key]:.4f}")

if len(features) >= 43:
    print(f"‚úÖ PASS - Extracted {len(features)} features!")
else:
    print(f"‚ö†Ô∏è  WARNING - Expected 43+ features, got {len(features)}")

# Step 8: Test dual-sieve methods
print("\n" + "=" * 70)
print("[Test 4] Dual-Sieve Methods")
print("=" * 70)

forward_survivors = [KNOWN_SEED, 12345678, 87654321, 99999999]
reverse_survivors = [KNOWN_SEED, 11111111, 87654321, 55555555]

print("Testing calculate_survivor_overlap_ratio()...")
overlap = scorer.calculate_survivor_overlap_ratio(forward_survivors, reverse_survivors)
print(f"  Jaccard Index: {overlap['jaccard_index']:.4f}")
print(f"  Intersection: {overlap['intersection_seeds']}")

if KNOWN_SEED in overlap['intersection_seeds']:
    print("  ‚úÖ Correct seed in intersection!")

print("\nTesting compute_dual_sieve_intersection()...")
intersection = scorer.compute_dual_sieve_intersection(forward_survivors, reverse_survivors)
print(f"  High-confidence seeds: {intersection}")

if KNOWN_SEED in intersection:
    print("  ‚úÖ Correct seed identified!")

print("\nTesting score_with_dual_sieve()...")
dual_score = scorer.score_with_dual_sieve(
    KNOWN_SEED, draws, forward_survivors, reverse_survivors, skip=0
)
print(f"  Dual-Sieve Score: {dual_score['dual_sieve_score']:.2f}%")
print(f"  In Intersection: {dual_score['in_intersection']}")

print("\nTesting build_prediction_pool()...")
pool = scorer.build_prediction_pool(
    survivors=intersection,
    lottery_history=draws,
    pool_size=2,
    use_dual_scoring=True,
    forward_survivors=forward_survivors,
    reverse_survivors=reverse_survivors
)
print(f"  Pool Size: {pool['pool_size']}")
print(f"  Top seed: {pool['pool'][0]['seed']}")

if pool['pool'][0]['seed'] == KNOWN_SEED:
    print("  ‚úÖ Correct seed ranked #1!")

print("\nTesting rank_by_dual_confidence()...")
ranked = scorer.rank_by_dual_confidence(
    forward_survivors, draws, forward_survivors, reverse_survivors
)
print(f"  Top seed: {ranked[0]['seed']}")

if ranked[0]['seed'] == KNOWN_SEED:
    print("  ‚úÖ Correct seed ranked #1 by dual-confidence!")

# Final Summary
print("\n" + "=" * 70)
print("TEST SUMMARY")
print("=" * 70)

if result['score'] >= 99.0:
    print("‚úÖ PERFECT - 100% score achieved!")
    print("‚úÖ All methods operational")
    print("‚úÖ Ready for production!")
elif result_offset['score'] >= 99.0:
    print("‚úÖ EXCELLENT - 100% score with offset search!")
    print("‚úÖ Make sure to use offset_search=True in production")
    print("‚úÖ All methods operational")
elif result['score'] >= 50.0:
    print("‚ö†Ô∏è  PARTIAL SUCCESS")
    print(f"   Correct seed: {result['score']:.2f}% (much better than random)")
    print(f"   Wrong seed: {wrong_result['score']:.2f}% (random chance)")
    print("   All methods working but score not 100%")
    print("\n   Possible causes:")
    print("   - Offset alignment issue (try offset_search=True)")
    print("   - Skip parameter difference")
    print("   - PRNG state initialization difference")
else:
    print("‚ùå ISSUES DETECTED")
    print(f"   Score too low: {result['score']:.2f}%")

print("\nüéâ Testing complete on YOUR computer!")
print("=" * 70)

print("\nüìÅ Files created:")
print("  - test_synthetic_corrected.json (using YOUR prng_registry)")

print("\nüìã If score is not 100%:")
print("  1. Check if offset_search=True helps")
print("  2. Try different skip values (0, 1, 10, etc.)")
print("  3. Check prng_registry.py implementation matches expected")

print("\n‚úÖ Next: Test with your REAL data (daily3.json)")
