#!/usr/bin/env python3
"""
GPU Residue Sieve - Main Engine
Flexible, modular, standalone sieve for PRNG seed discovery

Usage: python3 sieve_filter.py --job-file job.json --gpu-id 0

Compatible with coordinator.py and unified_system.py
"""

from adaptive_thresholds import estimate_background_thresholds, coerce_threshold
import argparse
import json
import time
import os
import sys
from typing import List, Dict, Any, Optional, Tuple

# ROCm environment setup - MUST BE FIRST
import socket
HOST = socket.gethostname()
if HOST in ["rig-6600", "rig-6600b"]:
    os.environ.setdefault("HSA_OVERRIDE_GFX_VERSION", "10.3.0")
    os.environ.setdefault("HSA_ENABLE_SDMA", "0")
os.environ.setdefault("ROCM_PATH", "/opt/rocm")
os.environ.setdefault("HIP_PATH", "/opt/rocm")

# Import PRNG registry
try:
    from prng_registry import KERNEL_REGISTRY, get_kernel_info, list_available_prngs
except ImportError:
    print("ERROR: prng_registry.py not found - must be in same directory", file=sys.stderr)
    sys.exit(1)

# GPU backend
try:
    import cupy as cp
    GPU_AVAILABLE = True
except ImportError:
    print("ERROR: CuPy not available - GPU required for sieve", file=sys.stderr)
    sys.exit(1)

import numpy as np


# ============================================================================
# DATASET LOADING
# ============================================================================

def load_draws_from_daily3(path: str, window_size: int = 30, sessions=None, offset: int = 0):
    """Load draws and return exactly `window_size` values starting at `offset`.

    - If sessions is provided, filter by session first.
    - Raises if the dataset is shorter than window_size.
    - Offset is clamped to a valid start (offset=0 means first entry in the file).
    """
    import json
    with open(path, 'r') as f:
        data = json.load(f)

    if sessions:
        data = [e for e in data if e.get('session') in sessions]

    n = len(data)
    if n < window_size:
        raise ValueError(f"Dataset has only {n} entries, need at least {window_size}")

    start = max(0, min(int(offset), n - window_size))
    end = start + window_size
    window = data[start:end]

    draws = [int(entry.get("full_state", entry["draw"])) for entry in window]
    return draws

# ============================================================================
# GPU SIEVE ENGINE
# ============================================================================

class GPUSieve:
    """GPU-accelerated flexible residue sieve"""

    def __init__(self, gpu_id: int = 0):
        if not GPU_AVAILABLE:
            raise RuntimeError("CuPy not available")

        self.gpu_id = gpu_id
        self.device = cp.cuda.Device(gpu_id)
        self.compiled_kernels = {}

    def _get_kernel(self, prng_family: str, custom_params: Optional[Dict] = None):
        """Get or compile kernel for PRNG family"""
        cache_key = f"{prng_family}_{hash(frozenset(custom_params.items()) if custom_params else 0)}"

        if cache_key in self.compiled_kernels:
            return self.compiled_kernels[cache_key]

        config = get_kernel_info(prng_family)
        kernel = cp.RawKernel(config['kernel_source'], config['kernel_name'])
        self.compiled_kernels[cache_key] = (kernel, config)

        return kernel, config

    def run_sieve(
        self,
        prng_family: str,
        seed_start: int,
        seed_end: int,
        residues: List[int],
        skip_range: Tuple[int, int] = (0, 16),
        min_match_threshold: float = 0.5,
        custom_params: Optional[Dict] = None,
        chunk_size: int = 1_000_000,
        offset: int = 0
    ) -> Dict[str, Any]:
        """Run flexible residue sieve for specified PRNG family"""

        with self.device:
            kernel, config = self._get_kernel(prng_family, custom_params)

            # Prepare inputs
            k = len(residues)
            residues_gpu = cp.array(residues, dtype=cp.uint32)
            skip_min, skip_max = skip_range

            # Result containers
            all_survivors = []
            all_match_rates = []
            all_best_skips = []
            total_tested = 0
            start_time = time.time()

            # Process in chunks
            for chunk_start in range(seed_start, seed_end, chunk_size):
                chunk_end = min(chunk_start + chunk_size, seed_end)
                n_seeds = chunk_end - chunk_start

                # Allocate arrays
                seed_type = config.get("seed_type", "uint32")
                dtype = cp.uint64 if seed_type == "uint64" else cp.uint32

                seeds_gpu = cp.arange(chunk_start, chunk_end, dtype=dtype)
                survivors_gpu = cp.zeros(n_seeds, dtype=dtype)
                match_rates_gpu = cp.zeros(n_seeds, dtype=cp.float32)
                best_skips_gpu = cp.zeros(n_seeds, dtype=cp.uint8)
                survivor_count_gpu = cp.zeros(1, dtype=cp.uint32)

                # Launch kernel
                threads_per_block = 256
                blocks = (n_seeds + threads_per_block - 1) // threads_per_block

                # Build kernel arguments
                kernel_args = [
                    seeds_gpu, residues_gpu, survivors_gpu,
                    match_rates_gpu, best_skips_gpu, survivor_count_gpu,
                    n_seeds, k, skip_min, skip_max, cp.float32(min_match_threshold)
                ]
                # Add PRNG-specific parameters
                default_params = config.get("default_params", {})

                if prng_family == 'xorshift32':
                    kernel_args.append(cp.int32(default_params.get("shift_a", 13)))
                    kernel_args.append(cp.int32(default_params.get("shift_b", 17)))
                    kernel_args.append(cp.int32(default_params.get("shift_c", 5)))
                elif prng_family == 'pcg32':
                    kernel_args.append(cp.uint64(default_params.get("increment", 1442695040888963407)))
                elif prng_family == 'lcg32':
                    kernel_args.append(cp.uint32(default_params.get("a", 1664525)))
                    kernel_args.append(cp.uint32(default_params.get("c", 1013904223)))
                    kernel_args.append(cp.uint32(default_params.get("m", 0xFFFFFFFF)))
                # mt19937 and xorshift64 have no extra params before offset

                # Add offset parameter LAST

                kernel_args.append(cp.int32(offset))

                # Execute kernel
                kernel((blocks,), (threads_per_block,), tuple(kernel_args))

                # Collect survivors
                count = int(survivor_count_gpu[0].get())
                if count > 0:
                    survivors = survivors_gpu[:count].get().tolist()
                    rates = match_rates_gpu[:count].get().tolist()
                    skips = best_skips_gpu[:count].get().tolist()

                    # DEBUG: Filter out false positives from kernel bug
                    for i, rate in enumerate(rates):
                        if rate >= min_match_threshold:
                            all_survivors.append(survivors[i])
                            all_match_rates.append(rate)
                            all_best_skips.append(skips[i])
                        else:
                            print(f"DEBUG: Filtered kernel false positive - seed {survivors[i]} rate {rate:.3f} < threshold {min_match_threshold}", file=sys.stderr)

                total_tested += n_seeds

            duration_ms = (time.time() - start_time) * 1000

            # Build detailed survivor records
            survivor_records = []
            for seed, rate, skip in zip(all_survivors, all_match_rates, all_best_skips):
                matches = int(rate * k)
                survivor_records.append({
                    'seed': int(seed),
                    'family': prng_family,
                    'match_rate': float(rate),
                    'matches': matches,
                    'total': k,
                    'best_skip': int(skip)
                })

            return {
                'family': prng_family,
                'seed_range': {'start': seed_start, 'end': seed_end},
                'survivors': survivor_records,
                'stats': {
                    'seeds_tested': total_tested,
                    'survivors_found': len(survivor_records),
                    'duration_ms': duration_ms,
                    'seeds_per_sec': total_tested / (duration_ms / 1000) if duration_ms > 0 else 0
                }
            }

    def run_hybrid_sieve(
        self,
        prng_family: str,
        seed_start: int,
        seed_end: int,
        residues: List[int],
        strategies: List[Dict[str, Any]],
        min_match_threshold: float = 0.5,
        chunk_size: int = 100_000,
        offset: int = 0
    ) -> Dict[str, Any]:
        """Run hybrid multi-strategy variable skip sieve"""

        # Import strategy helper
        try:
            from hybrid_strategy import analyze_skip_pattern
        except ImportError:
            print("WARNING: hybrid_strategy module not found, using basic analysis", file=sys.stderr)
            def analyze_skip_pattern(pattern):
                import statistics
                return {
                    'min': min(pattern) if pattern else 0,
                    'max': max(pattern) if pattern else 0,
                    'avg': statistics.mean(pattern) if pattern else 0,
                    'variance': statistics.variance(pattern) if len(pattern) > 1 else 0,
                    'std_dev': statistics.stdev(pattern) if len(pattern) > 1 else 0,
                }

        # Only mt19937_hybrid supports this mode
        if prng_family != 'mt19937_hybrid':
            raise ValueError(f"Hybrid sieve only supports mt19937_hybrid, got {prng_family}")

        with self.device:
            kernel, config = self._get_kernel(prng_family, None)

            k = len(residues)
            residues_gpu = cp.array(residues, dtype=cp.uint32)

            # Prepare strategy parameters
            n_strategies = len(strategies)
            strategy_max_misses = cp.array([s.max_consecutive_misses for s in strategies], dtype=cp.int32)
            strategy_tolerances = cp.array([s.skip_tolerance for s in strategies], dtype=cp.int32)

            # Result containers
            all_survivors = []
            all_match_rates = []
            all_strategy_ids = []
            all_skip_sequences = []
            total_tested = 0
            start_time = time.time()

            # Process in smaller chunks for hybrid (more memory intensive)
            for chunk_start in range(seed_start, seed_end, chunk_size):
                chunk_end = min(chunk_start + chunk_size, seed_end)
                n_seeds = chunk_end - chunk_start

                # Allocate arrays
                seeds_gpu = cp.arange(chunk_start, chunk_end, dtype=cp.uint32)
                survivors_gpu = cp.zeros(n_seeds, dtype=cp.uint32)
                match_rates_gpu = cp.zeros(n_seeds, dtype=cp.float32)
                strategy_ids_gpu = cp.zeros(n_seeds, dtype=cp.uint32)
                skip_sequences_gpu = cp.zeros(n_seeds * 512, dtype=cp.uint32)  # 512 draws max
                survivor_count_gpu = cp.zeros(1, dtype=cp.uint32)

                # Launch kernel
                threads_per_block = 256
                blocks = (n_seeds + threads_per_block - 1) // threads_per_block

                kernel_args = [
                    seeds_gpu, residues_gpu, survivors_gpu,
                    match_rates_gpu, skip_sequences_gpu, strategy_ids_gpu,
                    survivor_count_gpu, cp.int32(n_seeds), cp.int32(k),
                    strategy_max_misses, strategy_tolerances, cp.int32(n_strategies),
                    cp.float32(min_match_threshold), cp.int32(offset)
                ]

                kernel((blocks,), (threads_per_block,), kernel_args)
                cp.cuda.Device().synchronize()

                # Collect survivors
                count = int(survivor_count_gpu[0].get())
                if count > 0:
                    survivors = survivors_gpu[:count].get().tolist()
                    rates = match_rates_gpu[:count].get().tolist()
                    strat_ids = strategy_ids_gpu[:count].get().tolist()
                    skip_seqs = skip_sequences_gpu.get().reshape(n_seeds, 512)

                    for i in range(count):
                        if rates[i] >= min_match_threshold:
                            all_survivors.append(survivors[i])
                            all_match_rates.append(rates[i])
                            all_strategy_ids.append(strat_ids[i])
                            # Extract skip sequence for this survivor
                            skip_seq = skip_seqs[i, :k].tolist()
                            all_skip_sequences.append(skip_seq)

                total_tested += n_seeds

            duration_ms = (time.time() - start_time) * 1000

            # Build detailed survivor records with skip patterns
            survivor_records = []
            for seed, rate, strat_id, skip_seq in zip(
                all_survivors, all_match_rates, all_strategy_ids, all_skip_sequences
            ):
                matches = int(rate * k)
                skip_stats = analyze_skip_pattern(skip_seq)

                survivor_records.append({
                    'seed': int(seed),
                    'family': 'mt19937_hybrid',
                    'match_rate': float(rate),
                    'matches': matches,
                    'total': k,
                    'strategy_id': int(strat_id),
                    'strategy_name': strategies[strat_id].name if strat_id < len(strategies) else 'unknown',
                    'skip_pattern': skip_seq,
                    'skip_stats': skip_stats
                })

            return {
                'family': 'mt19937_hybrid',
                'seed_range': {'start': seed_start, 'end': seed_end},
                'survivors': survivor_records,
                'strategies_tested': n_strategies,
                'stats': {
                    'seeds_tested': total_tested,
                    'survivors_found': len(survivor_records),
                    'duration_ms': duration_ms,
                    'seeds_per_sec': total_tested / (duration_ms / 1000) if duration_ms > 0 else 0
                }
            }

# ============================================================================
# JOB EXECUTION
# ============================================================================

def execute_sieve_job(job: Dict[str, Any], gpu_id: int) -> Dict[str, Any]:
    """Execute a sieve job from job specification"""

    job_id = job.get('job_id', 'unknown')

    try:
        # Extract parameters
        dataset_path = job.get('dataset_path') or job.get('target_file')
        window_size = job.get('window_size', 10)
        seed_start = job.get('seed_start', 0)
        seed_end = job.get('seed_end', 100000)
        skip_range = tuple(job.get('skip_range', [0, 16]))
        min_match_threshold = job.get('min_match_threshold', 0.5)
        offset = job.get('offset', 0)
        sessions = job.get('sessions', ['midday', 'evening'])

        # Load draws
        draws = load_draws_from_daily3(dataset_path, window_size, sessions, offset)
        if not draws:
            raise ValueError("No draws loaded from dataset")

        # Get PRNG families to test
        prng_families = job.get('prng_families')
        if not prng_families:
            # Default: fast families
            prng_families = ['xorshift32', 'pcg32', 'mt19937']

        # Initialize sieve
        sieve = GPUSieve(gpu_id=gpu_id)

        # Run sieve for each family
        per_family_results = []
        all_survivors = []

        for family_spec in prng_families:
            # Handle both string names and dict with custom params
            if isinstance(family_spec, dict):
                family_name = family_spec['type']
                custom_params = family_spec.get('params', {})
            else:
                family_name = family_spec
                custom_params = None

            # Check if hybrid mode is enabled
            use_hybrid = job.get('hybrid', False)

            # Hybrid mode only works with mt19937
            if use_hybrid and family_name == 'mt19937':
                print(f"Testing {family_name} in HYBRID TWO-PHASE mode...", file=sys.stderr)

                # Get strategies from job
                strategies_data = job.get('strategies')
                if not strategies_data:
                    # Import default strategies
                    try:
                        from hybrid_strategy import get_all_strategies
                        strategies = get_all_strategies()
                    except ImportError:
                        print("WARNING: Hybrid mode requested but strategies not available", file=sys.stderr)
                        print("         Falling back to standard mode", file=sys.stderr)
                        use_hybrid = False
                        strategies = None
                else:
                    # Reconstruct strategy objects from dict data
                    from hybrid_strategy import StrategyConfig
                    strategies = [StrategyConfig(**s) for s in strategies_data]

                if use_hybrid and strategies:
                    # Get threshold settings (can be 'auto' or float)
                    phase1_in = job.get('phase1_threshold', 'auto')
                    phase2_in = job.get('phase2_threshold', 'auto')
                    
                    pilot_info = None
                    
                    # Coerce to float or 'auto'
                    phase1_threshold = coerce_threshold(phase1_in, 0.20)
                    phase2_threshold = coerce_threshold(phase2_in, 0.75)

                    # Run pilot if auto thresholds requested
                    if phase1_threshold == 'auto' or phase2_threshold == 'auto':
                        pilot_start_time = time.time()
                        print(f"  Running pilot to estimate adaptive thresholds...", file=sys.stderr)

                        # Create sequence generator for pilot
                        from prng_registry import mt19937_cpu
                        def generate_seq(seed, k, skip):
                            outputs = mt19937_cpu(seed, k * (skip + 2), skip=0)
                            result = []
                            idx = 0
                            for _ in range(k):
                                idx += skip
                                result.append(outputs[idx] % 1000)
                                idx += 1
                            return result

                        est_p1, est_p2 = estimate_background_thresholds(
                            draws=draws,
                            generate_sequence_func=generate_seq,
                            seed_start=seed_start,
                            seed_end=seed_end,
                            skip_range=skip_range,
                            k=window_size,
                            max_pilot_seeds=128
                        )
                        
                        pilot_duration = (time.time() - pilot_start_time) * 1000
                        pilot_info = {
                            'duration_ms': round(pilot_duration, 2),
                            'seed_range': [seed_start, seed_end],
                            'sample_size': min(128, seed_end - seed_start),
                            'estimated_phase1': est_p1,
                            'estimated_phase2': est_p2
                        }

                        if phase1_threshold == 'auto':
                            phase1_threshold = est_p1
                            print(f"  Auto Phase 1 threshold: {phase1_threshold:.3f} ({phase1_threshold:.1%})", file=sys.stderr)
                        if phase2_threshold == 'auto':
                            phase2_threshold = est_p2
                            print(f"  Auto Phase 2 threshold: {phase2_threshold:.3f} ({phase2_threshold:.1%})", file=sys.stderr)
                    
                    # Safety clamps (defense in depth)
                    phase1_threshold = max(0.001, min(0.30, phase1_threshold))
                    phase2_threshold = max(0.60, min(0.95, phase2_threshold))
                    
                    # Log final thresholds being used
                    print(f"  Using Phase 1: {phase1_threshold:.3f} ({phase1_threshold:.1%})", file=sys.stderr)
                    print(f"  Using Phase 2: {phase2_threshold:.3f} ({phase2_threshold:.1%})", file=sys.stderr)

                    print(f"  Phase 1: FULL MT19937 fixed-skip wide search", file=sys.stderr)

                    # PHASE 1: Wide search with FULL MT19937 and fixed skip
                    phase1_start = time.time()
                    phase1_result = sieve.run_sieve(
                        prng_family='mt19937',  # FULL MT19937 (same as test data)
                        seed_start=seed_start,
                        seed_end=seed_end,
                        residues=draws,
                        skip_range=skip_range,
                        min_match_threshold=phase1_threshold,
                        offset=offset
                    )
                    phase1_duration = (time.time() - phase1_start) * 1000

                    phase1_survivors = phase1_result.get('survivors', [])
                    print(f"  Phase 1 complete: {len(phase1_survivors)} survivors found ({phase1_duration:.1f}ms)", file=sys.stderr)

                    # PHASE 2: Deep dive on survivors only with variable skip
                    if phase1_survivors:
                        print(f"  Phase 2: Variable skip analysis on {len(phase1_survivors)} survivors", file=sys.stderr)
                        print(f"    Testing {len(strategies)} strategies", file=sys.stderr)

                        # Extract survivor seeds
                        survivor_seeds = [s['seed'] for s in phase1_survivors]

                        # Run hybrid on survivors only
                        phase2_start = time.time()
                        phase2_result = sieve.run_hybrid_sieve(
                            prng_family='mt19937_hybrid',  # SAME FULL MT19937, variable skip
                            seed_start=min(survivor_seeds),
                            seed_end=max(survivor_seeds) + 1,
                            residues=draws,
                            strategies=strategies,
                            min_match_threshold=phase2_threshold,
                            offset=offset
                        )
                        phase2_duration = (time.time() - phase2_start) * 1000

                        final_survivors = phase2_result.get('survivors', [])
                        print(f"  Phase 2 complete: {len(final_survivors)} final matches ({phase2_duration:.1f}ms)", file=sys.stderr)

                        # Build combined result
                        result = {
                            'family': 'mt19937_hybrid',
                            'seed_range': {'start': seed_start, 'end': seed_end},
                            'phase1': {
                                'survivors': len(phase1_survivors),
                                'tested': phase1_result.get('stats', {}).get('seeds_tested', 0),
                                'threshold': round(phase1_threshold, 4),
                                'duration_ms': round(phase1_duration, 2)
                            },
                            'phase2': {
                                'survivors': len(final_survivors),
                                'tested': len(phase1_survivors),
                                'threshold': round(phase2_threshold, 4),
                                'duration_ms': round(phase2_duration, 2),
                                'strategies_tested': len(strategies)
                            },
                            'survivors': final_survivors,
                            'stats': phase2_result.get('stats', {})
                        }
                        
                        # Add pilot info if available
                        if pilot_info:
                            result['pilot'] = pilot_info
                    else:
                        print(f"  Phase 1 found no survivors - skipping Phase 2", file=sys.stderr)
                        result = {
                            'family': 'mt19937_hybrid',
                            'seed_range': {'start': seed_start, 'end': seed_end},
                            'phase1': {
                                'survivors': 0,
                                'tested': phase1_result.get('stats', {}).get('seeds_tested', 0),
                                'threshold': round(phase1_threshold, 4),
                                'duration_ms': round(phase1_duration, 2)
                            },
                            'phase2': {'skipped': True},
                            'survivors': [],
                            'stats': phase1_result.get('stats', {})
                        }
                        
                        # Add pilot info if available
                        if pilot_info:
                            result['pilot'] = pilot_info

                    per_family_results.append(result)
                    all_survivors.extend(result['survivors'])
                    continue  # Skip duplicate fixed-skip pass after hybrid

            # Standard (non-hybrid) sieve
            print(f"Testing {family_name}...", file=sys.stderr)

            result = sieve.run_sieve(
                prng_family=family_name,
                seed_start=seed_start,
                seed_end=seed_end,
                residues=draws,
                skip_range=skip_range,
                offset=offset,
                min_match_threshold=min_match_threshold,
                custom_params=custom_params
            )

            per_family_results.append(result)
            all_survivors.extend(result['survivors'])

        # Compile final result
        total_tested = sum(r['stats']['seeds_tested'] for r in per_family_results)
        total_duration = sum(r['stats']['duration_ms'] for r in per_family_results)

        final_result = {
            'job_id': job_id,
            'success': True,
            'prng_families': [r['family'] for r in per_family_results],
            'seed_range': {'start': seed_start, 'end': seed_end},
            'k': len(draws),
            'skip_range': list(skip_range),
            'min_match_threshold': min_match_threshold,
            'survivors': all_survivors,
            'stats': {
                'total_seeds_tested': total_tested,
                'total_survivors': len(all_survivors),
                'duration_ms': total_duration,
                'avg_seeds_per_sec': total_tested / (total_duration / 1000) if total_duration > 0 else 0
            },
            'per_family': {
                r['family']: {
                    'survivors': r['survivors'],
                    'tested': r['stats']['seeds_tested'],
                    'found': r['stats']['survivors_found'],
                    'duration_ms': r['stats']['duration_ms']
                }
                for r in per_family_results
            },
            'seeds_analyzed': total_tested  # For coordinator compatibility
        }

        return final_result

    except Exception as e:
        import traceback
        return {
            'job_id': job_id,
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc(),
            'seeds_analyzed': 0
        }


# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='GPU Residue Sieve - Flexible PRNG seed discovery',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=f"""
Available PRNG families:
{chr(10).join('  - ' + name for name in list_available_prngs())}

Job file format (JSON):
{{
  "job_id": "sieve_001",
  "dataset_path": "daily3.json",
  "seed_start": 0,
  "seed_end": 1000000,
  "window_size": 10,
  "min_match_threshold": 0.5,
  "skip_range": [0, 16],
  "prng_families": ["xorshift32", "pcg32"],
  "sessions": ["midday", "evening"]
}}
        """
    )

    parser.add_argument('--job-file', required=True, help='Job specification JSON file')
    parser.add_argument('--gpu-id', type=int, default=0, help='GPU device ID')
    parser.add_argument('--list-prngs', action='store_true', help='List available PRNG families')

    args = parser.parse_args()

    # List PRNGs if requested
    if args.list_prngs:
        print("Available PRNG families:")
        for name in list_available_prngs():
            config = get_kernel_info(name)
            print(f"  {name:25} - {config['description']}")
        return 0

    # Load job specification
    try:
        with open(args.job_file, 'r') as f:
            job = json.load(f)
    except Exception as e:
        print(f"ERROR: Failed to load job file: {e}", file=sys.stderr)
        return 1

    job_id = job.get('job_id', 'unknown')

    # Execute sieve
    result = execute_sieve_job(job, args.gpu_id)

    # Write result file
    result_file = f"result_{job_id}.json"
    try:
        with open(result_file, 'w') as f:
            json.dump(result, f, indent=2)
    except Exception as e:
        print(f"WARNING: Failed to write result file: {e}", file=sys.stderr)

    # Echo to stdout for coordinator parsing
    print(json.dumps(result))

    return 0 if result['success'] else 1


if __name__ == '__main__':
    sys.exit(main())
