#!/usr/bin/env python3
"""
generate_scorer_jobs.py (v2 - Pull Architecture)
================================================
Generates job specs for the 26-GPU Scorer Meta-Optimization (Step 2.5).

This script is run ONCE on the head node (zeus). It:
1. Creates a local Optuna study.
2. Pre-samples ALL trial parameters (e.g., 100 sets).
3. Saves these parameters directly into the 'scorer_jobs.json' file.

This ensures remote workers are "dumb" and just run the test they are given,
without needing any database connection.
"""

import json
import argparse
from pathlib import Path
import optuna
import sys

# This is the search space, defined once.
def define_search_space(trial: optuna.trial.Trial) -> dict:
    """Defines the full search space for both scorer and model."""
    params = {
        # Scorer Params
        "residue_mod_1": trial.suggest_int("residue_mod_1", 5, 20),
        "residue_mod_2": trial.suggest_int("residue_mod_2", 50, 150),
        "residue_mod_3": trial.suggest_int("residue_mod_3", 500, 1500),
        "max_offset": trial.suggest_int("max_offset", 3, 15),
        "temporal_window_size": trial.suggest_categorical("temporal_window_size", [50, 100, 150, 200]),
        "temporal_num_windows": trial.suggest_int("temporal_num_windows", 3, 10),
        "min_confidence_threshold": trial.suggest_float("min_confidence_threshold", 0.05, 0.3, log=True),
        
        # Mini-Model Params (from anti_overfit_trial_worker.py)
        "hidden_layers": trial.suggest_categorical('hidden_layers', ['128_64', '256_128_64']),
        "dropout": trial.suggest_float('dropout', 0.1, 0.5),
        "learning_rate": trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),
        "batch_size": trial.suggest_categorical('batch_size', [64, 128, 256])
    }
    return params

def main():
    parser = argparse.ArgumentParser(description='Generate scorer evaluation jobs with pre-sampled parameters')
    parser.add_argument('--trials', type=int, default=100, help='Number of Optuna trials to generate')
    parser.add_argument('--survivors', required=True, help='Base name of survivors JSON (e.g., bidirectional_survivors.json)')
    parser.add_argument('--train-history', required=True, help='Base name of train_history.json')
    parser.add_argument('--holdout-history', required=True, help='Base name of holdout_history.json')
    parser.add_argument('--study-name', required=True, help='Optuna study name for the scorer')
    parser.add_argument('--study-db', required=True, help='Optuna study database URL (local path on zeus)')
    
    args = parser.parse_args()

    try:
        # Create LOCAL Optuna study to generate trial parameters
        study = optuna.create_study(
            study_name=args.study_name,
            storage=args.study_db,
            direction='maximize',
            load_if_exists=True # Allows re-running
        )
    except Exception as e:
        print(f"FATAL ERROR: Could not create or load Optuna study at {args.study_db}")
        print(f"Error: {e}")
        print("Please check file permissions and if 'optuna_studies' directory exists.")
        sys.exit(1)

    # Define the *remote* path where workers will find the data
    remote_data_path = "~/distributed_prng_analysis"
    
    jobs = []
    
    print(f"Pre-sampling {args.trials} parameter sets from Optuna...")
    for i in range(args.trials):
        
        # --- HERE IS THE FIX ---
        # 1. Ask Optuna for a new trial object (with no parameters)
        trial = study.ask()
        
        # 2. Call the function to APPLY suggestions to this trial
        params = define_search_space(trial)
        # --- END OF FIX ---
        
        # Store the Optuna trial number so we can link results later
        params['optuna_trial_number'] = trial.number
        
        job = {
            "job_id": f"scorer_trial_{i}",
            "script": "scorer_trial_worker.py",
            "args": [
                # Arg 1: Survivor file path (remote)
                f"{remote_data_path}/{Path(args.survivors).name}",
                # Arg 2: Train history path (remote)
                f"{remote_data_path}/{Path(args.train_history).name}",
                # Arg 3: Holdout history path (remote)
                f"{remote_data_path}/{Path(args.holdout_history).name}",
                # Arg 4: The trial ID (for the output filename)
                str(i),
                # Arg 5: The pre-sampled parameters as a JSON string
                json.dumps(params)
            ],
            "gpu_required": True,
            "output_file": f"coordinator_logs/scorer_trial_{i}.log",
            "timeout": 3600, # 1 hour timeout per trial
            "retry_on_failure": False
        }
        jobs.append(job)
    
    # Save job specifications
    output_file = "scorer_jobs.json"
    with open(output_file, "w") as f:
        json.dump(jobs, f, indent=2)

    print(f"âœ… Generated {len(jobs)} jobs with pre-sampled parameters")
    print(f"   Output: {output_file}")
    print(f"\nðŸ“‹ Sample job:")
    print(json.dumps(jobs[0], indent=2))

if __name__ == "__main__":
    main()
