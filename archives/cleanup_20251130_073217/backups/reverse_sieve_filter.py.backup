#!/usr/bin/env python3
"""
GPU Reverse Residue Sieve - Bidirectional Validation Engine
Validates candidate seeds backward through historical draws.

Usage: python3 reverse_sieve_filter.py --job-file job.json --gpu-id 0

BASIC VERSION - Core functionality only
ML feature extraction will be added in next step.
"""

import argparse
import json
import time
import os
import sys
from typing import List, Dict, Any, Optional, Tuple
import socket

# ROCm environment setup
HOST = socket.gethostname()
if HOST in ["rig-6600", "rig-6600b"]:
    os.environ.setdefault("HSA_OVERRIDE_GFX_VERSION", "10.3.0")
    os.environ.setdefault("HSA_ENABLE_SDMA", "0")
os.environ.setdefault("ROCM_PATH", "/opt/rocm")
os.environ.setdefault("HIP_PATH", "/opt/rocm")

# GPU backend
try:
    import cupy as cp
    GPU_AVAILABLE = True
except ImportError:
    print("ERROR: CuPy not available - GPU required", file=sys.stderr)
    sys.exit(1)

import numpy as np

# Load kernels from prng_registry
try:
    from prng_registry import KERNEL_REGISTRY, get_kernel_info
except ImportError:
    print("ERROR: prng_registry.py not found", file=sys.stderr)
    sys.exit(1)

# Load strategies for hybrid mode
try:
    from hybrid_strategy import get_all_strategies, StrategyConfig
    HYBRID_AVAILABLE = True
except ImportError:
    HYBRID_AVAILABLE = False
    print("WARNING: hybrid_strategy.py not available - hybrid mode disabled", file=sys.stderr)


# ============================================================================
# DATASET LOADING
# ============================================================================

def load_draws_from_daily3(path: str, window_size: int = 30, sessions=None, offset: int = 0):
    """Load draws from dataset"""
    with open(path, 'r') as f:
        data = json.load(f)

    if sessions:
        data = [e for e in data if e.get('session') in sessions]

    n = len(data)
    if n < window_size:
        raise ValueError(f"Dataset has only {n} entries, need at least {window_size}")

    start = max(0, min(int(offset), n - window_size))
    end = start + window_size
    window = data[start:end]

    draws = [int(entry.get("full_state", entry["draw"])) for entry in window]
    return draws


# ============================================================================
# GPU REVERSE SIEVE ENGINE
# ============================================================================

class GPUReverseSieve:
    """
    GPU-accelerated reverse sieve engine.
    Validates candidate seeds backward through historical draws.
    """
    
    def __init__(self, gpu_id: int = 0):
        if not GPU_AVAILABLE:
            raise RuntimeError("CuPy not available")
        
        self.gpu_id = gpu_id
        self.device = cp.cuda.Device(gpu_id)
        self.compiled_kernels = {}
        
        print(f"GPUReverseSieve initialized on GPU {gpu_id}", file=sys.stderr)
    
    def _get_kernel(self, prng_family: str):
        """Get or compile kernel for reverse PRNG family"""
        cache_key = f"{prng_family}_reverse"
        
        if cache_key in self.compiled_kernels:
            return self.compiled_kernels[cache_key]
        
        # Get reverse kernel info
        kernel_name = f"{prng_family}_reverse"
        if kernel_name not in KERNEL_REGISTRY:
            raise ValueError(f"Reverse kernel not available for {prng_family}")
        
        config = get_kernel_info(kernel_name)
        kernel = cp.RawKernel(config['kernel_source'], config['kernel_name'])
        
        self.compiled_kernels[cache_key] = (kernel, config)
        return kernel, config
    
    def run_reverse_sieve(self,
                          candidate_seeds: List[int],
                          prng_family: str,
                          draws: List[int],
                          skip_range: Tuple[int, int] = (0, 20),
                          min_match_threshold: float = 0.01,
                          offset: int = 0) -> Dict[str, Any]:
        """
        Run fixed skip reverse sieve on candidate seeds.
        """
        start_time = time.time()
        
        with self.device:
            # Extract seeds and their specific skip values
            seeds_array = [c["seed"] if isinstance(c, dict) else c for c in candidate_seeds]
            skips_array = [c.get("skip", 0) if isinstance(c, dict) else 0 for c in candidate_seeds]

            n_candidates = len(candidate_seeds)
            k = len(draws)
            
            print(f"Reverse sieve: {n_candidates} candidates, {k} draws", file=sys.stderr)
            
            # Prepare GPU arrays
            # Prepare GPU arrays
            candidate_seeds_gpu = cp.array(seeds_array, dtype=cp.uint32)
            candidate_skips_gpu = cp.array(skips_array, dtype=cp.uint8)
            residues = cp.array(draws, dtype=cp.uint32)
            survivors = cp.zeros(n_candidates, dtype=cp.uint32)
            match_rates = cp.zeros(n_candidates, dtype=cp.float32)
            used_skips = cp.zeros(n_candidates, dtype=cp.uint8)  # NEW: track which skip was used
            survivor_count = cp.zeros(1, dtype=cp.uint32)
            
            # Get kernel
            kernel, config = self._get_kernel(prng_family)
            
            # Launch kernel
            threads_per_block = 256
            blocks = (n_candidates + threads_per_block - 1) // threads_per_block
            kernel(
                (blocks,), (threads_per_block,),
                (candidate_seeds_gpu, candidate_skips_gpu, residues, survivors, 
                 match_rates, used_skips, survivor_count, cp.int32(n_candidates), cp.int32(k),
                 cp.float32(min_match_threshold), cp.int32(offset))
            )
            
            # Collect results
            count = int(survivor_count[0].get())
            survivor_records = []
            if count > 0:
                survivors_cpu = survivors[:count].get()
                rates_cpu = match_rates[:count].get()
                skips_cpu = used_skips[:count].get()
                for i in range(count):
                    survivor_records.append({
                        'seed': int(survivors_cpu[i]),
                        'skip': int(skips_cpu[i]),
                        'match_rate': float(rates_cpu[i])
                    })
            
            duration_ms = (time.time() - start_time) * 1000
            
            print(f"  Found {count} survivors in {duration_ms:.1f}ms", file=sys.stderr)
            
            return {
                'family': f"{prng_family}_reverse",
                'survivors': survivor_records,
                'stats': {
                    'candidates_tested': n_candidates,
                    'survivors_found': count,
                    'duration_ms': duration_ms,
                    'device': f'GPU_{self.gpu_id}'
                }
            }
    
    def run_hybrid_reverse_sieve(self,
                                  candidate_seeds: List[int],
                                  prng_family: str,
                                  draws: List[int],
                                  strategies: List[StrategyConfig],
                                  min_match_threshold: float = 0.50,
                                  offset: int = 0) -> Dict[str, Any]:
        """
        Run variable skip hybrid reverse sieve on candidate seeds.
        """
        start_time = time.time()
        
        with self.device:
            n_candidates = len(candidate_seeds)
            n_strategies = len(strategies)
            k = len(draws)
            
            print(f"Hybrid reverse: {n_candidates} candidates, {n_strategies} strategies", file=sys.stderr)
            
            # Prepare GPU arrays
            candidate_seeds_gpu = cp.array(seeds_array, dtype=cp.uint32)
            candidate_skips_gpu = cp.array(skips_array, dtype=cp.uint8)
            residues = cp.array(draws, dtype=cp.uint32)
            survivors = cp.zeros(n_candidates, dtype=cp.uint32)
            match_rates = cp.zeros(n_candidates, dtype=cp.float32)
            skip_sequences = cp.zeros(n_candidates * 512, dtype=cp.uint32)
            strategy_ids = cp.zeros(n_candidates, dtype=cp.uint32)
            survivor_count = cp.zeros(1, dtype=cp.uint32)
            
            # Strategy parameters
            strategy_max_misses = cp.array([s.max_consecutive_misses for s in strategies], dtype=cp.int32)
            strategy_tolerances = cp.array([s.skip_tolerance for s in strategies], dtype=cp.int32)
            
            # Get hybrid kernel
            kernel_name = f"{prng_family}_hybrid_reverse"
            if kernel_name not in KERNEL_REGISTRY:
                raise ValueError(f"Hybrid reverse kernel not available for {prng_family}")
            
            config = get_kernel_info(kernel_name)
            kernel = cp.RawKernel(config['kernel_source'], config['kernel_name'])
            
            # Launch kernel
            threads_per_block = 256
            blocks = (n_candidates + threads_per_block - 1) // threads_per_block
            
            kernel(
                (blocks,), (threads_per_block,),
                (candidate_seeds_gpu, residues, survivors, match_rates, skip_sequences,
                 strategy_ids, survivor_count, cp.int32(n_candidates), cp.int32(k),
                 strategy_max_misses, strategy_tolerances, cp.int32(n_strategies),
                 cp.float32(min_match_threshold), cp.int32(offset))
            )
            
            # Collect results
            count = int(survivor_count[0].get())
            
            survivor_records = []
            if count > 0:
                survivors_cpu = survivors[:count].get()
                rates_cpu = match_rates[:count].get()
                strategy_ids_cpu = strategy_ids[:count].get()
                skip_seq_flat = skip_sequences.get()
                
                for i in range(count):
                    strat_id = int(strategy_ids_cpu[i])
                    skip_seq = skip_seq_flat[i*512:(i+1)*512][:k].tolist()
                    
                    survivor_records.append({
                        'seed': int(survivors_cpu[i]),
                        'family': f"{prng_family}_hybrid_reverse",
                        'match_rate': float(rates_cpu[i]),
                        'matches': int(rates_cpu[i] * k),
                        'total': k,
                        'strategy_name': strategies[strat_id].name if strat_id < len(strategies) else 'unknown',
                        'skip_pattern': skip_seq
                    })
            
            duration_ms = (time.time() - start_time) * 1000
            
            print(f"  Found {count} hybrid survivors in {duration_ms:.1f}ms", file=sys.stderr)
            
            return {
                'family': f"{prng_family}_hybrid_reverse",
                'survivors': survivor_records,
                'stats': {
                    'candidates_tested': n_candidates,
                    'survivors_found': count,
                    'strategies_tested': n_strategies,
                    'duration_ms': duration_ms,
                    'device': f'GPU_{self.gpu_id}'
                }
            }


# ============================================================================
# JOB EXECUTION
# ============================================================================

def execute_reverse_job(job: Dict[str, Any], gpu_id: int) -> Dict[str, Any]:
    """
    Execute reverse sieve job from job specification.
    Compatible with coordinator.py distributed execution.
    """
    job_id = job.get('job_id', 'unknown')
    
    try:
        # Extract parameters
        dataset_path = job.get('dataset_path') or job.get('target_file')
        window_size = job.get('window_size', 30)
        skip_range = tuple(job.get('skip_range', [0, 20]))
        min_match_threshold = job.get('min_match_threshold', 0.01)
        offset = job.get('offset', 0)
        sessions = job.get('sessions', ['midday', 'evening'])
        prng_families = job.get('prng_families', ['mt19937'])
        hybrid = job.get('hybrid', False)
        
        # Candidate seeds (required for reverse sieve)
        candidate_seeds = job.get('candidate_seeds')
        if not candidate_seeds:
            raise ValueError("candidate_seeds required for reverse sieve")
        
        # Load draws
        draws = load_draws_from_daily3(dataset_path, window_size, sessions, offset)
        if not draws:
            raise ValueError("No draws loaded from dataset")
        
        # Initialize reverse sieve
        sieve = GPUReverseSieve(gpu_id=gpu_id)
        
        # Run reverse sieve
        per_family_results = []
        all_survivors = []
        
        for family in prng_families:
            if hybrid and HYBRID_AVAILABLE:
                # Hybrid mode
                strategies_data = job.get('strategies', [])
                strategies = [StrategyConfig(**s) for s in strategies_data]
                phase2_threshold = job.get('phase2_threshold', 0.50)
                
                result = sieve.run_hybrid_reverse_sieve(
                    candidate_seeds=candidate_seeds,
                    prng_family=family,
                    draws=draws,
                    strategies=strategies,
                    min_match_threshold=phase2_threshold,
                    offset=offset
                )
            else:
                # Fixed skip mode
                result = sieve.run_reverse_sieve(
                    candidate_seeds=candidate_seeds,
                    prng_family=family,
                    draws=draws,
                    skip_range=skip_range,
                    min_match_threshold=min_match_threshold,
                    offset=offset
                )
            
            per_family_results.append(result)
            all_survivors.extend(result['survivors'])
        
        # Compile final result
        total_duration = sum(r['stats']['duration_ms'] for r in per_family_results)
        
        final_result = {
            'job_id': job_id,
            'success': True,
            'mode': 'reverse_sieve',
            'prng_families': [r['family'] for r in per_family_results],
            'candidates_tested': len(candidate_seeds),
            'window_size': window_size,
            'skip_range': list(skip_range),
            'min_match_threshold': min_match_threshold,
            'survivors': all_survivors,
            'stats': {
                'total_candidates': len(candidate_seeds),
                'total_survivors': len(all_survivors),
                'duration_ms': total_duration
            },
            'per_family': {
                r['family']: {
                    'survivors': r['survivors'],
                    'tested': r['stats']['candidates_tested'],
                    'found': r['stats']['survivors_found'],
                    'duration_ms': r['stats']['duration_ms']
                }
                for r in per_family_results
            }
        }
        
        return final_result
        
    except Exception as e:
        import traceback
        return {
            'job_id': job_id,
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }


# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='GPU Reverse Residue Sieve - Basic Version'
    )
    
    parser.add_argument('--job-file', required=True, help='Job specification JSON file')
    parser.add_argument('--gpu-id', type=int, default=0, help='GPU device ID')
    
    args = parser.parse_args()
    
    # Load job
    try:
        with open(args.job_file, 'r') as f:
            job = json.load(f)
    except Exception as e:
        print(f"ERROR: Failed to load job file: {e}", file=sys.stderr)
        return 1
    
    job_id = job.get('job_id', 'unknown')
    
    # Execute reverse sieve
    result = execute_reverse_job(job, args.gpu_id)
    
    # Write result file
    result_file = f"result_{job_id}.json"
    try:
        with open(result_file, 'w') as f:
            json.dump(result, f, indent=2)
    except Exception as e:
        print(f"WARNING: Failed to write result file: {e}", file=sys.stderr)
    
    # Echo to stdout for coordinator parsing
    print(json.dumps(result))
    
    return 0 if result['success'] else 1


if __name__ == '__main__':
    sys.exit(main())
