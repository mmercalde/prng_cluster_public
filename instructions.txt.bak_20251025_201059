instructions.txt
# Distributed PRNG Analysis System - Production Instructions

## System Overview
**Status: FULLY OPERATIONAL - 26 GPU Cluster (285.69 TFLOPS)**

A distributed pseudorandom number generator (PRNG) analysis system that uses GPU acceleration across multiple nodes to analyze lottery data patterns. The system automatically detects and optimizes for both NVIDIA (CUDA) and AMD (ROCm) hardware.

**NEW: Bidirectional Sieve Architecture** - Forward + Reverse PRNG analysis with ML fusion for adaptive pattern discovery.
## Data File Format Requirements

### Standard Input Format (daily3.json, test files)

All analysis requires JSON files with lottery draw data. The format varies slightly depending on analysis type:

#### Fixed Skip Sieve Format (Minimal)
```json
[
  {
    "draw": 134,
    "session": "midday",
    "timestamp": 5000000
  },
  {
    "draw": 840,
    "session": "midday",
    "timestamp": 5000001
  }
]
```

**Required fields:**
- `draw` (integer 0-999): The lottery draw result
- `session` (string): "midday" or "evening" (can be any identifier)
- `timestamp` or `date` (integer/string): Temporal ordering

#### Hybrid Variable Skip Format (Same as Fixed)
```json
[
  {
    "draw": 994,
    "session": "midday",
    "timestamp": 5000000
  }
]
```

**Note:** Hybrid mode uses the SAME format as fixed skip. The only difference is you add `--hybrid` flag.

#### Multi-Modulo Validation Format (Advanced)
```json
[
  {
    "draw": 134,
    "full_state": 3234134,
    "session": "midday",
    "timestamp": 5000000
  }
]
```

**Additional field:**
- `full_state` (integer): Complete PRNG state value (not just mod 1000)

**When to use full_state:**
- For maximum confidence (triple modulo validation)
- When you have access to complete PRNG state
- Testing with synthetic data where full state is known

**When NOT needed:**
- Standard lottery data (only has draw values 0-999)
- Hybrid mode (works with draw values only)
- Most real-world scenarios

#### Quick Reference: What Format Do I Need?

| Analysis Type | Required Fields | Optional Fields |
|--------------|-----------------|-----------------|
| Fixed Skip Sieve | draw, session, timestamp | full_state |
| Hybrid Variable Skip | draw, session, timestamp | full_state |
| Reverse Sieve | draw, session, timestamp | full_state |
| Timestamp Search | draw, session, timestamp | - |

### Example: Creating Test Data

#### For Fixed Skip Testing
```bash
cat > test_simple.json << 'EOF'
[
  {"draw": 450, "session": "midday", "timestamp": 1000000},
  {"draw": 303, "session": "midday", "timestamp": 1000001},
  {"draw": 618, "session": "midday", "timestamp": 1000002}
]
EOF
```

#### For Hybrid Testing (Variable Skip)
```bash
# Use the create_xorshift32_hybrid_test.py script shown in Hybrid section
# It generates proper format automatically
python3 create_xorshift32_hybrid_test.py
```

### Common Format Mistakes

âŒ **Wrong: Missing required fields**
```json
[
  {"draw": 134}  // Missing session and timestamp
]
```

âŒ **Wrong: Incorrect data types**
```json
[
  {"draw": "134", "session": "midday", "timestamp": 5000000}  // draw should be int, not string
]
```

âŒ **Wrong: Using date when timestamp expected**
```json
// Some modes expect timestamp (integer), check docs
[
  {"draw": 134, "session": "midday", "date": "2025-10-16"}  // Should use timestamp for most modes
]
```

âœ… **Correct: All required fields, proper types**
```json
[
  {"draw": 134, "session": "midday", "timestamp": 5000000}
]
```
## Hardware Architecture
- **Zeus (Coordinator)**: 2x RTX 3080 Ti (CUDA)
- **rig-6600 (192.168.3.120)**: 12x RX 6600 (ROCm)
- **rig-6600b (192.168.3.154)**: 12x RX 6600 (ROCm)
- **Total**: 26 GPUs, ~285.69 TFLOPS computational power

## Core System Files

### Main Components
- `unified_system_working.py` - Primary interface with modular analysis options
- `coordinator.py` - Distributed job coordinator with SSH connection management
- `distributed_worker.py` - GPU worker script (runs on all nodes)
- `sieve_filter.py` - **NEW: GPU-accelerated forward/reverse sieve engine**
- `prng_registry.py` - **NEW: Multi-PRNG kernel library with forward + reverse implementations**
- `enhanced_gpu_model_id.py` - GPU-accelerated PRNG analysis engine
- `distributed_config.json` - Node configuration and connection settings
- `daily3.json` - Input lottery data

### Module System (modules/ directory)
- `direct_analysis.py` - Cluster analysis with parameter optimization
- `result_viewer.py` - Interactive result viewing and visualization
- `system_monitor.py` - Hardware monitoring and diagnostics
- `database_manager.py` - Database operations and job management
- `file_manager.py` - File operations and maintenance

## NEW: Multi-PRNG Bidirectional Sieve System

### Overview
**Status: PRODUCTION READY - Forward Sieve Verified on All 26 GPUs**

A universal PRNG analysis framework that simultaneously tests multiple PRNG families using bidirectional validation:
- **Forward Sieve**: Generate sequences from candidate seeds
- **Reverse Sieve**: Work backward from recent draws to find candidate seeds
- **Bidirectional Intersection**: High-confidence survivors that pass both directions
- **ML Fusion**: Adaptive weighting and PRNG family identification

### Supported PRNG Families

#### Fully Implemented (Forward + Reverse)
1. **xorshift32** - Fast XorShift variant (âœ… VERIFIED: seed 42 found with 100% match)
2. **xorshift64** - 64-bit XorShift
3. **xorshift128** - 128-bit XorShift
4. **lcg32** - Linear Congruential Generator (MSVC variant)
5. **pcg32** - Permuted Congruential Generator
6. **mt19937** - Mersenne Twister (32-bit)
7. **splitmix64** - SplitMix64 algorithm

#### Key Features
- **Multi-modulo validation**: Tests state % 1000, % 8, % 125 for high confidence
- **Full 32-bit state support**: Handles complete PRNG state values
- **Configurable skip/offset**: Handles draw spacing and temporal alignment
- **GPU kernel compilation cache**: Automatic optimization per hardware

### Performance Benchmarks

#### Forward Sieve (Verified)
- **RTX 3080 Ti**: ~730 seeds/sec per GPU (with full state validation)
- **RX 6600**: ~730 seeds/sec per GPU (ROCm optimized)
- **Full cluster**: 26/26 jobs successful, 100K seeds in 47.2 seconds
- **Match accuracy**: 100% (seed 42 found with perfect 30/30 match)

#### Reverse Sieve (In Development)
- Expected performance: Similar to forward sieve
- Backward state propagation from most recent draws
- Exponential candidate elimination per step

### CLI Usage Examples

#### Basic Forward Sieve
```bash
# Test single PRNG family
python3 coordinator.py \
  test_seed42_first30.json \
  --method residue_sieve \
  --prng-type xorshift32 \
  --seeds 100000 \
  --offset 0

# Search larger seed space
python3 coordinator.py \
  daily3.json \
  --method residue_sieve \
  --prng-type mt19937 \
  --seeds 1000000 \
  --offset 15 \
  --skip-range 0 20
```

#### Multi-PRNG Ensemble Analysis (Coming Soon)
```bash
# Test all PRNG families simultaneously
python3 coordinator.py \
  daily3.json \
  --method ensemble_sieve \
  --prng-families xorshift32,mt19937,lcg32,pcg32 \
  --seeds 500000 \
  --bidirectional

# ML-guided PRNG identification
python3 coordinator.py \
  daily3.json \
  --method ml_fusion \
  --auto-detect-prng \
  --confidence-threshold 0.95
```

#### Bidirectional Validation (Coming Soon)
```bash
# Forward + Reverse intersection
python3 coordinator.py \
  daily3.json \
  --method bidirectional \
  --prng-type xorshift32 \
  --seeds 1000000 \
  --forward-window 30 \
  --reverse-window 30

# Adaptive drift detection
python3 coordinator.py \
  daily3.json \
  --method adaptive \
  --detect-reseeding \
  --temporal-validation
```

### Sieve Parameters Reference

#### Core Parameters
- `--method {residue_sieve,ensemble_sieve,bidirectional,ml_fusion}`: Analysis mode
- `--prng-type {xorshift32,mt19937,lcg32,pcg32,xorshift64,splitmix64}`: PRNG family
- `--prng-families LIST`: Multiple PRNGs for ensemble (comma-separated)
- `--seeds INT`: Total seed candidates to test across cluster
- `--offset INT`: Number of PRNG steps to skip before sequence (temporal alignment)
- `--skip-range MIN MAX`: Test multiple skip values (e.g., 0 20)

#### Validation Parameters
- `--window-size INT`: Number of draws to validate against (default: 30)
- `--min-match-threshold FLOAT`: Match rate threshold (0.0-1.0, default: 0.5)
- `--bidirectional`: Enable forward + reverse validation
- `--forward-window INT`: Forward sieve window size
- `--reverse-window INT`: Reverse sieve window size

#### ML Parameters (Coming Soon)
- `--auto-detect-prng`: Let ML identify PRNG family
- `--confidence-threshold FLOAT`: Minimum confidence for predictions
- `--learning-rate FLOAT`: RL adaptation rate
- `--ensemble-weights`: Custom PRNG weighting

### Understanding Multi-Modulo Validation

The sieve uses **three simultaneous modulo checks** for high confidence:

```python
# A seed survives only if ALL three match:
match = (state % 1000 == draw % 1000) AND  # The actual draw value
        (state % 8 == draw % 8) AND        # Low bits check
        (state % 125 == draw % 125)        # Mid bits check
```

**Why this matters:**
- Single mod 1000 match = ~0.1% false positive rate
- Triple validation = ~0.00001% false positive rate
- Effectively requires full 32-bit state match

**Data Requirements:**
- Dataset must include `full_state` field (not just `draw`)
- For testing: Use `create_synthetic_full_state.py` to generate test data
- For production: Capture full PRNG state values, not just mod 1000 outputs

### Creating Test Datasets

#### Synthetic Test Data (Known Seeds)
```bash
# Generate test data with known seed 42
cat > create_test_data.py << 'EOF'
import json

def xorshift32_step(state):
    x = state & 0xFFFFFFFF
    x ^= (x << 13) & 0xFFFFFFFF
    x ^= (x >> 17) & 0xFFFFFFFF
    x ^= (x << 5) & 0xFFFFFFFF
    return x & 0xFFFFFFFF

state = 42
draws = []
for i in range(100):
    state = xorshift32_step(state)
    draws.append({
        "date": f"2020-01-{i+1:02d}",
        "session": "midday",
        "draw": state % 1000,
        "full_state": int(state)  # Critical for multi-modulo validation
    })

with open('test_seed42_known.json', 'w') as f:
    json.dump(draws, f, indent=2)
EOF

python3 create_test_data.py

# Verify the sieve finds it
python3 coordinator.py \
  test_seed42_known.json \
  --method residue_sieve \
  --prng-type xorshift32 \
  --seeds 100000 \
  --offset 0

# Expected: Seed 42 found with 100% match rate
```

#### Multi-Session Test Data
```bash
# Generate data with separate midday/evening seeds
python3 create_synthetic_dataset.py \
  --seed-midday 42 \
  --seed-evening 1337 \
  --prng xorshift32 \
  --count 10000 \
  --skip 5 \
  --output synthetic_dual_session.json
```

### Result Interpretation

#### Survivor Output Format
```json
{
  "seed": 42,
  "family": "xorshift32",
  "match_rate": 1.0,
  "matches": 30,
  "total": 30,
  "best_skip": 0
}
```

**Key Metrics:**
- **match_rate**: Percentage of draws that matched (0.0-1.0)
- **matches/total**: Raw match count (e.g., 30/30 = perfect)
- **best_skip**: Optimal skip value found (temporal alignment)
- **seed**: The PRNG seed candidate

#### Confidence Levels
- **match_rate >= 0.95**: Extremely high confidence (likely correct seed)
- **match_rate 0.80-0.94**: High confidence (strong candidate)
- **match_rate 0.60-0.79**: Moderate confidence (needs validation)
- **match_rate < 0.60**: Low confidence (likely false positive)

#### Example Analysis Results
```bash
# Check results for seed 42
cat results/multi_gpu_analysis_*.json | python3 -c "
import sys, json
d = json.load(sys.stdin)
survivors = []
for r in d.get('results', []):
    survivors.extend(r.get('survivors', []))

seed_42 = [s for s in survivors if s.get('seed') == 42]
if seed_42:
    print('âœ… SEED 42 FOUND!')
    print(f'Match rate: {seed_42[0][\"match_rate\"]}')
    print(f'Matches: {seed_42[0][\"matches\"]}/{seed_42[0][\"total\"]}')
"
```

## Legacy: Fast Congruence Residue Sieve

### Overview
**Status: SUPERSEDED by Multi-PRNG Sieve (above)**

Original fast residue filter for mod 1000 only. Still functional but replaced by more comprehensive multi-modulo validation system.

### Performance Benchmarks (Legacy)
- **RTX 3080 Ti**: 60,000-90,000 seeds/sec per GPU
- **RX 6600**: 10,000-20,000 seeds/sec per GPU
- **Full cluster**: 40/40 jobs successful, 100K seeds in 2.9 seconds

### Legacy CLI Usage
```bash
# Original residue sieve (mod 1000 only)
python3 coordinator.py --method residue_sieve --prng-type lcg32 --window-size 512 --k-sigma 6.0 --seeds 1000000 daily3.json -o results/sieve_test.json
```

**Note**: New code should use `--method residue_sieve` with multi-modulo validation instead.

## CRITICAL: ROCm Environment Setup - What NOT to Do

### âŒ DO NOT Use Shell Wrappers for AMD Nodes
**Wrong Approach**: Creating wrapper scripts like `run_worker_rocm.sh` and modifying `distributed_config.json` to use them.

**Why Wrong**: The coordinator already has built-in environment activation via `python_env` paths. Adding wrappers creates unnecessary complexity and can interfere with the proven job distribution system.

### âŒ DO NOT Modify Remote Command Execution
**Wrong Approach**: Changing the coordinator's SSH command construction or adding manual environment activation to commands.

**Why Wrong**: The coordinator automatically constructs proper activation commands based on `python_env` paths in `distributed_config.json`. The existing mechanism works reliably.

### âŒ DO NOT Set Environment Variables in Config File
**Wrong Approach**: Adding environment variables to `distributed_config.json` or trying to pass them through SSH commands.

**Why Wrong**: Environment variables must be set BEFORE any Python imports, which means they belong in the Python files themselves, not in configuration or command-line parameters.

### âœ… The Correct Approach (Proven Working Method)
1. **Use existing python_env mechanism**: Point AMD nodes to `/home/michael/rocm_env/bin/python` in config
2. **Set environment variables in Python files**: Add ROCm variables at the top of `distributed_worker.py`, `sieve_filter.py`, and `enhanced_gpu_model_id.py`
3. **Leverage proven infrastructure**: Use the established job data structure and routing logic
4. **Follow existing patterns**: Add new functionality using the same patterns as existing analysis modes

### Example of Correct ROCm Setup Pattern
```python
#!/usr/bin/env python3
# ROCm environment setup - MUST BE FIRST
import os, socket
HOST = socket.gethostname()

# Apply ROCm overrides for AMD systems
if HOST in ["rig-6600", "rig-6600b"]:
    os.environ.setdefault("HSA_OVERRIDE_GFX_VERSION", "10.3.0")
    os.environ.setdefault("HSA_ENABLE_SDMA", "0")

# ROCm paths
os.environ.setdefault("ROCM_PATH", "/opt/rocm")
os.environ.setdefault("HIP_PATH", "/opt/rocm")

# AFTER environment setup, import GPU libraries
import cupy as cp
```

**Critical Files Requiring ROCm Prelude:**
- `distributed_worker.py` âœ…
- `sieve_filter.py` âœ…
- `enhanced_gpu_model_id.py` âœ…

## Common Integration Mistakes and Solutions

### Issue: "Python integer out of bounds for uint16"
**Cause**: Old kernel code using `unsigned short* residues` (16-bit) instead of `unsigned int*` (32-bit)
**Solution**: All kernels in `prng_registry.py` now use `unsigned int* residues` for full state support

### Issue: "Connection reset by peer (104)" on AMD Nodes
**Cause**: New functionality not following established job data patterns
**Solution**: Use existing job_data structure, don't create custom communication protocols

### Issue: Seed Not Found Despite Perfect Manual Match
**Cause**: Missing offset parameter or incorrect data format
**Solution**:
- Verify dataset includes `full_state` field (not just `draw`)
- Calculate correct offset (e.g., last 30 of 100 draws needs offset=70)
- Check sieve uses `entry.get('full_state', entry['draw'])` in data loading

### Issue: Zero Match Rate for Known Seeds
**Cause**: Data type mismatch between Python and GPU kernel
**Solution**: Verify `residues_gpu = cp.array(residues, dtype=cp.uint32)` not uint16

### Key Lesson
The system now supports full 32-bit PRNG state analysis with multi-modulo validation. Always ensure:
1. Dataset contains `full_state` values
2. Kernels use `unsigned int*` for residues
3. Correct offset calculation for temporal alignment
4. ROCm environment variables set before any GPU imports

## Quick Start Guide

### Starting the System
```bash
# Activate your GPU environment (tf or torch)
source ~/venvs/tf/bin/activate  # or torch

# Launch unified interface
python3 unified_system_working.py

# Test all 26 GPUs
# Select: Direct Analysis â†’ System Connectivity Test
# Expected: All nodes show "GPUs available"
```

### Basic Analysis Workflow
```bash
# 1. Test sieve with known seed (verification)
python3 coordinator.py \
  test_seed42_first30.json \
  --method residue_sieve \
  --prng-type xorshift32 \
  --seeds 100000 \
  --offset 0

# Expected: Seed 42 found with 100% match rate in ~47 seconds

# 2. Multi-PRNG ensemble search (production)
python3 coordinator.py \
  daily3.json \
  --method residue_sieve \
  --prng-type mt19937 \
  --seeds 1000000 \
  --offset 15

# 3. Standard correlation analysis (legacy)
python3 unified_system_working.py
# Select: Direct Analysis â†’ Standard Analysis â†’ General correlation analysis â†’ y
# Expected: 25/25 jobs successful across all 26 GPUs
```

## Critical GPU Setup Requirements

### NVIDIA Nodes (Zeus - localhost)
**Environment**: Any Python environment with CUDA-compatible CuPy
```bash
# Verify CUDA CuPy installation
python3 -c "import cupy; print('CUDA CuPy:', cupy.__version__)"
# Expected output: CUDA CuPy: 13.5.1 (or similar)

# Test local GPU workers
echo '{"job_id":"test","seeds":[1],"prng_type":"xorshift","samples":1000}' > test.json
python3 distributed_worker.py test.json --gpu-id 0
# Expected: "Job test completed successfully"

# NEW: Test sieve functionality
python3 sieve_filter.py --job-file test_job.json --gpu-id 0
# Expected: JSON output with survivor results
```

### AMD Nodes (Both rig-6600 systems)
**Critical Requirement**: ROCm environment variables must be set BEFORE any GPU imports.

**File Requirements**: All GPU-intensive files must contain ROCm prelude:

```python
#!/usr/bin/env python3

# ROCm environment setup - MUST BE FIRST
import os, socket
HOST = socket.gethostname()

# Apply ROCm overrides for AMD systems
if HOST in ["rig-6600", "rig-6600b"]:
    os.environ.setdefault("HSA_OVERRIDE_GFX_VERSION", "10.3.0")
    os.environ.setdefault("HSA_ENABLE_SDMA", "0")

# ROCm paths
os.environ.setdefault("ROCM_PATH", "/opt/rocm")
os.environ.setdefault("HIP_PATH", "/opt/rocm")

# AFTER environment setup, import GPU libraries
import cupy as cp
# ... rest of imports
```

**Files Requiring ROCm Prelude:**
- âœ… `distributed_worker.py`
- âœ… `sieve_filter.py`
- âœ… `enhanced_gpu_model_id.py`

**Test AMD nodes**:
```bash
# Test rig-6600
ssh 192.168.3.120 'source ~/rocm_env/bin/activate && cd distributed_prng_analysis && python3 -c "import cupy; print(cupy.cuda.runtime.getDeviceCount())"'
# Expected: 12

# Test rig-6600b
ssh 192.168.3.154 'source ~/rocm_env/bin/activate && cd distributed_prng_analysis && python3 -c "import cupy; print(cupy.cuda.runtime.getDeviceCount())"'
# Expected: 12

# NEW: Test sieve on AMD nodes
ssh 192.168.3.120 'source ~/rocm_env/bin/activate && cd distributed_prng_analysis && python3 sieve_filter.py --job-file test_job.json --gpu-id 0'
# Expected: JSON output with results
```

## Configuration File Setup

### distributed_config.json
```json
{
  "nodes": [
    {
      "hostname": "localhost",
      "username": "michael",
      "gpu_count": 2,
      "gpu_type": "RTX 3080 Ti",
      "script_path": "/home/michael/distributed_prng_analysis",
      "python_env": "/home/michael/venvs/tf/bin/python"
    },
    {
      "hostname": "192.168.3.120",
      "username": "michael",
      "gpu_count": 12,
      "gpu_type": "RX 6600",
      "script_path": "/home/michael/distributed_prng_analysis",
      "python_env": "/home/michael/rocm_env/bin/python",
      "password": "your_password"
    },
    {
      "hostname": "192.168.3.154",
      "username": "michael",
      "gpu_count": 12,
      "gpu_type": "RX 6600",
      "script_path": "/home/michael/distributed_prng_analysis",
      "python_env": "/home/michael/rocm_env/bin/python",
      "password": "your_password"
    }
  ]
}
```

**Key Points**:
- `python_env` must point to Python executable in the correct virtual environment
- `script_path` must contain all system files on each node including `sieve_filter.py` and `prng_registry.py`
- Passwords stored in plain text - consider SSH keys for security
- All nodes must have identical versions of `sieve_filter.py` and `prng_registry.py`

## Analysis Types and Parameters

### Quick Test (Connectivity Verification)
- **Purpose**: Verify all 26 GPUs respond correctly
- **Parameters**: 1,000 seeds, 1,000 samples, light correlation
- **Runtime**: 30-60 seconds
- **Command**: Direct Analysis â†’ Quick Test Analysis

### NEW: Sieve Analysis (Production Mode)
- **Quick sieve test**: 100K seeds, 30 window (47 seconds) - Verification
- **Standard sieve**: 1M seeds, 30 window (7 minutes) - Production
- **Deep sieve**: 10M seeds, 30 window (70 minutes) - Comprehensive search
- **Multi-PRNG ensemble**: Test all families simultaneously
- **Purpose**: Find PRNG seeds with high-confidence bidirectional validation

### Standard Analysis (Legacy)
- **General correlation**: 50K seeds, 10K samples, correlation lag 32
- **Pattern matching**: 25K seeds, 20K samples, optimized for recent patterns
- **Randomness testing**: 100K seeds, 5K samples, comprehensive statistical tests
- **Runtime**: 5-15 minutes across full cluster

### Comprehensive Analysis
- **Deep correlation**: 200K seeds, 50K samples, correlation lag 128
- **Multi-target search**: Automated lottery number targeting
- **Historical reconstruction**: 300K seeds, extensive temporal analysis
- **Runtime**: 30-120 minutes utilizing full 285.69 TFLOPS

### Draw Matching (Number Search)
- **Quick search**: 10K seeds (30 seconds)
- **Standard search**: 100K seeds (2-5 minutes)
- **Deep search**: 500K seeds (10-20 minutes)
- **Purpose**: Find PRNG seeds that generate specific lottery numbers

## Command Line Usage

### NEW: Multi-PRNG Sieve Operations
```bash
# Test known seed (verification)
python3 coordinator.py \
  test_seed42_first30.json \
  --method residue_sieve \
  --prng-type xorshift32 \
  --seeds 100000 \
  --offset 0

# Production analysis on real data
python3 coordinator.py \
  daily3.json \
  --method residue_sieve \
  --prng-type mt19937 \
  --seeds 1000000 \
  --offset 15 \
  --skip-range 0 20 \
  --min-match-threshold 0.8

# Multi-PRNG ensemble (coming soon)
python3 coordinator.py \
  daily3.json \
  --method ensemble_sieve \
  --prng-families xorshift32,mt19937,lcg32,pcg32 \
  --seeds 500000 \
  --bidirectional
```

### Basic Cluster Analysis (Legacy)
```bash
# Test connectivity across all nodes
python3 coordinator.py daily3.json -c distributed_config.json --test-only

# Multi-PRNG analysis (legacy correlation mode)
python3 coordinator.py daily3.json -c distributed_config.json -s 50000 -n 10000
```

### Advanced Parameters

#### Sieve-Specific
- `--method {residue_sieve,ensemble_sieve,bidirectional}`: Sieve operation mode
- `--prng-type {xorshift32,mt19937,lcg32,pcg32,xorshift64,splitmix64}`: PRNG family
- `--prng-families LIST`: Multiple PRNGs for ensemble testing
- `--seeds INT`: Total seed candidates across cluster
- `--offset INT`: Temporal alignment (PRNG steps to skip)
- `--skip-range MIN MAX`: Test multiple skip values
- `--min-match-threshold FLOAT`: Survivor threshold (0.0-1.0)
- `--window-size INT`: Number of draws to validate (default: 30)
- `--bidirectional`: Enable forward + reverse validation

#### Legacy Correlation
- `-s, --seeds`: Total seeds across all nodes (higher = more statistical confidence)
- `-n, --samples`: Samples per seed (higher = better accuracy per seed)
- `--lmax`: Maximum correlation lag (32-128 typical)
- `--grid-size`: Grid for 2D analysis (8-16 typical)
- `--draw-match N`: Search for seeds producing number N (0-999)

## Troubleshooting Guide

### GPU Detection Issues

#### NVIDIA Problems
```bash
# Check CUDA installation
nvidia-smi
python3 -c "import cupy; print(cupy.cuda.runtime.getDeviceCount())"

# Common fix: Update CuPy
pip install --upgrade cupy-cuda12x
```

#### AMD ROCm Problems
```bash
# Check ROCm installation
rocm-smi --showid
# Should show 12 GPUs on each AMD node

# Verify environment variables in ALL worker files
grep -n "HSA_OVERRIDE_GFX_VERSION" distributed_worker.py sieve_filter.py enhanced_gpu_model_id.py
# Should find the environment setup code in ALL three files

# Test ROCm CuPy
ssh 192.168.3.120 'source ~/rocm_env/bin/activate && python3 -c "import cupy; print(\"Working\")"'
```

#### Common GPU Errors and Solutions

**"No module named 'cupy'"**
```bash
# Check virtual environment activation
# Coordinator uses python_env path from config file
# Verify config points to environment with CuPy installed
```

**"Python integer X out of bounds for uint16"**
```bash
# FIXED: All kernels now use unsigned int* (32-bit)
# If error persists, verify prng_registry.py has been updated:
grep "unsigned int\* residues" prng_registry.py
# Should show multiple matches, NOT "unsigned short* residues"
```

**"radix_sort: failed on 2nd step"**
```bash
# Clear CuPy cache (often resolves kernel compilation issues)
rm -rf ~/.cache/cupy
ssh 192.168.3.120 "rm -rf ~/.cache/cupy"
ssh 192.168.3.154 "rm -rf ~/.cache/cupy"
```

**"Module not initialized" (AMD only)**
```bash
# Verify HSA_OVERRIDE_GFX_VERSION=10.3.0 is set BEFORE cupy import
# Check ALL three files: distributed_worker.py, sieve_filter.py, enhanced_gpu_model_id.py
# Environment variables must be at the very top of files
```

**"name 'offset' is not defined"**
```bash
# Ensure sieve_filter.py run_sieve() function signature includes offset parameter
# Should be: def run_sieve(..., chunk_size: int = 1_000_000, offset: int = 0)
```

**"get_kernel_info() takes 1 positional argument but 2 were given"**
```bash
# FIXED: Updated sieve_filter.py to call get_kernel_info(prng_family) without custom_params
# If error persists, check line ~93 in sieve_filter.py
```

**"Connection reset by peer (104)" (AMD only)**
```bash
# Usually indicates new functionality not following established patterns
# Check job_data structure matches existing job types
# Verify ROCm environment prelude is present in ALL GPU-intensive files
```

**"Local execution failed (rc=1)"**
```bash
# Test worker directly to see full error
echo '{"job_id":"debug","seeds":[1]}' > debug.json
python3 distributed_worker.py debug.json --gpu-id 0
# Look for syntax errors, missing imports, or environment issues

# NEW: Test sieve directly
python3 sieve_filter.py --job-file debug_sieve.json --gpu-id 0
```

### Sieve-Specific Issues

**"Seed found manually but not by sieve"**
```bash
# Common causes:
# 1. Incorrect offset calculation
#    - Last 30 of 100 draws needs offset=70, not offset=0
# 2. Missing full_state in dataset
#    - Dataset must have "full_state" field for multi-modulo validation
# 3. Wrong skip parameter
#    - Try --skip-range 0 20 to test multiple skip values
```

**"Zero survivors despite patterns"**
```bash
# Check dataset format
python3 -c "
import json
with open('your_data.json') as f:
    d = json.load(f)
    print('Has full_state:', 'full_state' in d[0] if d else False)
"

# Verify data loading
grep "get.*full_state" sieve_filter.py
# Should show: entry.get('full_state', entry['draw'])
```

**"Match rate always 0.0"**
```bash
# Verify kernel parameter passing
# Check sieve_filter.py lines ~150-160 for:
# - kernel_args.append(cp.uint32(shift_a))
# - kernel_args.append(cp.uint32(shift_b))
# - kernel_args.append(cp.uint32(shift_c))
# - kernel_args.append(cp.int32(offset))  # Must be LAST
```

### Network and SSH Issues

#### Connection Problems
```bash
# Test SSH connectivity
ssh user@192.168.3.120 "echo 'Connection working'"
ssh user@192.168.3.154 "echo 'Connection working'"

# Check SSH key setup (recommended over passwords)
ssh-keygen -t rsa
ssh-copy-id user@192.168.3.120
ssh-copy-id user@192.168.3.154
```

#### File Synchronization
```bash
# Ensure all nodes have identical files (CRITICAL for sieve functionality)
scp sieve_filter.py prng_registry.py distributed_worker.py 192.168.3.120:/home/michael/distributed_prng_analysis/
scp sieve_filter.py prng_registry.py distributed_worker.py 192.168.3.154:/home/michael/distributed_prng_analysis/

# Verify file integrity
sha256sum sieve_filter.py prng_registry.py
ssh 192.168.3.120 "cd distributed_prng_analysis && sha256sum sieve_filter.py prng_registry.py"
ssh 192.168.3.154 "cd distributed_prng_analysis && sha256sum sieve_filter.py prng_registry.py"
# Checksums should match across all nodes

## NEW: Timestamp-Based PRNG Seed Search

### Overview
**Status: PRODUCTION READY - Fully Verified on All 26 GPUs**

Searches for Unix timestamp seeds by testing millions of candidate timestamps to see if any generate matching lottery draw sequences.

### Key Features
- Tests 800M+ timestamps in ~50 seconds
- Skip/gap detection (0-100 gaps)
- Multiple PRNG families: MT19937, xorshift32, pcg32, lcg32, xorshift64
- Verified: 100% match on synthetic test (seed 1706817600, skip 5)
- Full MT19937 with 624-word state

### Basic Usage

Search for timestamp seeds:
  python3 timestamp_search.py daily3.json --mode second --window 512 --threshold 0.15 --prngs mt19937 --skip-max 100

Create test data:
  python3 create_test_mt19937.py

Verify system works:
  python3 timestamp_search.py test_mt19937_512.json --mode second --window 512 --threshold 0.8 --prngs mt19937 --skip-max 10

### Timestamp Modes
- second: 800M timestamps, 1-second resolution (RECOMMENDED)
- millisecond: 800B timestamps, 0.001-second resolution (slower)
- minute: Per-minute timestamps (faster, lower precision)

### System Verification
- Seed 1706817600 found with 100% match (512/512 draws)
- Skip value 5 detected correctly
- All 26 GPUs working

### Performance
- Throughput: 1.56 billion seeds/second
- Runtime: ~50 seconds for 800M timestamps
- Memory: 2.5 KB per MT19937 state

### Deploy to Remote Nodes
  scp prng_registry.py timestamp_search.py coordinator.py sieve_filter.py michael@192.168.3.120:~/distributed_prng_analysis/
  scp prng_registry.py timestamp_search.py coordinator.py sieve_filter.py michael@192.168.3.154:~/distributed_prng_analysis/

## NEW: Hybrid Variable Skip Detection (October 16, 2025)

### Overview
**Status: PRODUCTION READY - Verified on All 26 GPUs**

Advanced PRNG analysis that detects **variable skip patterns** (non-constant gaps between draws) using multi-strategy hybrid kernels. Unlike fixed-skip sieves that assume constant gaps, hybrid mode can discover complex, changing skip patterns.

### Supported Hybrid PRNGs
1. **mt19937_hybrid** - Two-phase MT19937 (fixed skip â†’ variable skip refinement)
2. **xorshift32_hybrid** - Single-phase Xorshift32 with multi-strategy detection âœ… NEW
3. **pcg32_hybrid** - Coming soon
4. **lcg32_hybrid** - Coming soon
5. **xorshift64_hybrid** - Coming soon

### Key Features
- **Multi-strategy detection**: Tests 5 different skip pattern strategies simultaneously
- **Variable skip patterns**: Handles patterns like [5,5,3,7,5,5,8,4,5,5] (changing gaps)
- **Single-phase & two-phase modes**: Optimized per PRNG family
- **100% match accuracy**: Verified with seed 54321, 670 draws, variable pattern
- **Forward + Reverse validation**: Bidirectional confidence (reverse implementation in progress)

### How It Works

**Traditional Fixed Skip (Existing Sieves)**:
```
Draws:  [D1] --5--> [D2] --5--> [D3] --5--> [D4]
        Constant gap of 5 between every draw
```

**Hybrid Variable Skip (NEW)**:
```
Draws:  [D1] --5--> [D2] --3--> [D3] --7--> [D4] --5--> [D5]
        Variable gaps: 5, then 3, then 7, then 5...
```

**Detection Strategy**:
- Uses 5 strategies with different tolerance levels
- Each strategy has:
  - `max_consecutive_misses`: How many gaps can be wrong
  - `skip_tolerance`: Â±N range for skip detection
  - `match_threshold`: Minimum % of draws that must match

### CLI Usage Examples

#### Test Xorshift32 Hybrid (Verification)
```bash
# Create test data with variable skip pattern
cat > create_xorshift32_hybrid_test.py << 'PYEOF'
import json
from prng_registry import xorshift32_cpu

seed = 54321
base_pattern = [5,5,3,7,5,5,8,4,5,5]
skip_pattern = base_pattern * 67  # 670 draws

total_needed = sum(skip_pattern) + len(skip_pattern)
all_outputs = xorshift32_cpu(seed, total_needed, skip=0)

draws = []
idx = 0
for skip in skip_pattern:
    idx += skip
    draws.append(all_outputs[idx] % 1000)
    idx += 1

test_data = [{'draw': d, 'session': 'midday', 'timestamp': 5000000 + i}
             for i, d in enumerate(draws)]

with open('test_xorshift32_hybrid.json', 'w') as f:
    json.dump(test_data, f)

print(f"Created test_xorshift32_hybrid.json: {len(draws)} draws")
print(f"Expected seed: {seed}")
print(f"Variable pattern: {base_pattern}")
PYEOF

python3 create_xorshift32_hybrid_test.py

# Run hybrid sieve
python3 coordinator.py \
  test_xorshift32_hybrid.json \
  --method residue_sieve \
  --prng-type xorshift32_hybrid \
  --seeds 100000 \
  --window-size 512 \
  --threshold 0.50 \
  --hybrid

# Expected output:
# âœ… Seed 54321 found
# Match rate: 100.0%
# Pattern detected: [5, 5, 3, 7, 5, 5, 8, 4, 5, 5]
```

#### Test MT19937 Hybrid (Two-Phase)
```bash
# MT19937 uses two-phase approach:
# Phase 1: Fixed-skip wide search (threshold 0.01)
# Phase 2: Variable-skip refinement on survivors (threshold 0.50)

python3 coordinator.py \
  test_known.json \
  --method residue_sieve \
  --prng-type mt19937 \
  --seeds 100000 \
  --window-size 10 \
  --threshold 0.01 \
  --hybrid \
  --phase1-threshold 0.01 \
  --phase2-threshold 0.50

# Phase 1 finds candidates with fixed skip
# Phase 2 validates variable skip patterns
```

#### Production Analysis with Hybrid
```bash
# Search real lottery data for variable skip patterns
python3 coordinator.py \
  daily3.json \
  --method residue_sieve \
  --prng-type xorshift32_hybrid \
  --seeds 1000000 \
  --window-size 100 \
  --threshold 0.50 \
  --hybrid \
  --offset 0

# Will test 1M seeds across 26 GPUs
# Detects variable skip patterns automatically
```

### Parameter Reference (Hybrid-Specific)

#### Core Hybrid Parameters
- `--hybrid`: Enable hybrid variable skip detection mode (REQUIRED for *_hybrid PRNGs)
- `--phase1-threshold FLOAT`: Phase 1 threshold for two-phase PRNGs (default: 0.01)
- `--phase2-threshold FLOAT`: Phase 2 threshold for all hybrid modes (default: 0.50)
- `--threshold FLOAT`: Overall match threshold (0.5-0.8 typical for hybrid)

#### Standard Parameters (Apply to Hybrid Too)
- `--prng-type {xorshift32_hybrid,mt19937_hybrid}`: PRNG family
- `--seeds INT`: Total seed candidates to test across cluster
- `--window-size INT`: Number of draws to validate against
- `--offset INT`: Temporal alignment (PRNG steps to skip before sequence)
- `--skip-min INT`: Minimum skip value in pattern (default: 0)
- `--skip-max INT`: Maximum skip value in pattern (default: 16)

#### Strategy Parameters (Advanced - Built-in)
Hybrid mode uses 5 built-in strategies from `hybrid_strategy.py`:

1. **Strict Continuous**
   - `max_consecutive_misses: 3`
   - `skip_tolerance: 5`
   - Best for: Tight, consistent patterns

2. **Lenient Continuous**
   - `max_consecutive_misses: 10`
   - `skip_tolerance: 20`
   - Best for: Loose, variable patterns

3. **Aggressive Reseed**
   - `max_consecutive_misses: 5`
   - `skip_tolerance: 5`
   - `enable_reseed_search: True`
   - Best for: Patterns with potential reseeding

4. **Balanced Hybrid** (Recommended)
   - `max_consecutive_misses: 7`
   - `skip_tolerance: 10`
   - Best for: General-purpose detection

5. **Extreme Tolerance**
   - `max_consecutive_misses: 20`
   - `skip_tolerance: 50`
   - Best for: Catching everything, high false positives

### Result Interpretation

#### Fixed Skip Output (Existing)
```json
{
  "seed": 12345,
  "family": "xorshift32",
  "match_rate": 1.0,
  "matches": 100,
  "total": 100,
  "best_skip": 5
}
```

#### Hybrid Variable Skip Output (NEW)
```json
{
  "seed": 54321,
  "family": "xorshift32_hybrid",
  "match_rate": 1.0,
  "matches": 670,
  "total": 670,
  "skip_pattern": [5, 5, 3, 7, 5, 5, 8, 4, 5, 5, 5, 5, 3, 7, ...],
  "strategy_used": "Balanced Hybrid",
  "pattern_stats": {
    "mean_skip": 5.4,
    "variance": 2.1,
    "std_dev": 1.45
  }
}
```

**Key Differences**:
- `skip_pattern`: Array of detected skip values (not single `best_skip`)
- `strategy_used`: Which detection strategy found the match
- `pattern_stats`: Statistical analysis of skip pattern

### Performance Benchmarks

#### Xorshift32 Hybrid (Single-Phase)
- **RTX 3080 Ti**: ~1,200 seeds/sec per GPU
- **RX 6600**: ~1,200 seeds/sec per GPU
- **Full cluster**: 100K seeds in ~3-4 seconds
- **Match accuracy**: 100% on variable patterns
- **Memory**: ~512 KB per GPU (strategy state tracking)

#### MT19937 Hybrid (Two-Phase)
- **Phase 1** (fixed): ~60K seeds/sec per GPU
- **Phase 2** (variable): ~1K seeds/sec per GPU
- **Full cluster**: 100K seeds Phase 1 in ~2s, survivors Phase 2 in ~5s
- **False positive rate**: <0.01% after two-phase validation
- **Memory**: ~2.5 MB per GPU (MT19937 state + strategy tracking)

### Comparison: Fixed vs Hybrid

| Feature | Fixed Skip | Hybrid Variable Skip |
|---------|-----------|---------------------|
| **Speed** | 60K seeds/sec | 1.2K seeds/sec |
| **Pattern Type** | Constant gaps | Variable gaps |
| **Strategies** | 1 (simple match) | 5 (multi-strategy) |
| **Memory** | Minimal | Moderate |
| **Best For** | Simple RNGs | Complex systems |
| **False Positives** | Very low | Very low |

### Troubleshooting Hybrid Mode

#### "0 strategies loaded" Error
```bash
# Check if hybrid_strategy module exists
ls -lh hybrid_strategy.py

# Verify it can be imported
python3 -c "from hybrid_strategy import get_all_strategies; print('OK')"

# Deploy to remote nodes if missing
scp hybrid_strategy.py 192.168.3.120:~/distributed_prng_analysis/
scp hybrid_strategy.py 192.168.3.154:~/distributed_prng_analysis/
```

#### "CUDA_ERROR_INVALID_VALUE: invalid argument"
```bash
# Usually means kernel parameters are mismatched
# Hybrid kernels need additional parameters

# Verify sieve_filter.py passes correct args for hybrid:
grep -A 20 "xorshift32_hybrid" prng_registry.py

# Should show kernel signature with:
# - unsigned int* seeds
# - unsigned int* residues
# - ... other params ...
# - float threshold
# - int shift_a, shift_b, shift_c
# - int offset (MUST BE LAST)
```

#### "Seed found in direct test but not by coordinator"
```bash
# Most common: Test data not deployed to remote nodes
for host in 192.168.3.120 192.168.3.154; do
    ssh $host "ls -lh ~/distributed_prng_analysis/test_*.json"
done

# Copy missing test files
scp test_xorshift32_hybrid.json test_xorshift32_const_skip5.json \
    192.168.3.120:~/distributed_prng_analysis/
scp test_xorshift32_hybrid.json test_xorshift32_const_skip5.json \
    192.168.3.154:~/distributed_prng_analysis/
```

#### "Hybrid mode only supports mt19937_hybrid"
```bash
# OLD ERROR - FIXED in latest code
# This error means you're running old sieve_filter.py

# Check if code checks metadata, not hardcoded PRNG name
grep "variable_skip" sieve_filter.py
# Should show: family_config.get('variable_skip', False)

# NOT: if family_name == 'mt19937':

# Redeploy latest code if needed
scp sieve_filter.py 192.168.3.120:~/distributed_prng_analysis/
scp sieve_filter.py 192.168.3.154:~/distributed_prng_analysis/
```

#### "IndentationError" in sieve_filter.py
```bash
# Can happen after patching hybrid support
# Verify Python syntax
python3 -m py_compile sieve_filter.py

# If error, check lines around 490-510 for proper indentation
# The elif block for two-phase must be properly indented
```

### Deployment Checklist for Hybrid

Before running hybrid analysis across cluster:

#### 1. Deploy Core Files
```bash
# All nodes need these files for hybrid to work
for host in 192.168.3.120 192.168.3.154; do
    scp prng_registry.py sieve_filter.py hybrid_strategy.py coordinator.py \
        reverse_sieve_filter.py $host:~/distributed_prng_analysis/
done
```

#### 2. Deploy Test Data (If Testing)
```bash
for host in 192.168.3.120 192.168.3.154; do
    scp test_*.json $host:~/distributed_prng_analysis/
done
```

#### 3. Verify File Timestamps Match
```bash
# Check local vs remote timestamps
ls -lh sieve_filter.py prng_registry.py hybrid_strategy.py

# Check remote nodes
ssh 192.168.3.120 "ls -lh ~/distributed_prng_analysis/{sieve_filter,prng_registry,hybrid_strategy}.py"
ssh 192.168.3.154 "ls -lh ~/distributed_prng_analysis/{sieve_filter,prng_registry,hybrid_strategy}.py"

# Timestamps should match (or remote should be newer)
```

#### 4. Verify Checksums
```bash
# Generate checksums locally
sha256sum sieve_filter.py prng_registry.py hybrid_strategy.py

# Compare with remote nodes
ssh 192.168.3.120 "cd ~/distributed_prng_analysis && sha256sum sieve_filter.py prng_registry.py hybrid_strategy.py"
ssh 192.168.3.154 "cd ~/distributed_prng_analysis && sha256sum sieve_filter.py prng_registry.py hybrid_strategy.py"

# ALL checksums must match exactly
```

#### 5. Test on Single GPU First
```bash
# Before running full cluster, test one GPU
python3 coordinator.py \
  test_xorshift32_hybrid.json \
  --method residue_sieve \
  --prng-type xorshift32_hybrid \
  --seeds 10000 \
  --threshold 0.50 \
  --hybrid

# Verify seed 54321 found with 100% match
# Only then scale to full cluster
```

### Verified Test Results (October 16, 2025)

**Test 1: MT19937 Constant Skip** âœ…
- File: test_known.json (10 draws)
- Seed: 54321, Skip: 1
- Result: Found with 10.0% match rate
- Worker: 192.168.3.154 GPU0 (RX 6600)
- Status: PASSED

**Test 2: Xorshift32 Constant Skip** âœ…
- File: test_xorshift32_const_skip5.json (100 draws)
- Seed: 12345, Skip: 5
- Result: Found with 100.0% match rate
- Worker: 192.168.3.120 GPU1 (RX 6600)
- Status: PASSED

**Test 3: Xorshift32 Variable Skip (Hybrid)** âœ…
- File: test_xorshift32_hybrid_dist.json (670 draws)
- Seed: 54321, Pattern: [5,5,3,7,5,5,8,4,5,5]
- Result: Found with 100.0% match rate, pattern detected correctly
- Worker: 192.168.3.154 GPU0 (RX 6600)
- Runtime: 0.98s
- Status: PASSED

All tests passed on distributed cluster (26 GPUs across 3 nodes).

### Backup Procedures (Hybrid Release)

#### In-Place Backups
```bash
# Creates .bak_TIMESTAMP files next to originals
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Local backups
for file in prng_registry.py sieve_filter.py coordinator.py hybrid_strategy.py reverse_sieve_filter.py; do
    [ -f "$file" ] && cp "$file" "${file}.bak_${TIMESTAMP}"
done

# Remote backups
for host in 192.168.3.120 192.168.3.154; do
    ssh $host "cd ~/distributed_prng_analysis && \
        for file in prng_registry.py sieve_filter.py hybrid_strategy.py reverse_sieve_filter.py; do \
            [ -f \"\$file\" ] && cp \"\$file\" \"\${file}.bak_${TIMESTAMP}\"; \
        done"
done

echo "âœ… Backups complete: .bak_${TIMESTAMP}"
```

#### Restore from Backup
```bash
# List available backups
ls -lt *.bak_* | head -10

# Restore specific file
TIMESTAMP=20251016_192844
cp sieve_filter.py.bak_${TIMESTAMP} sieve_filter.py

# Restore to remote nodes
for host in 192.168.3.120 192.168.3.154; do
    scp sieve_filter.py.bak_${TIMESTAMP} $host:~/distributed_prng_analysis/sieve_filter.py
done
```

**Last Verified Backup**: `.bak_20251016_192844`

### Architecture Notes: Single-Phase vs Two-Phase

#### Single-Phase Hybrid (xorshift32_hybrid)
- PRNG name already has `_hybrid` suffix
- Directly calls `run_hybrid_sieve()` with multi-strategy detection
- No Phase 1 filtering required
- Best for: PRNGs with fast variable skip kernels

```python
# Automatic detection in sieve_filter.py
if family_name.endswith('_hybrid'):
    # Single-phase: Direct hybrid sieve
    result = sieve.run_hybrid_sieve(
        prng_family=family_name,
        seed_start=seed_start,
        seed_end=seed_end,
        residues=draws,
        strategies=strategies,
        min_match_threshold=phase2_threshold,
        offset=offset
    )
```

#### Two-Phase Hybrid (mt19937)
- Base name `mt19937` without `_hybrid` suffix
- Phase 1: Fixed skip wide search (fast, filters to ~1% survivors)
- Phase 2: Variable skip validation on survivors (thorough)
- Best for: Complex PRNGs where fixed-skip filtering helps

```python
# Automatic detection in sieve_filter.py
elif family_config.get('multi_strategy', False):
    # Two-phase approach
    # Phase 1: Fixed skip
    phase1_result = sieve.run_sieve(
        prng_family='mt19937',
        ...
        min_match_threshold=phase1_threshold  # Low threshold
    )

    # Phase 2: Variable skip on survivors
    phase2_result = sieve.run_hybrid_sieve(
        prng_family='mt19937_hybrid',
        ...
        min_match_threshold=phase2_threshold  # High threshold
    )
```

### When to Use Hybrid Mode

#### Use Hybrid If:
- âœ… Skip patterns are **not constant** (varies between draws)
- âœ… Standard fixed-skip sieve finds **no survivors**
- âœ… You suspect **adaptive or dynamic** draw spacing
- âœ… Testing **real-world RNG implementations** (often have variable timing)
- âœ… Need to detect **reseeding events** in sequence

#### Use Fixed Skip If:
- âœ… Skip patterns are **constant** (same gap every time)
- âœ… Need **maximum speed** (60K seeds/sec vs 1.2K seeds/sec)
- âœ… Testing **simple PRNGs** with predictable behavior
- âœ… Working with **synthetic test data** with known constant skip
- âœ… First-pass **wide search** before hybrid refinement

### Future Hybrid PRNGs (Coming Soon)

**pcg32_hybrid** - PCG with variable skip
**lcg32_hybrid** - LCG with variable skip
**xorshift64_hybrid** - 64-bit xorshift with variable skip

All will follow the single-phase architecture pattern (like xorshift32_hybrid).

---

**Hybrid Variable Skip System Version**: 2.0
**Status**: Production Ready
**Last Updated**: October 16, 2025
**Verified On**: 26 GPUs (2x RTX 3080 Ti, 24x RX 6600)
cat > instructions.txt << 'INSTRUCTIONS_EOF'
# Distributed PRNG Analysis System - Production Instructions

## System Overview
**Status: FULLY OPERATIONAL - 26 GPU Cluster (285.69 TFLOPS)**
**Last Updated: October 18, 2025**
**All 10 PRNGs Verified: 5 Fixed Skip + 5 Hybrid Variable Skip**

A distributed pseudorandom number generator (PRNG) analysis system that uses GPU acceleration across multiple nodes to analyze lottery data patterns. The system automatically detects and optimizes for both NVIDIA (CUDA) and AMD (ROCm) hardware.

### Verified System Status (October 18, 2025)
```
==================================================
FINAL TEST SUMMARY - ALL 10 PRNGs
==================================================
Total Tests: 10
Passed: 10
Failed: 0

ðŸŽ‰ ALL 10 PRNG TESTS PASSED! ðŸŽ‰

Verified PRNGs:
  âœ… 5 Fixed Skip (Constant Gap)
  âœ… 5 Hybrid (Variable Skip)

Total: 10/10 PRNGs Operational on 26-GPU Cluster
```

## Hardware Architecture
- **Zeus (Coordinator)**: 2x RTX 3080 Ti (CUDA)
- **rig-6600 (192.168.3.120)**: 12x RX 6600 (ROCm)
- **rig-6600b (192.168.3.154)**: 12x RX 6600 (ROCm)
- **Total**: 26 GPUs, ~285.69 TFLOPS computational power

## Quick Start for New Users

### 1. Verify System is Working
```bash
# Activate the correct Python environment
source ~/venvs/tf/bin/activate

# Test a single PRNG (should complete in ~10 seconds)
python3 coordinator.py \
  test_xorshift32_hybrid.json \
  --method residue_sieve \
  --prng-type xorshift32_hybrid \
  --seeds 10000 \
  --window-size 512 \
  --threshold 0.50 \
  --hybrid

# Expected output:
# âœ… localhost GPU0 | xorshift32_hybrid-sieve | 1.1s | 2 seeds
# âœ… localhost GPU1 | xorshift32_hybrid-sieve | 1.3s | 2 seeds
# âœ… All 24 remote GPUs working
# Total jobs: 26
# Successful: 26
# Failed: 0
```

### 2. Run Full System Test (All 10 PRNGs)
```bash
# This tests all 5 fixed-skip + 5 hybrid PRNGs
./test_all_prngs_fixed.sh

# Expected runtime: ~3-5 minutes
# Expected output: "ðŸŽ‰ ALL 10 PRNG TESTS PASSED! ðŸŽ‰"
```

### 3. Analyze Real Data
```bash
# Search your lottery data for PRNG seeds
python3 coordinator.py \
  daily3.json \
  --method residue_sieve \
  --prng-type mt19937 \
  --seeds 1000000 \
  --window-size 100 \
  --threshold 0.50 \
  --offset 0

# Runtime: ~7 minutes for 1M seeds
# Results saved in: results/multi_gpu_analysis_*.json
```

## Core System Files

### Main Components
- `coordinator.py` - **CRITICAL**: Distributes jobs across 26 GPUs
- `sieve_filter.py` - **CRITICAL**: GPU-accelerated PRNG analysis engine
- `prng_registry.py` - **CRITICAL**: Multi-PRNG kernel library (10 PRNGs)
- `adaptive_thresholds.py` - Threshold coercion and validation
- `hybrid_strategy.py` - Multi-strategy variable skip detection
- `distributed_worker.py` - GPU worker (runs on all nodes)
- `distributed_config.json` - Node configuration
- `test_all_prngs_fixed.sh` - Full system validation script

### Test Data Files
- `test_xorshift32_hybrid.json` - Hybrid variable skip test (512 draws)
- `test_multi_prng_*.json` - Fixed skip tests (5 PRNGs)
- `test_*_hybrid.json` - Hybrid tests (5 PRNGs)

## Supported PRNGs (All Verified on 26 GPUs)

### Fixed Skip (Constant Gap)
1. **xorshift32** - Fast 32-bit XorShift
2. **pcg32** - Permuted Congruential Generator
3. **lcg32** - Linear Congruential Generator
4. **xorshift64** - 64-bit XorShift
5. **mt19937** - Mersenne Twister

### Hybrid (Variable Skip)
6. **xorshift32_hybrid** - Variable skip XorShift32
7. **pcg32_hybrid** - Variable skip PCG32
8. **lcg32_hybrid** - Variable skip LCG32
9. **xorshift64_hybrid** - Variable skip XorShift64
10. **mt19937_hybrid** - Variable skip MT19937

## Command Line Examples

### Example 1: Test Single PRNG (Quick Verification)
```bash
# Test xorshift32 with 10K seeds (fast ~10s test)
python3 coordinator.py \
  test_multi_prng_xorshift32.json \
  --method residue_sieve \
  --prng-type xorshift32 \
  --seeds 10000 \
  --window-size 512 \
  --threshold 0.50 \
  --skip 5

# What to expect:
# - Runtime: ~10 seconds
# - All 26 GPUs should show âœ…
# - Output: "Successful: 26, Failed: 0"
```

### Example 2: Hybrid Variable Skip Detection
```bash
# Detect variable skip patterns (e.g., [5,5,3,7,5,5,8,4])
python3 coordinator.py \
  test_xorshift32_hybrid.json \
  --method residue_sieve \
  --prng-type xorshift32_hybrid \
  --seeds 100000 \
  --window-size 512 \
  --threshold 0.50 \
  --hybrid

# What to expect:
# - Runtime: ~12 seconds for 100K seeds
# - Uses 5 detection strategies simultaneously
# - Can find complex variable skip patterns
```

### Example 3: Production Analysis on Real Data
```bash
# Search 1 million seeds across all 26 GPUs
python3 coordinator.py \
  daily3.json \
  --method residue_sieve \
  --prng-type mt19937 \
  --seeds 1000000 \
  --window-size 100 \
  --threshold 0.50 \
  --offset 0

# What to expect:
# - Runtime: ~7 minutes
# - Tests 1M potential seeds
# - Results in: results/multi_gpu_analysis_*.json
# - Any survivors will have match_rate >= 0.50
```

### Example 4: Test All 10 PRNGs (Full Validation)
```bash
# Comprehensive test of entire system
./test_all_prngs_fixed.sh

# What to expect:
# - Runtime: ~3-5 minutes
# - Tests all 10 PRNGs sequentially
# - Final output: "ðŸŽ‰ ALL 10 PRNG TESTS PASSED! ðŸŽ‰"
# - If any fail, see troubleshooting section below
```

## Critical Bug Fixes (October 18, 2025)

### Bug Fix #1: prng_type='sieve' Error
**Symptom**: "Unknown PRNG family: sieve"
**Cause**: Coordinator was hardcoding `prng_type='sieve'` instead of using user's argument
**Fix Applied**: Changed line 1671 in coordinator.py
```python
# BEFORE (WRONG):
prng_type='sieve',

# AFTER (CORRECT):
prng_type=args.prng_type,
```

### Bug Fix #2: Missing Kernel Parameters (xorshift32_hybrid)
**Symptom**: "identifier 'shift_a' is undefined" in CUDA compilation
**Cause**: Kernel signature missing shift_a, shift_b, shift_c parameters
**Fix Applied**: Line 736 in prng_registry.py
```c
// BEFORE (WRONG):
float threshold, int offset

// AFTER (CORRECT):
float threshold, int shift_a, int shift_b, int shift_c
```

### Bug Fix #3: Threshold Coercion Returning 'auto'
**Symptom**: "could not convert string to float: 'auto'"
**Cause**: `coerce_threshold()` returned string 'auto' instead of default value
**Fix Applied**: Line in adaptive_thresholds.py
```python
# BEFORE (WRONG):
if val is None:
    return 'auto'

# AFTER (CORRECT):
if val is None:
    return default
```

### Bug Fix #4: prng_families Using Wrong Value
**Symptom**: Localhost GPUs fail, remote GPUs work (24/26 success)
**Cause**: Coordinator not using job.prng_type when setting prng_families
**Fix Applied**: Lines 509, 691 in coordinator.py
```python
# BEFORE (WRONG):
'prng_families': self._sieve_config.get('prng_families', ...)

# AFTER (CORRECT):
'prng_families': [job.prng_type] if job.prng_type else (...)
```

## Troubleshooting Guide

### Issue: "Unknown PRNG family: sieve"
```bash
# Check if coordinator.py has the fix
grep -n "prng_type=args.prng_type" coordinator.py
# Should show line 1671

# If not found, restore from backup and apply fix:
TIMESTAMP=20251018_XXXXXX  # Use your backup timestamp
cp coordinator.py.bak_${TIMESTAMP} coordinator.py
sed -i "s/prng_type='sieve'/prng_type=args.prng_type/" coordinator.py
```

### Issue: "identifier 'shift_a' is undefined"
```bash
# Check if prng_registry.py has the kernel fix
grep -n "float threshold, int shift_a" prng_registry.py
# Should show line 736

# If not found:
sed -i '736s/float threshold, int offset/float threshold, int shift_a, int shift_b, int shift_c/' prng_registry.py

# Clear kernel cache
rm -rf ~/.cupy/kernel_cache
ssh 192.168.3.120 "rm -rf ~/.cupy/kernel_cache"
ssh 192.168.3.154 "rm -rf ~/.cupy/kernel_cache"
```

### Issue: "could not convert string to float: 'auto'"
```bash
# Check if adaptive_thresholds.py has the fix
grep -A 3 "if val is None:" adaptive_thresholds.py | grep "return default"
# Should show "return default"

# If not found:
sed -i "s/return 'auto'/return default/" adaptive_thresholds.py
```

### Issue: Localhost GPUs Fail (24/26 Success Rate)
```bash
# Symptom:
# âœ… 192.168.3.120 GPU0-11 | PASSED
# âœ… 192.168.3.154 GPU0-11 | PASSED
# âŒ localhost GPU0 | FAILED
# âŒ localhost GPU1 | FAILED

# Most common cause: prng_families not using job.prng_type

# Check coordinator.py lines 509 and 691:
sed -n '509p' coordinator.py
sed -n '691p' coordinator.py

# Both should show:
# 'prng_families': [job.prng_type] if job.prng_type else (...)

# If not, apply fix:
# (See Bug Fix #4 above)
```

### Issue: Test Files Are Empty (0 lines)
```bash
# Check test file sizes
wc -l test_*.json

# If any show 0 lines, regenerate:
./test_all_prngs_fixed.sh

# Or regenerate specific test:
python3 << 'EOF'
import json

def xorshift32_step(state):
    x = state & 0xFFFFFFFF
    x ^= (x << 13) & 0xFFFFFFFF
    x ^= (x >> 17) & 0xFFFFFFFF
    x ^= (x << 5) & 0xFFFFFFFF
    return x & 0xFFFFFFFF

SEED = 12345
SKIP = 5
NUM_DRAWS = 512

state = SEED
draws = []
for i in range(NUM_DRAWS):
    for _ in range(SKIP):
        state = xorshift32_step(state)
    state = xorshift32_step(state)
    draw = state % 1000
    draws.append({'draw': draw, 'session': 'midday', 'timestamp': 5000000 + i})

with open('test_multi_prng_xorshift32.json', 'w') as f:
    json.dump(draws, f, indent=2)

print(f"âœ… Created test with {len(draws)} draws")
EOF
```

### Issue: CuPy Kernel Cache Problems
```bash
# Symptom: Jobs fail after code changes, even though code is correct
# Cause: Old compiled kernels cached

# Solution: Clear cache on ALL nodes
rm -rf ~/.cupy/kernel_cache
ssh 192.168.3.120 "rm -rf ~/.cupy/kernel_cache"
ssh 192.168.3.154 "rm -rf ~/.cupy/kernel_cache"

# Also clear Python cache
find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null
```

### Issue: Remote Nodes Work, Localhost Fails (NOT prng_families issue)
```bash
# If localhost fails but you've verified all 4 bug fixes are applied,
# test directly without coordinator:

# Create test job
cat > test_direct.json << 'EOF'
{
  "job_id": "test_direct",
  "search_type": "residue_sieve",
  "dataset_path": "test_xorshift32_hybrid.json",
  "seed_start": 0,
  "seed_end": 1000,
  "window_size": 512,
  "min_match_threshold": 0.5,
  "skip_range": [0, 16],
  "offset": 0,
  "prng_families": ["xorshift32_hybrid"],
  "sessions": ["midday", "evening"],
  "hybrid": true,
  "phase1_threshold": null,
  "phase2_threshold": null,
  "strategies": null
}
EOF

# Test directly
cd ~/distributed_prng_analysis
source ~/venvs/tf/bin/activate
CUDA_VISIBLE_DEVICES=0 python -u sieve_filter.py --job-file test_direct.json --gpu-id 0

# If this works but coordinator fails, check execute_local_job in coordinator.py
```

## File Backup and Restore Procedures

### Create Backups In-Place
```bash
# Creates .bak_TIMESTAMP files next to originals
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Local backups
for file in coordinator.py sieve_filter.py prng_registry.py adaptive_thresholds.py hybrid_strategy.py; do
    [ -f "$file" ] && cp "$file" "${file}.bak_${TIMESTAMP}"
done

# Remote backups
for host in 192.168.3.120 192.168.3.154; do
    ssh $host "cd ~/distributed_prng_analysis && \
        for file in coordinator.py sieve_filter.py prng_registry.py adaptive_thresholds.py; do \
            [ -f \"\$file\" ] && cp \"\$file\" \"\${file}.bak_${TIMESTAMP}\"; \
        done"
done

echo "âœ… Backups complete: .bak_${TIMESTAMP}"
```

### Restore from Backup
```bash
# List available backups
ls -lt *.bak_* | head -20

# Restore specific file (replace TIMESTAMP)
TIMESTAMP=20251018_210000
cp coordinator.py.bak_${TIMESTAMP} coordinator.py

# Restore to remote nodes
for host in 192.168.3.120 192.168.3.154; do
    scp coordinator.py.bak_${TIMESTAMP} $host:~/distributed_prng_analysis/coordinator.py
done

# Verify restore
sha256sum coordinator.py
ssh 192.168.3.120 "sha256sum ~/distributed_prng_analysis/coordinator.py"
ssh 192.168.3.154 "sha256sum ~/distributed_prng_analysis/coordinator.py"
```

### Deploy Updated Files to Remote Nodes
```bash
# After making changes locally, deploy to remote nodes
for host in 192.168.3.120 192.168.3.154; do
    scp coordinator.py sieve_filter.py prng_registry.py adaptive_thresholds.py hybrid_strategy.py \
        $host:~/distributed_prng_analysis/
done

# Verify checksums match
echo "=== Local ==="
sha256sum coordinator.py sieve_filter.py prng_registry.py

echo "=== 192.168.3.120 ==="
ssh 192.168.3.120 "cd ~/distributed_prng_analysis && sha256sum coordinator.py sieve_filter.py prng_registry.py"

echo "=== 192.168.3.154 ==="
ssh 192.168.3.154 "cd ~/distributed_prng_analysis && sha256sum coordinator.py sieve_filter.py prng_registry.py"
```

## Performance Benchmarks

### Fixed Skip PRNGs
- **Speed**: ~60,000 seeds/sec per GPU
- **Localhost (2x RTX 3080 Ti)**: ~120K seeds/sec
- **Remote (24x RX 6600)**: ~1.44M seeds/sec
- **Full cluster**: ~1.56M seeds/sec
- **Example**: 10K seeds analyzed in ~10 seconds

### Hybrid Variable Skip PRNGs
- **Speed**: ~1,200 seeds/sec per GPU (slower due to multi-strategy)
- **Localhost**: ~2.4K seeds/sec
- **Remote**: ~28.8K seeds/sec
- **Full cluster**: ~31.2K seeds/sec
- **Example**: 10K seeds analyzed in ~12 seconds

### Real-World Usage
```bash
# Quick test (development/debugging)
--seeds 10000     # ~10 seconds

# Standard search (production)
--seeds 1000000   # ~7 minutes (fixed skip) or ~15 minutes (hybrid)

# Deep search (comprehensive)
--seeds 10000000  # ~70 minutes (fixed skip) or ~150 minutes (hybrid)
```

## Understanding the Output

### Successful Analysis
```bash
=== ANALYSIS COMPLETE ===
Analysis ID: analysis_20dd010c8316
Total jobs: 26
Successful: 26
Failed: 0
Runtime: 12.3s
Results saved: results/multi_gpu_analysis_1760850510.json
âœ… Analysis completed successfully
```

### Failed Jobs (Before Fixes)
```bash
# Old output (with bugs):
âš ï¸ localhost GPU0 | sieve-sieve | 0.7s | Failed (will retry 1/3)
âš ï¸ localhost GPU1 | sieve-sieve | 0.7s | Failed (will retry 1/3)
âœ… 192.168.3.120 GPU0 | xorshift32_hybrid-sieve | 2.3s | 2 seeds
# ... (24/26 success = BUG!)

# New output (after fixes):
âœ… localhost GPU0 | xorshift32_hybrid-sieve | 1.1s | 2 seeds
âœ… localhost GPU1 | xorshift32_hybrid-sieve | 1.3s | 2 seeds
âœ… 192.168.3.120 GPU0 | xorshift32_hybrid-sieve | 2.3s | 2 seeds
# ... (26/26 success = CORRECT!)
```

### Results File Format
```json
{
  "analysis_id": "analysis_20dd010c8316",
  "total_jobs": 26,
  "successful": 26,
  "failed": 0,
  "runtime": 12.3,
  "results": [
    {
      "job_id": "sieve_001",
      "success": true,
      "prng_families": ["xorshift32_hybrid"],
      "seed_range": {"start": 0, "end": 385},
      "survivors": [],  // Empty if no matches found
      "stats": {
        "total_seeds_tested": 385,
        "total_survivors": 0,
        "duration_ms": 1100
      }
    }
  ]
}
```

## Data File Format

### Basic Format (Works for All Modes)
```json
[
  {
    "draw": 450,
    "session": "midday",
    "timestamp": 5000000
  },
  {
    "draw": 303,
    "session": "midday",
    "timestamp": 5000001
  }
]
```

**Required fields:**
- `draw` (integer 0-999): The lottery number
- `session` (string): Session identifier
- `timestamp` (integer): Sequential ordering

## Configuration File

### distributed_config.json
```json
{
  "nodes": [
    {
      "hostname": "localhost",
      "username": "michael",
      "gpu_count": 2,
      "gpu_type": "RTX 3080 Ti",
      "script_path": "/home/michael/distributed_prng_analysis",
      "python_env": "/home/michael/venvs/tf/bin/python"
    },
    {
      "hostname": "192.168.3.120",
      "username": "michael",
      "gpu_count": 12,
      "gpu_type": "RX 6600",
      "script_path": "/home/michael/distributed_prng_analysis",
      "python_env": "/home/michael/rocm_env/bin/python"
    },
    {
      "hostname": "192.168.3.154",
      "username": "michael",
      "gpu_count": 12,
      "gpu_type": "RX 6600",
      "script_path": "/home/michael/distributed_prng_analysis",
      "python_env": "/home/michael/rocm_env/bin/python"
    }
  ]
}
```

## System Verification Checklist

Before reporting issues, verify:

### 1. All Bug Fixes Applied
```bash
# Check all 4 critical fixes:
grep -n "prng_type=args.prng_type" coordinator.py | grep 1671
grep -n "float threshold, int shift_a" prng_registry.py | grep 736
grep "return default" adaptive_thresholds.py
sed -n '509p;691p' coordinator.py | grep "job.prng_type"

# All 4 should return results. If any are missing, apply fixes from section above.
```

### 2. Test Files Have Data
```bash
wc -l test_*.json | grep -v " 0 "
# All files should have >0 lines. If any are empty, regenerate with test_all_prngs_fixed.sh
```

### 3. Remote Nodes Have Latest Files
```bash
# Check file timestamps
ls -lh coordinator.py sieve_filter.py prng_registry.py
ssh 192.168.3.120 "ls -lh ~/distributed_prng_analysis/{coordinator,sieve_filter,prng_registry}.py"
ssh 192.168.3.154 "ls -lh ~/distributed_prng_analysis/{coordinator,sieve_filter,prng_registry}.py"

# Timestamps should be recent. If not, deploy updated files.
```

### 4. Environment Activated
```bash
# Check Python environment
which python3
# Should show: /home/michael/venvs/tf/bin/python3 (or torch)

# If not:
source ~/venvs/tf/bin/activate
```

### 5. All 26 GPUs Detected
```bash
# Quick GPU test
python3 coordinator.py test_multi_prng_xorshift32.json \
  --method residue_sieve \
  --prng-type xorshift32 \
  --seeds 100 \
  --window-size 512 \
  --threshold 0.50 \
  --skip 5

# Should show:
# âœ… localhost: 2 GPUs available
# âœ… 192.168.3.120: 12 GPUs available
# âœ… 192.168.3.154: 12 GPUs available
# Active GPU workers: 26
```

## Advanced Topics

### Hybrid Mode: Variable Skip Detection

Hybrid mode detects non-constant skip patterns like [5,5,3,7,5,5,8,4,5,5]:
```bash
# Enable hybrid mode with --hybrid flag
python3 coordinator.py \
  test_xorshift32_hybrid.json \
  --method residue_sieve \
  --prng-type xorshift32_hybrid \
  --seeds 100000 \
  --window-size 512 \
  --threshold 0.50 \
  --hybrid

# Uses 5 strategies simultaneously:
# 1. Strict Continuous (tight patterns)
# 2. Lenient Continuous (loose patterns)
# 3. Aggressive Reseed (reseeding detection)
# 4. Balanced Hybrid (recommended)
# 5. Extreme Tolerance (catch-all)
```

### Parameters Reference

#### Core Parameters
- `--method residue_sieve`: Analysis method (only sieve currently)
- `--prng-type {xorshift32,pcg32,lcg32,xorshift64,mt19937}`: PRNG family
- `--seeds INT`: Total seeds to test across cluster
- `--window-size INT`: Number of draws to validate (default: 512)
- `--threshold FLOAT`: Match threshold 0.0-1.0 (default: 0.50)

#### Fixed Skip Parameters
- `--skip INT`: Constant skip value (e.g., --skip 5)
- `--skip-range MIN MAX`: Test range of skips (e.g., --skip-range 0 20)

#### Hybrid Parameters
- `--hybrid`: Enable variable skip detection (REQUIRED for *_hybrid PRNGs)
- `--phase1-threshold FLOAT`: Phase 1 threshold (default: 0.01)
- `--phase2-threshold FLOAT`: Phase 2 threshold (default: 0.50)

#### Other Parameters
- `--offset INT`: PRNG steps to skip before starting (temporal alignment)
- `--resume-policy {resume,restart}`: Resume or restart on failure

## Getting Help

### Step 1: Run System Test
```bash
./test_all_prngs_fixed.sh
```

If this passes (10/10), your system is working correctly.

### Step 2: Check Bug Fixes
```bash
# Verify all 4 critical fixes are applied (see "System Verification Checklist" above)
```

### Step 3: Check Logs
```bash
# Recent analysis results
ls -lt results/*.json | head -5

# Check for errors in most recent
cat $(ls -t results/*.json | head -1) | python3 -m json.tool | head -50
```

### Step 4: Test Individual Components
```bash
# Test sieve_filter.py directly
cat > test_component.json << 'EOF'
{
  "job_id": "test_component",
  "search_type": "residue_sieve",
  "dataset_path": "test_multi_prng_xorshift32.json",
  "seed_start": 0,
  "seed_end": 1000,
  "window_size": 512,
  "min_match_threshold": 0.5,
  "skip_range": [0, 16],
  "offset": 0,
  "prng_families": ["xorshift32"],
  "sessions": ["midday", "evening"],
  "hybrid": false
}
EOF

python3 sieve_filter.py --job-file test_component.json --gpu-id 0
```

---

**System Version**: 2.1 (October 18, 2025)
**Status**: Production Ready - All 10 PRNGs Verified
**Last Verified**: 26/26 GPUs (2x RTX 3080 Ti, 24x RX 6600)Analysis (October 19, 2025)
<artifact identifier="corrected-reverse-guide" type="text/markdown" title="CORRECTED: Reverse Sieve Implementation Guide">
## NEW: Reverse Sieve for Backward PRNG Analysis (October 19, 2025)
Overview
Status: PARTIAL IMPLEMENTATION - 6/22 Reverse PRNGs Completed
Last Updated: October 19, 2025 - CORRECTED based on working LCG32 implementation
Reverse sieve PRNGs enable the same forward analysis but with hardcoded parameters in the kernel. Despite the name "reverse", they use the SAME forward analysis path through sieve_filter.py.
Current Implementation Status
Completed (6/22)

âœ… mt19937_reverse + mt19937_hybrid_reverse
âœ… lcg32_reverse + lcg32_hybrid_reverse (VERIFIED 26/26 GPUs)

Remaining (16/22)
Need both fixed + hybrid variants for:

xorshift32
xorshift64
xorshift128
pcg32
java_lcg
minstd
xoshiro256pp
philox4x32

KEY DISCOVERY: How Reverse PRNGs Actually Work
IMPORTANT: Reverse PRNGs are NOT truly "reverse" in the sense of working backward through draws. They are simply variants of forward PRNGs with:

Hardcoded parameters in the kernel (no registry params needed)
Same analysis path through sieve_filter.py
Special handling in sieve_filter.py to skip parameter passing

Why they're called "reverse":

Original intent was for backward validation
Current implementation: forward sieve with minimal registry requirements
Future: May evolve to true backward propagation through reverse_sieve_filter.py

Prerequisites: Required System Fixes
CRITICAL: These fixes must be in place BEFORE adding new reverse PRNGs:
Fix #1: sieve_filter.py Line 488
bash# Check if fix is applied
sed -n '488p' sieve_filter.py

# Should show:
is_single_phase = ('_hybrid' in family_name)

# If shows endswith('_hybrid'), fix it:
sed -i "488s/family_name.endswith('_hybrid')/('_hybrid' in family_name)/" sieve_filter.py
Fix #2: sieve_filter.py Line 321 (Skip params for reverse)
bash# Check if fix is applied
sed -n '320,325p' sieve_filter.py

# Should show:
#     *(
#         [] if '_reverse' in prng_family else  # Skip for reverse kernels

# If missing, add it:
sed -i '321s/^                    \*(/                    \*(\n                        [] if '\''_reverse'\'' in prng_family else  # Skip for reverse kernels/' sieve_filter.py
Verify Both Fixes
bashpython3 -c "import sieve_filter" && echo "âœ… sieve_filter.py OK"

# Deploy to remote nodes
for host in 192.168.3.120 192.168.3.154; do
    scp sieve_filter.py $host:~/distributed_prng_analysis/
done

Step-by-Step Guide: Adding New Reverse PRNG
Step 1: Backup Everything
bashTIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Local backups
for file in prng_registry.py coordinator.py sieve_filter.py; do
    [ -f "$file" ] && cp "$file" "${file}.bak_${TIMESTAMP}"
done

# Remote backups
for host in 192.168.3.120 192.168.3.154; do
    ssh $host "cd ~/distributed_prng_analysis && \
        for file in prng_registry.py coordinator.py sieve_filter.py; do \
            [ -f \"\$file\" ] && cp \"\$file\" \"\${file}.bak_${TIMESTAMP}\"; \
        done"
done

echo "âœ… Backups: .bak_${TIMESTAMP}"
Step 2: Create Reverse Kernels with Hardcoded Parameters
Find the forward kernel first:
bash# Find the forward kernel to copy from
grep -n "PRNGNAME_KERNEL = r'''" prng_registry.py
Template for Fixed Reverse Kernel:
pythonPRNGNAME_REVERSE_KERNEL = r'''
extern "C" __global__
void prngname_reverse_sieve(
    unsigned int* candidate_seeds,
    unsigned int* residues,
    unsigned int* survivors,
    float* match_rates,
    unsigned char* best_skips,
    unsigned int* survivor_count,
    int n_candidates,
    int k,
    int skip_min,
    int skip_max,
    float threshold,
    int offset
) {
    int idx = blockDim.x * blockIdx.x + threadIdx.x;
    if (idx >= n_candidates) return;

    // HARDCODE all PRNG parameters here (NOT in signature!)
    const unsigned int param1 = VALUE1;
    const unsigned int param2 = VALUE2;
    // ... etc for all PRNG-specific params

    unsigned int seed = candidate_seeds[idx];
    float best_rate = 0.0f;
    int best_skip_val = 0;

    // Copy EXACT logic from forward kernel
    // Just change: seeds[idx] -> candidate_seeds[idx]
    //             n_seeds -> n_candidates
    // Everything else IDENTICAL to forward kernel
    
    for (int skip = skip_min; skip <= skip_max; skip++) {
        unsigned int state = seed;
        
        // Apply offset
        for (int o = 0; o < offset; o++) {
            // PRNG step using param1, param2, etc.
        }
        
        // Apply skip
        for (int s = 0; s < skip; s++) {
            // PRNG step
        }
        
        // Test sequence
        int matches = 0;
        for (int i = 0; i < k; i++) {
            // PRNG step
            
            // Multi-modulo validation
            if (((state % 1000) == (unsigned int)(residues[i] % 1000)) &&
                ((state % 8) == (unsigned int)(residues[i] % 8)) &&
                ((state % 125) == (unsigned int)(residues[i] % 125))) {
                matches++;
            }
            
            // Skip between draws
            for (int s = 0; s < skip; s++) {
                // PRNG step
            }
        }
        
        float rate = ((float)matches) / ((float)k);
        if (rate > best_rate) {
            best_rate = rate;
            best_skip_val = skip;
        }
    }
    
    if (best_rate >= threshold) {
        unsigned int pos = atomicAdd(survivor_count, 1);
        survivors[pos] = candidate_seeds[idx];
        match_rates[pos] = best_rate;
        best_skips[pos] = (unsigned char)best_skip_val;
    }
}
'''
Template for Hybrid Reverse Kernel:
pythonPRNGNAME_HYBRID_REVERSE_KERNEL = r'''
extern "C" __global__
void prngname_hybrid_reverse_sieve(
    unsigned int* candidate_seeds,
    unsigned int* residues,
    unsigned int* survivors,
    float* match_rates,
    unsigned int* skip_sequences,
    unsigned int* strategy_ids,
    unsigned int* survivor_count,
    int n_candidates,
    int k,
    int* strategy_max_misses,
    int* strategy_tolerances,
    int n_strategies,
    float threshold,
    int offset
) {
    int idx = blockDim.x * blockIdx.x + threadIdx.x;
    if (idx >= n_candidates) return;

    // HARDCODE all PRNG parameters here
    const unsigned int param1 = VALUE1;
    const unsigned int param2 = VALUE2;

    unsigned int seed = candidate_seeds[idx];

    // Copy EXACT logic from forward hybrid kernel
    // Just change: seeds[idx] -> candidate_seeds[idx]
    //             n_seeds -> n_candidates
    
    for (int strat_id = 0; strat_id < n_strategies; strat_id++) {
        int max_consecutive_misses = strategy_max_misses[strat_id];
        int skip_tolerance = strategy_tolerances[strat_id];
        
        unsigned int state = seed;
        
        // Apply offset
        for (int o = 0; o < offset; o++) {
            // PRNG step
        }
        
        int matches = 0;
        int consecutive_misses = 0;
        unsigned int skip_seq[512];
        bool failed = false;
        
        for (int i = 0; i < k && !failed; i++) {
            bool found = false;
            
            for (int try_skip = 0; try_skip <= skip_tolerance && !found; try_skip++) {
                unsigned int state_save = state;
                
                // Apply trial skip
                for (int s = 0; s < try_skip; s++) {
                    // PRNG step
                }
                
                // Generate next value
                // PRNG step
                
                // Multi-modulo test
                if (((state % 1000) == (unsigned int)(residues[i] % 1000)) &&
                    ((state % 8) == (unsigned int)(residues[i] % 8)) &&
                    ((state % 125) == (unsigned int)(residues[i] % 125))) {
                    found = true;
                    matches++;
                    consecutive_misses = 0;
                    skip_seq[i] = try_skip;
                } else {
                    state = state_save;
                }
            }
            
            if (!found) {
                consecutive_misses++;
                if (consecutive_misses > max_consecutive_misses) {
                    failed = true;
                }
                skip_seq[i] = 0;
            }
        }
        
        if (!failed) {
            float rate = ((float)matches) / ((float)k);
            
            if (rate >= threshold) {
                int pos = atomicAdd(survivor_count, 1);
                survivors[pos] = candidate_seeds[idx];
                match_rates[pos] = rate;
                strategy_ids[pos] = strat_id;
                
                for (int i = 0; i < k; i++) {
                    skip_sequences[pos * 512 + i] = skip_seq[i];
                }
                
                return;
            }
        }
    }
}
'''
Step 3: Insert Kernels in prng_registry.py
bash# Find insertion point (before MT19937_REVERSE_KERNEL)
grep -n "^MT19937_REVERSE_KERNEL" prng_registry.py

# Create kernel file
cat > prngname_reverse_kernels.txt << 'EOF'

PRNGNAME_REVERSE_KERNEL = r'''
[paste your fixed reverse kernel here]
'''

PRNGNAME_HYBRID_REVERSE_KERNEL = r'''
[paste your hybrid reverse kernel here]
'''

EOF

# Insert (replace LINENUM with actual line from grep output, minus 1)
sed -i 'LINENUMr prngname_reverse_kernels.txt' prng_registry.py

# Verify insertion
grep -n "^PRNGNAME_REVERSE_KERNEL\|^PRNGNAME_HYBRID_REVERSE_KERNEL" prng_registry.py
Step 4: Add Registry Entries (MINIMAL - Only 3-4 Fields!)
Find insertion point:
bashgrep -n "'lcg32_hybrid_reverse':" prng_registry.py
# Note the line number
For Fixed Reverse (3 fields only):
python    'prngname_reverse': {
        'kernel_source': PRNGNAME_REVERSE_KERNEL,
        'kernel_name': 'prngname_reverse_sieve',
        'description': 'PRNGNAME reverse sieve - fixed skip backward validation'
    },
For Hybrid Reverse (4 fields - note variable_skip):
python    'prngname_hybrid_reverse': {
        'kernel_source': PRNGNAME_HYBRID_REVERSE_KERNEL,
        'kernel_name': 'prngname_hybrid_reverse_sieve',
        'description': 'PRNGNAME hybrid reverse - variable skip backward validation',
        'variable_skip': True
    },
Insert with sed:
bash# Replace LINENUM with actual line number
sed -i 'LINENUMa\    '\''prngname_reverse'\'': {\n        '\''kernel_source'\'': PRNGNAME_REVERSE_KERNEL,\n        '\''kernel_name'\'': '\''prngname_reverse_sieve'\'',\n        '\''description'\'': '\''PRNGNAME reverse sieve - fixed skip backward validation'\''\n    },\n    '\''prngname_hybrid_reverse'\'': {\n        '\''kernel_source'\'': PRNGNAME_HYBRID_REVERSE_KERNEL,\n        '\''kernel_name'\'': '\''prngname_hybrid_reverse_sieve'\'',\n        '\''description'\'': '\''PRNGNAME hybrid reverse - variable skip backward validation'\'',\n        '\''variable_skip'\'': True\n    },' prng_registry.py

# Verify
grep -A 5 "'prngname_reverse':" prng_registry.py
grep -A 6 "'prngname_hybrid_reverse':" prng_registry.py
Step 5: Update coordinator.py Choices
bash# Find the choices list
grep -n "choices=\[" coordinator.py | grep prng

# Edit and add after existing reverse entries
nano coordinator.py
# Add: 'prngname_reverse', 'prngname_hybrid_reverse',
Step 6: Verify, Deploy, Test
bash# Test syntax
python3 -c "import prng_registry" && echo "âœ… Registry OK"
python3 -c "import coordinator" && echo "âœ… Coordinator OK"

# Clear kernel cache
rm -rf ~/.cupy/kernel_cache

# Deploy to remote nodes
for host in 192.168.3.120 192.168.3.154; do
    scp prng_registry.py coordinator.py $host:~/distributed_prng_analysis/
    ssh $host "rm -rf ~/.cupy/kernel_cache"
done

# Create test data (using forward PRNG function)
cat > test_prngname_reverse.py << 'PYEOF'
import json

def prngname_step(state):
    # Implement PRNG step function
    # Example for xorshift32:
    x = state & 0xFFFFFFFF
    x ^= (x << 13) & 0xFFFFFFFF
    x ^= (x >> 17) & 0xFFFFFFFF
    x ^= (x << 5) & 0xFFFFFFFF
    return x & 0xFFFFFFFF

SEED = 12345
SKIP = 5
NUM_DRAWS = 100

state = SEED
draws = []
for i in range(NUM_DRAWS):
    for _ in range(SKIP):
        state = prngname_step(state)
    state = prngname_step(state)
    draws.append({
        'draw': state % 1000,
        'session': 'midday',
        'timestamp': 5000000 + i
    })

with open('test_multi_prng_prngname.json', 'w') as f:
    json.dump(draws, f, indent=2)

print(f"âœ… Test created: seed {SEED}, skip {SKIP}, {len(draws)} draws")
PYEOF

python3 test_prngname_reverse.py

# Deploy test to remote nodes
for host in 192.168.3.120 192.168.3.154; do
    scp test_multi_prng_prngname.json $host:~/distributed_prng_analysis/
done

# Test fixed reverse on all 26 GPUs
python3 coordinator.py \
  test_multi_prng_prngname.json \
  --method residue_sieve \
  --prng-type prngname_reverse \
  --seeds 5000 \
  --window-size 100 \
  --threshold 0.50 \
  --skip 5

# Expected: Successful: 26, Failed: 0

Common Mistakes (CORRECTED)
âŒ Mistake #1: Adding Extra Parameters to Kernel Signature
WRONG:
cvoid prngname_reverse_sieve(..., float threshold, unsigned int a, unsigned int c, int offset)
CORRECT:
cvoid prngname_reverse_sieve(..., float threshold, int offset) {
    const unsigned int a = 1103515245;  // Hardcode inside!
    const unsigned int c = 12345;
âŒ Mistake #2: Adding Registry Fields That Forward PRNG Has
WRONG:
python'prngname_reverse': {
    'kernel_source': PRNGNAME_REVERSE_KERNEL,
    'kernel_name': 'prngname_reverse_sieve',
    'cpu_reference': prngname_cpu,      # âŒ NO!
    'default_params': {...},            # âŒ NO!
    'seed_type': 'uint32',              # âŒ NO!
    'description': '...'
}
CORRECT:
python'prngname_reverse': {
    'kernel_source': PRNGNAME_REVERSE_KERNEL,
    'kernel_name': 'prngname_reverse_sieve',
    'description': '...'  # Only 3 fields!
}
âŒ Mistake #3: Forgetting variable_skip for Hybrid
WRONG:
python'prngname_hybrid_reverse': {
    'kernel_source': PRNGNAME_HYBRID_REVERSE_KERNEL,
    'kernel_name': 'prngname_hybrid_reverse_sieve',
    'description': '...'
}
CORRECT:
python'prngname_hybrid_reverse': {
    'kernel_source': PRNGNAME_HYBRID_REVERSE_KERNEL,
    'kernel_name': 'prngname_hybrid_reverse_sieve',
    'description': '...',
    'variable_skip': True  # âœ… Required for hybrid!
}

Troubleshooting
Issue: "CUDA_ERROR_INVALID_VALUE: invalid argument"
bash# This means parameter mismatch
# Check kernel signature has NO extra params:
grep -A 15 "void prngname_reverse_sieve" prng_registry.py

# Should end with: float threshold, int offset)
# NOT: float threshold, int a, int b, int offset)

# Also check sieve_filter.py has the skip-params fix:
sed -n '320,325p' sieve_filter.py
# Should show: [] if '_reverse' in prng_family else
Issue: "'default_params'" KeyError
bash# Hybrid reverse missing variable_skip flag
sed -n "/'prngname_hybrid_reverse'/,/},/p" prng_registry.py

# Should show:
#     'variable_skip': True

# If missing, add it:
nano prng_registry.py
# Add 'variable_skip': True to the hybrid_reverse entry
Issue: Hybrid Not Detected (Calls run_sieve instead of run_hybrid_sieve)
bash# Check sieve_filter.py line 488:
sed -n '488p' sieve_filter.py

# Should show:
# is_single_phase = ('_hybrid' in family_name)

# NOT:
# is_single_phase = family_name.endswith('_hybrid')
```

---

## Quick Reference Checklist

- [ ] Backup all files (local + remote)
- [ ] Copy forward kernel, rename to *_reverse_sieve
- [ ] Change `seeds[idx]` â†’ `candidate_seeds[idx]`
- [ ] Change `n_seeds` â†’ `n_candidates`
- [ ] Hardcode ALL PRNG params as `const` at top of kernel
- [ ] NO extra params in kernel signature
- [ ] Insert kernels before MT19937_REVERSE_KERNEL
- [ ] Add registry entries (3 fields for fixed, 4 for hybrid)
- [ ] Add `'variable_skip': True` for hybrid variant
- [ ] Update coordinator.py choices
- [ ] Verify Python syntax
- [ ] Clear kernel cache (all nodes)
- [ ] Deploy to remote nodes
- [ ] Create test data file
- [ ] Deploy test data to remote nodes
- [ ] Test fixed reverse: 26/26 success
- [ ] Test hybrid reverse: 26/26 success

---

## Verified Working Example: LCG32

**Test Results (October 19, 2025):**
```
âœ… lcg32 (Forward Fixed):          26/26 GPUs - 9.4s
âœ… lcg32_hybrid (Forward Variable): 26/26 GPUs - 15.4s
âœ… lcg32_reverse (Reverse Fixed):   26/26 GPUs - 9.7s
âœ… lcg32_hybrid_reverse (Reverse Variable): 26/26 GPUs - 10.2s

RESULT: 4/4 LCG32 VARIANTS PASSED
Key Lessons from LCG32:

Reverse PRNGs use forward analysis path (sieve_filter.py)
Parameters must be hardcoded in kernel
Hybrid reverse needs 'variable_skip': True in registry
No default_params, cpu_reference, etc. in registry
sieve_filter.py must skip params for _reverse kernels


Performance Expectations
Fixed Reverse:

Speed: ~60K seeds/sec per GPU (same as forward)
5K seeds: ~10 seconds on 26 GPUs
1M seeds: ~10-20 minutes

Hybrid Reverse:

Speed: ~1.2K seeds/sec per GPU (same as forward hybrid)
5K seeds: ~10 seconds on 26 GPUs
1M seeds: ~15-30 minutes


Current Progress
Completed: 6/22 (27%)

mt19937_reverse, mt19937_hybrid_reverse
lcg32_reverse, lcg32_hybrid_reverse

Remaining: 16/22 (73%)

8 PRNGs Ã— 2 variants each

Estimated time per PRNG:

With this guide: 30-45 minutes
Includes: kernel creation, registry, testing, deployment
1. PRNG Parameter Reference Table
Add this section so we know EXACTLY what to hardcode for each PRNG:
bashcat >> instructions.txt << 'EOF'

## PRNG Parameter Reference (For Hardcoding in Reverse Kernels)

### xorshift32
```c
const unsigned int shift_a = 13;
const unsigned int shift_b = 17;
const unsigned int shift_c = 5;
```

### xorshift64
```c
const unsigned long long shift_a = 13;
const unsigned long long shift_b = 7;
const unsigned long long shift_c = 17;
```

### xorshift128
```c
const unsigned int shift_a = 11;
const unsigned int shift_b = 8;
const unsigned int shift_c = 19;
```

### pcg32
```c
const unsigned long long multiplier = 6364136223846793005ULL;
const unsigned long long increment = 1442695040888963407ULL;
```

### java_lcg
```c
const unsigned long long multiplier = 25214903917ULL;
const unsigned long long addend = 11ULL;
const unsigned long long mask = 281474976710655ULL;
```

### minstd
```c
const unsigned int multiplier = 48271;
const unsigned int modulus = 2147483647;
```

### xoshiro256pp
```c
// No hardcoded params - uses state rotation
// 4x 64-bit state array
```

### philox4x32
```c
const unsigned int multiplier_0 = 0xD2511F53;
const unsigned int multiplier_1 = 0xCD9E8D57;
const unsigned int key_0 = 0x9E3779B9;
const unsigned int key_1 = 0xBB67AE85;
```

### sfc64
```c
// No hardcoded params - uses state array
// 4x 64-bit state array
```
EOF
2. Complete Working Example Kernels
Add full LCG32_REVERSE_KERNEL as copy-paste template:
bash# Extract the working LCG32 kernels and add to docs
cat >> instructions.txt << 'EOF'

## Complete Working Example: LCG32 Reverse Kernels

### LCG32_REVERSE_KERNEL (Fixed Skip)
```c
[paste complete working kernel from prng_registry.py]
```

### LCG32_HYBRID_REVERSE_KERNEL (Variable Skip)
```c
[paste complete working kernel from prng_registry.py]
```

**Key Points from LCG32:**
- Lines 1-15: Signature (NO extra params!)
- Lines 16-18: Hardcoded constants (a, c)
- Lines 20-50: EXACT copy of forward logic
- Lines 51-60: Multi-modulo validation
- Lines 61-70: Survivor storage

EOF
3. Automated Helper Script
Create this script to speed up the process:
bashcat > create_reverse_prng.sh << 'SCRIPT'
#!/bin/bash
# Automated Reverse PRNG Generator
# Usage: ./create_reverse_prng.sh xorshift32

PRNG=$1
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

echo "Creating reverse PRNG for: $PRNG"

# Backup
cp prng_registry.py prng_registry.py.bak_${TIMESTAMP}
cp coordinator.py coordinator.py.bak_${TIMESTAMP}

# Extract forward kernel
FORWARD_KERNEL=$(awk "/${PRNG^^}_KERNEL = r'''/,/^'''/" prng_registry.py)

# Generate reverse kernel (basic template)
cat > ${PRNG}_reverse_template.txt << 'EOF'
# TODO: Copy forward kernel here
# TODO: Change seeds[idx] -> candidate_seeds[idx]
# TODO: Change n_seeds -> n_candidates
# TODO: Hardcode all PRNG parameters at top
# TODO: Remove params from signature
EOF

echo "âœ… Template created: ${PRNG}_reverse_template.txt"
echo "Next steps:"
echo "1. Edit ${PRNG}_reverse_template.txt"
echo "2. Run: cat ${PRNG}_reverse_template.txt >> prng_registry.py"
echo "3. Add registry entries"
echo "4. Test with: python3 coordinator.py test_multi_prng_${PRNG}.json ..."
SCRIPT

chmod +x create_reverse_prng.sh
4. Batch Test Script for All Remaining PRNGs
bashcat > test_remaining_reverse_prngs.sh << 'SCRIPT'
#!/bin/bash
# Test all remaining reverse PRNGs

REMAINING=(
    "xorshift32"
    "xorshift64" 
    "xorshift128"
    "pcg32"
    "java_lcg"
    "minstd"
    "xoshiro256pp"
    "philox4x32"
)

PASSED=0
FAILED=0

for prng in "${REMAINING[@]}"; do
    echo "Testing ${prng}_reverse..."
    
    # Test fixed
    python3 coordinator.py \
        test_multi_prng_${prng}.json \
        --method residue_sieve \
        --prng-type ${prng}_reverse \
        --seeds 5000 \
        --window-size 100 \
        --threshold 0.50 \
        --skip 5 > /tmp/test_${prng}_fixed.log 2>&1
    
    if grep -q "Successful: 26" /tmp/test_${prng}_fixed.log; then
        echo "  âœ… ${prng}_reverse: PASSED"
        ((PASSED++))
    else
        echo "  âŒ ${prng}_reverse: FAILED"
        ((FAILED++))
    fi
    
    # Test hybrid
    python3 coordinator.py \
        test_multi_prng_${prng}.json \
        --method residue_sieve \
        --prng-type ${prng}_hybrid_reverse \
        --seeds 5000 \
        --window-size 100 \
        --threshold 0.50 > /tmp/test_${prng}_hybrid.log 2>&1
    
    if grep -q "Successful: 26" /tmp/test_${prng}_hybrid.log; then
        echo "  âœ… ${prng}_hybrid_reverse: PASSED"
        ((PASSED++))
    else
        echo "  âŒ ${prng}_hybrid_reverse: FAILED"
        ((FAILED++))
    fi
done

echo ""
echo "=========================================="
echo "Final Results: $PASSED passed, $FAILED failed"
echo "=========================================="
SCRIPT

chmod +x test_remaining_reverse_prngs.sh
