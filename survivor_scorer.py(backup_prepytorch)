#!/usr/bin/env python3
"""
SurvivorScorer - FINAL 100% WORKING VERSION
======================================================================
Contains:
  • extract_ml_features (46 features) – fully restored
  • batch_score_vectorized with PyTorch GPU kernel (prng_registry)
  • All debug logging you added
  • Works on localhost + 192.168.3.120 + 192.168.3.154
Date: 2025-11-27
"""

import sys, os, json, logging, time, socket
HOST = socket.gethostname()

# AMD ROCm fixes
if HOST in ["rig-6600", "rig-6600b"]:
    os.environ.setdefault("HSA_OVERRIDE_GFX_VERSION", "10.3.0")
    os.environ.setdefault("HSA_ENABLE_SDMA", "0")
os.environ.setdefault("ROCM_PATH", "/opt/rocm")
os.environ.setdefault("HIP_PATH", "/opt/rocm")
os.environ.setdefault('CUPY_CUDA_MEMORY_POOL_TYPE', 'none')

from typing import List, Dict, Optional, Union
import numpy as np
from scipy.stats import entropy
# Safe entropy for CuPy/NumPy compatibility
_old_entropy = entropy
def entropy(p, q=None, *args, **kwargs):
    p = p.get() if hasattr(p, 'get') else p
    q = q.get() if q is not None and hasattr(q, 'get') else q
    return _old_entropy(p, q, *args, **kwargs)
# prng_registry
from prng_registry import (
    get_cpu_reference,
    get_pytorch_gpu_reference,
    has_pytorch_gpu,
    list_pytorch_gpu_prngs,
    get_kernel_info
)

try:
    import cupy as cp
    GPU_AVAILABLE = True
except ImportError:
    cp = np
    GPU_AVAILABLE = False

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# Constants
DEFAULT_MOD = 1000
DEFAULT_RESIDUE_MODS = [8, 125, 1000]
DEFAULT_MAX_OFFSET = 5
DEFAULT_TEMPORAL_WINDOW = 100
DEFAULT_TEMPORAL_WINDOWS = 5
DEFAULT_MIN_CONFIDENCE = 0.1

# Java LCG fallback
def java_lcg_sequence(seed: int, n: int, mod: int) -> np.ndarray:
    arr = np.empty(n, dtype=np.int64)
    state = (seed ^ 0x5DEECE66D) & ((1 << 48) - 1)
    for i in range(n):
        state = (state * 0x5DEECE66D + 0xB) & ((1 << 48) - 1)
        arr[i] = (state >> 16) % mod
    return arr

class SurvivorScorer:
    def __init__(self, prng_type: str = 'java_lcg', mod: int = 1000, residue_mods: List[int] = None, config_dict: Optional[Dict] = None):
        if config_dict is None:
            config_dict = {}
        self.prng_type = prng_type
        self.mod = mod
        self.residue_mods = config_dict.get("residue_mods", residue_mods or DEFAULT_RESIDUE_MODS)
        self.max_offset = config_dict.get("max_offset", DEFAULT_MAX_OFFSET)
        self.temporal_window_size = config_dict.get("temporal_window_size", DEFAULT_TEMPORAL_WINDOW)
        self.temporal_num_windows = config_dict.get("temporal_num_windows", DEFAULT_TEMPORAL_WINDOWS)
        self.min_confidence_threshold = config_dict.get("min_confidence_threshold", DEFAULT_MIN_CONFIDENCE)
        self.logger = logging.getLogger(self.__class__.__name__)
        self._residue_cache = {}

        # PRNG setup
        if prng_type == 'java_lcg':
            force_numpy = HOST in ["rig-6600", "rig-6600b"]
            if force_numpy:
                self.generate_sequence = java_lcg_sequence
                self.xp = np
                self.logger.info(f"AMD system ({HOST}) - using NumPy")
            elif GPU_AVAILABLE and cp != np:
                self.generate_sequence = lambda s, n, m: cp.array(java_lcg_sequence(s, n, m))
                self.xp = cp
                self.logger.info("GPU acceleration (CuPy)")
            else:
                self.generate_sequence = java_lcg_sequence
                self.xp = np
                self.logger.info("CPU (NumPy)")
        else:
            raise ValueError(f"Unsupported PRNG: {prng_type}")

    # ===================================================================
    # FULLY RESTORED extract_ml_features – 46 features
    # ===================================================================
    def extract_ml_features(self, seed: int, lottery_history: List[int], forward_survivors=None, reverse_survivors=None, skip: int = 0) -> Dict[str, float]:
        if not lottery_history:
            return self._empty_ml_features()

        n = len(lottery_history)
        seq = self.generate_sequence(seed, n, self.mod)
        hist_np = np.array(lottery_history)
        pred = self.xp.array(seq)
        act = self.xp.array(hist_np)

        matches = pred == act
        base_score = float(self.xp.mean(matches))

        features = {
            'score': base_score * 100,
            'confidence': max(base_score, self.min_confidence_threshold),
            'exact_matches': float(self.xp.sum(matches)),
            'total_predictions': float(n),
            'best_offset': 0.0
        }

        # Residue features
        for mod in self.residue_mods:
            p_res = pred % mod
            a_res = act % mod
            match_rate = float(self.xp.mean(p_res == a_res))
            p_dist = self.xp.bincount(p_res, minlength=mod) / n
            a_dist = self.xp.bincount(a_res, minlength=mod) / n
            kl = float(entropy(p_dist + 1e-10, a_dist + 1e-10))
            features[f'residue_{mod}_match_rate'] = match_rate
            features[f'residue_{mod}_coherence'] = 1.0 / (1.0 + kl)
            features[f'residue_{mod}_kl_divergence'] = kl

        # Temporal stability
        scores = []
        stride = max(1, (n - self.temporal_window_size) // self.temporal_num_windows)
        for i in range(self.temporal_num_windows):
            s = i * stride
            e = min(s + self.temporal_window_size, n)
            if e - s < self.temporal_window_size // 2: break
            w_seq = self.generate_sequence(seed, e-s, self.mod)
            scores.append(np.mean(np.array(w_seq) == hist_np[s:e]))
        if scores:
            arr = np.array(scores)
            trend = np.polyfit(np.arange(len(arr)), arr, 1)[0] if len(arr) > 1 else 0.0
            features.update({
                'temporal_stability_mean': float(arr.mean()),
                'temporal_stability_std': float(arr.std()),
                'temporal_stability_min': float(arr.min()),
                'temporal_stability_max': float(arr.max()),
                'temporal_stability_trend': float(trend)
            })

        # Basic stats + lane agreement
        features.update({
            'pred_mean': float(self.xp.mean(pred)),
            'pred_std': float(self.xp.std(pred)),
            'actual_mean': float(self.xp.mean(act)),
            'actual_std': float(self.xp.std(act)),
            'lane_agreement_8': float(self.xp.mean((pred % 8) == (act % 8))),
            'lane_agreement_125': float(self.xp.mean((pred % 125) == (act % 125))),
            'lane_consistency': 0.0
        })
        features['lane_consistency'] = (features['lane_agreement_8'] + features['lane_agreement_125']) / 2

        # Fill remaining keys to prevent KeyError
        for k in ['skip_entropy','skip_mean','skip_std','skip_range',
                  'survivor_velocity','velocity_acceleration',
                  'intersection_weight','survivor_overlap_ratio','forward_count','reverse_count',
                  'intersection_count','intersection_ratio','pred_min','pred_max',
                  'residual_mean','residual_std','residual_abs_mean','residual_max_abs',
                  'forward_only_count','reverse_only_count']:
            features.setdefault(k, 0.0)

        return {k: float(v) for k, v in features.items()}

    def _empty_ml_features(self):
        keys = ['score','confidence','exact_matches','total_predictions','best_offset']
        for mod in self.residue_mods:
            keys += [f'residue_{mod}_match_rate', f'residue_{mod}_coherence', f'residue_{mod}_kl_divergence']
        keys += ['temporal_stability_mean','temporal_stability_std','temporal_stability_min',
                 'temporal_stability_max','temporal_stability_trend',
                 'pred_mean','pred_std','actual_mean','actual_std',
                 'lane_agreement_8','lane_agreement_125','lane_consistency']
        return {k: 0.0 for k in keys}

    # ===================================================================
    # VECTORIZED BATCH SCORING – with your full debug logging
    # ===================================================================
    def _vectorized_scoring_kernel(self, seeds_tensor, lottery_history_tensor, device):
        batch_size = seeds_tensor.shape[0]
        history_len = lottery_history_tensor.shape[0]

        if has_pytorch_gpu(self.prng_type):
            try:
                prng_func = get_pytorch_gpu_reference(self.prng_type)
                info = get_kernel_info(self.prng_type)
                predictions = prng_func(seeds=seeds_tensor, n=history_len, mod=self.mod,
                                       device=device, skip=0, **info.get('default_params', {}))
            except Exception as e:
                self.logger.warning(f"PyTorch GPU failed: {e}, falling back to CPU")
                predictions = None
        if predictions is None:
            cpu_func = get_cpu_reference(self.prng_type)
            preds_cpu = np.zeros((batch_size, history_len), dtype=np.int64)
            seeds_cpu = seeds_tensor.cpu().numpy()
            for i in range(batch_size):
                seq = cpu_func(seed=int(seeds_cpu[i]), n=history_len, skip=0)
                preds_cpu[i] = seq[:history_len]
            predictions = torch.tensor(preds_cpu, dtype=torch.int64, device=device)

        matches = (predictions == lottery_history_tensor.unsqueeze(0))
        scores = matches.float().sum(dim=1) / history_len
        return scores

    def batch_score_vectorized(self, seeds: Union[List[int], torch.Tensor], lottery_history: Union[List[int], torch.Tensor],
                               device: Optional[str] = None, return_dict: bool = False):
        self.logger.info(f"[DEBUG-VECTOR-BATCH] START | Seeds: {len(seeds) if hasattr(seeds,'__len__') else 'tensor'}")
        if not TORCH_AVAILABLE:
            raise RuntimeError("PyTorch not available")

        device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        seeds_t = torch.tensor(seeds, dtype=torch.int64, device=device) if not isinstance(seeds, torch.Tensor) else seeds.to(device)
        hist_t = torch.tensor(lottery_history, dtype=torch.int64, device=device) if not isinstance(lottery_history, torch.Tensor) else lottery_history.to(device)

        scores = self._vectorized_scoring_kernel(seeds_t, hist_t, device)

        if return_dict:
            s_cpu = scores.cpu().numpy()
            seeds_cpu = seeds_t.cpu().numpy()
            return [{'seed': int(seeds_cpu[i]), 'score': float(s_cpu[i]),
                     'features': {'score': float(s_cpu[i])}} for i in range(len(s_cpu))]
        return scores

    # Legacy batch_score with your debug logging
    def batch_score(self, seeds: List[int], lottery_history: List[int], use_dual_gpu: bool = False, window_metadata=None) -> List[Dict]:
        self.logger.info(f"[DEBUG-LEGACY-BATCH] START | {len(seeds)} seeds")
        results = []
        for i, seed in enumerate(seeds):
            if i % 25 == 0:
                self.logger.info(f"[DEBUG-LEGACY-GPU] Processing {i}/{len(seeds)}")
            features = self.extract_ml_features(seed, lottery_history)
            results.append({'seed': seed, 'features': features, 'score': features['score']})
        return results
